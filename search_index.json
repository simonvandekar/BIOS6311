[["index.html", "BIOS6311: Principles of Modern Biostatistics Course information FINAL DECEMBER 7TH 2023 MIDTERM NOVEMBER 9TH 2023 Syllabus 0.1 Labs 0.2 Homework", " BIOS6311: Principles of Modern Biostatistics Simon Vandekar 2023-08-19 Course information This document includes all the course notes for Vanderbilt Biostatistics BIOS6311 Principles of Modern Biostatistics. FINAL DECEMBER 7TH 2023 MIDTERM NOVEMBER 9TH 2023 From that Rice book above here are some good practice problems: Section 4.7: 2, 16, 44, 47, 50, 54, 68 (not really that helpful) Section 5.4: 11 (might be helpful), 17 (the equality should be approximate equality), Section 7.7: 3, 8, 10, 16, 17, 18, 21 Syllabus Schedule: Tuesdays/Thursdays 10:30am-12pm (in-person) Lab: Tuesdays 4pm-5pm (in-person) Instructor: Simon Vandekar (he/him/his) TA: Yeji Kuo Office hours: by appointment Email: simon.vandekar@vumc.org. I do not check my vanderbilt.edu email address, regularly. 0.0.1 Overview Biostatistics (and statistics) is a framework for learning about the world that is based on the theory of probability. The goal of this class is to teach the concepts of biostatistics through basic examples that form the content of the class using software tools for reproducible statistical research in R. The concepts are the basis for modern statistical research – i.e. the foundational concepts you learn here can be used to evaluate modern statistical methods. The objective content will cover basic statistical objects (e.g. means), with as much focus as possible on rigorous modern methods. My interests are in medical imaging in the fields of psychology, psychiatry, and cellular biology, so I will use examples from those fields, hoping to pique your interest in those research areas. 0.0.2 Goal Upon completion of this course, you should be able to evaluate statistical methods based on their operating characteristics. While the concepts for methods evaluation we will learn are more general, they will be taught in the context of one and two-sample statistical methods within Frequentist, Likelihood, and Bayesian philosophies with as much focus as possible on rigorous modern methods. If the course is effective you will Strengthen mathematical tools for understanding and evaluating statistical methods Learn to analyze a dataset using basic statistical inference tools (e.g. one sample/two sample tests) Learn to program statistical evaluation tools in R Learn to use the goals and concepts of the three statistical philosophies Evaluate statistical methods using simulations and bootstrapping Understand how statisticians choose and design statistical methods 0.0.3 Datasets Most of the course will be taught through applications with a dataset. I will make a couple datasets available for you to apply your statistical methods and evaluation tools. 0.0.4 Homework Homework will be your primary grade for the course. It will also be the way that you will learn software tools through hands on experience: we will plan for you to submit most of homework assignments using Rmarkdown. 0.0.5 Exams and Quizzes Previously, I just had fill-in-the-blank quizzes and a final exam. This time we will have an open-answer midterm and final to help prepare you for the first qualifying exam. 0.0.6 Class This will be an in-person class, but I might record the lectures. We will meet in-person twice a week (Tues/Thurs 10:30am-12pm). In class meetings we’ll be working to solve math and programming problems together that will help you do your homework. 0.0.7 Lab There will be as many lab activities as I have time to plan. Otherwise that time will be used to help debug code, catch up on missed classes, or learn the materials and work together or in groups on the homework. Background necessary for the course: The official background for the course is Calculus 1. I will teach as if you have taken introductory probability, such as “A first course in probability,” by Ross. I assume novice level literacy in R statistical programming, but experience in another language will be helpful to learning R (in particular Matlab and Python). I will use some linear algebra if the class as a whole seems to have sufficient background in this area. 0.0.8 Text I’ve based the class off of previous versions by Robert Greevy and “Mathematical Statistics and Data Analysis,” by Rice. I will not explicitly use this book in the class, but it is probably the most complete reference for the material. I will point to other references as they come up. 0.0.9 Class resources Previously I’ve done everything in Brightspace, but to make it more accessible, I am going to host it through a course webpage instead. Brightspace - For class communication, homework submission and grading. Pumble - For class communication. Box - For sharing datasets and files. 0.0.10 Diversity and inclusion: Creativity is critical to research in statistics. In statistics, creativity comes in the form of questions (e.g. what happens if this model is incorrect?; when I condition on a subset of the data, what things are still random?) Diversity is at the heart of creativity, because our perspectives shape how we see the world. By working together to consider other’s perspectives, we will learn more about the problems we discuss. For this reason, please interact with each other in a spirit of curiosity and empathy (not just about the class content, but as you learn about the people you will go through grad school with). I expect this class to be a welcoming environment for all students, regardless of background, skin color, gender identity, orientation, spiritual belief or any other personal feature. 0.0.11 Course outline I might adapt course content based on the mine or the classes interests. This is generally how it has looked: Probability tools and R Law of Large Numbers and Central Limit Theorem Confidence intervals for a single mean Z intervals T intervals CIs for binomial proportion Hypothesis testing Paired means Two means Welch’s correction Likelihood theory Features of the likelihood function Bayesian statistics Binomial proportion Normal mean Contingency tables and tests for two binomial means (might switch this for effect sizes) Resampling and Nonparametric methods Overview of regression 0.1 Labs All the shared files are here. Here is a list of links to the lab activities. Week 1 0.2 Homework Here is a list of links for the homework. Homework 1 Homework 2 Homework 3 "],["glossaryjargon.html", "Glossary/Jargon", " Glossary/Jargon Reference distribution - the standardized distribution used to compute probabilities. Examples include the Normal distribution, Chi-squared distribution, T distribution, and F distribution. Sampling distribution - the true distribution of a statistic drawn from data randomly sampled from a distribution. For a test statistic, it may not be the same as the reference distribution if we are using approximations or assumptions are violated. Statistic - a random variable computed as a function of a random sample. Test statistic - the standardized value, which is assumed to follow the reference distribution. One/two tailed hypothesis Paired/unpaired test One/two sample test Skew Type 1 error rate - the probability of falsely rejecting the null when it is true. Type 2 error rate - the probability of falsely retaining the null when it is false. Power - the probability of correctly rejecting the null. Wald statistic - A statistic derived as the estimator minus the parameter divided by the variance of the estimator times square root of \\(n\\), \\(\\frac{\\sqrt{n}(\\hat\\mu - \\mu)}{\\text{Var}(\\sqrt{n} \\hat\\mu)}\\). Parameter - an unknown population value. Estimator - a statistic used to estimate a parameter. Estimate - a function of an observed sample used to estimate a parameter (not random). Coverage - The proportion of the time that an interval captures the true value of the parameter. Width/Length - The expected width/length of a confidence interval is the distance between the upper and lower bounds. Consistent estimator - an estimator that converges to the target parameter as the sample size gets bigger. Standard error - the standard deviation of a statistic. "],["how-to-follow-along-in-this-class.html", "How to follow along in this class 0.3 Class notes 0.4 Labs and homeworks", " How to follow along in this class 0.3 Class notes I will use the whiteboard and Rstudio for teaching. The notes and code will be based of of what is available in this document. 0.3.1 Written notes Because I will be writing on the whiteboard for written notes, you can Follow along with your own notebook. Print the notes and add your own. To print the notes, Push the lines in the hover menu at the top to close the sidebar and then print to pdf or paper in your browser. Please print two-sided. Save as a PDF and open in Notes app on a tablet where you can annotate the file. 0.3.2 Code notes The code examples in the course may be fully written in the notes, or they may be barebones that we complete together in class. I will try to update the code in this document, so that the code is completed here after we have written it in class. To follow along with R code you can Create an Rmarkdown file with a section for each chunk of example code we run and complete the code as we complete it in class. Write the code in separate .R scripts organized in a file for the course. 0.4 Labs and homeworks This document and all the files in the course are compiled using Rmarkdown. For completing the labs and homework assignments, I’m assuming that you will download the files and type your answers into the documents. There will be a bit of a learning curve, so it’s best to start working with it on the first assignments, so that you don’t feel too overwhelmed trying to learn Rmarkdown and the course content. Check out the Week 1 lab assignment as an example of the folder structure I will use for homework and labs. You can download the whole folder and work from there. There are the following files in the folder that you need to pay attention to: lab1_2.Rproj - this is R project file that opens up a saved workspace in Rstudio. lab1_2.Rmd - this is the Rmarkdown file that you can edit to complete your answers. lab1_2.html - this is the output from the Rmarkdown file. When you add your answers and hit the Knit button in Rstudio it will compile this file. You can change the format between html/pdf/docx. The other files are intermediate files created after you push the Knit button. "],["probability.html", "1 Probability 1.1 Probability review 1.2 CDFs, PDFs, quantile functions 1.3 Multivariate random variables 1.4 Parameters, estimates, and estimators", " 1 Probability 1.1 Probability review 1.1.1 Objectives In this meeting we will: Introductions Review some probability notation (e.g. PMF, Expectations) Use Bernoulli random variables to study proportions Define Estimators and learn to compute values assess estimators 1.1.2 Administrative stuff Introductions How did you get interested in statistics? What do you do for fun? Syllabus 1.1.3 Types of data Continuous Categorical Ordinal Examples: Brain volume Diagnosis Symptom rating scale (1-7) Coin flip Proportion of heads in \\(N\\) flips Proportion of time spent sleeping each week 1.1.4 Random variables Random variables are the key player in statistics and are often used to describe the process by which data arise. 1.1.4.1 Probability notation Blackboard P is probability, \\(\\mathbb{P}(X=x)\\), means the probability the random variable \\(X\\) is equal to the nonrandom value \\(x\\). \\(\\sim\\) “is distributed as” Probability mass function (PMF; loose definition is it assigns probabilities to values for a given random variable) Continuous/Discrete random variables A random variable does not have a value in itself… We don’t usually talk about \\(X=0.5\\), but \\(\\mathbb{P}(X=0.5)\\). 1.1.4.1.1 Bernoulli example Something that takes only two values can be described with a Bernoulli random variable. Coin flip Diagnosis For \\(X\\sim \\text{Be}(\\pi)\\): X is distributed as Bernoulli, with parameter \\(\\pi \\in (0,1)\\), e.g. \\(\\pi=0.25\\). \\(\\mathbb{P}(X = x) = \\pi^x(1-\\pi)^{(1-x)}\\). That is the probability mass function (PMF) of a Bernoulli random variable Common notation is \\(f_X(x)\\) is the PMF of the random variable \\(X\\). In this case \\(f_X(x):=\\pi^x(1-\\pi)^{(1-x)}\\). \\(:=\\) notation means “is defined by.” 1.1.4.2 Probability axioms We have an intuitive understanding of the basic axioms of probability. An event \\(E\\) is something that can occur, e.g. head or tails \\(\\{0,1\\}\\). Let \\(\\Omega = {0,1}\\) be union of all possible events The (Kolmogorov) axioms are \\(\\mathbb{P}(X\\in E) \\ge 0\\) – probability is positive. \\(\\mathbb{P}(X\\in \\Omega) = 1\\) – probabilities sum to 1. For disjoint sets \\(E_1 \\cap E_2 = \\varnothing\\), \\(\\mathbb{P}(E_1 \\cup E_2) = \\mathbb{P}(E_1) + \\mathbb{P}(E_2)\\). 1.1.4.3 Why use probabilities for data? STOPPED HERE Intuitive and communicable explanation? Table below from Chess in the air Risk of dying 1.1.4.4 Multinomial example A die is an example of a multinomial distribution Code die = data.frame(&#39;X&#39;=1:6, &#39;P(X)&#39;=paste0(&#39;$\\\\pi_&#39;, 1:6, &#39;$&#39;), check.names = FALSE) knitr::kable(die) X P(X) 1 \\(\\pi_1\\) 2 \\(\\pi_2\\) 3 \\(\\pi_3\\) 4 \\(\\pi_4\\) 5 \\(\\pi_5\\) 6 \\(\\pi_6\\) Can also think about statements like \\(\\mathbb{P}(X\\le x)\\) This is a sum over probabilities corresponding to possible values of \\(X\\). Missing probabilities are called parameters e.g. x = 2 \\[ \\sum_{i=1}^2 \\mathbb{P}(X=i) = 1/3 \\] 1.1.4.5 Wordle Multinomial example Multinomial can be used for distributions of other things E.g. Wordle scores. The probability of getting the Wordle in a certain number of guesses. Also 6 (or one more) possible values. Same family of distribution as the die, except with different parameters \\(Y=\\)Number of tries \\(P(Y)\\) 1 0 2 0.03 3 0.28 4 0.40 5 0.18 6 0.11 7 ?? Code wordle = c(0, 2, 17, 25, 11, 7) #wordle/sum(wordle) #round(wordle/sum(wordle), 2) Wordle results 1.1.4.6 Normal example The normal density has two parameters \\(\\mu, \\sigma\\) is \\[ \\mathbb{P}(X\\le x) = \\int_{-\\infty}^x (2\\pi\\sigma^2)^{-1/2} \\exp\\left\\{-\\frac{1}{2\\sigma^2}(z-\\mu)^2 \\right\\}dz \\] Probabilities of sets \\(\\mathbb{P}(X \\in E)\\), where \\(E = (-\\infty, -1.96) \\cup (1.96, \\infty)\\). Probability \\(X=x\\)? Examples: Multinomial – after a rolling a die, it has to land on one of them. Normal, \\(E=(-\\infty,\\infty)\\). If not disjoint, then adding some probabilities twice. Multinomial \\(\\{1,2,3 \\}, \\{4,3\\}\\) 1.2 CDFs, PDFs, quantile functions 1.2.1 Objectives Introduce CDFs, PDFs, and quantile functions Introduce Expectations (means) 1.2.2 PDFs and CDFs (and quantile functions) 1.2.2.1 PDFs The PDF (probability density function) is the derivative of the CDF and often denoted with a lower case letter \\(f(x)\\). For discrete random variables the PDF is call the PMF (probability mass function). Figure 1.1: Corresponding density functions. 1.2.2.2 PDFs continued The PDF can conceptually be thought of as \\(\\mathbb{P}(X=x)\\), for PMFs, that’s exactly what it is. But, for continuous random variables the probability they take any value is equal to zero. These PDFs are functions with parameters: \\[ \\begin{align*} \\text{Normal: }&amp; f(x; \\mu, \\sigma^2) = (2\\pi\\sigma^2)^{-1/2} \\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2 \\right\\} \\\\ \\text{Gamma: }&amp; f(x; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x} \\\\ \\text{Poisson: }&amp; f(x; \\lambda) = \\frac{\\lambda^k\\ e^{-\\lambda}}{k!} \\\\ \\end{align*} \\] The CDF (below) and PDF are useful because we never know what values the random variable will take, so we can integrate the PDF or use the CDF to figure out where they are most likely to fall. 1.2.2.3 CDFs The cumulative distribution function (CDF), \\(F(x)\\), for a random variable \\(X\\) is a function that satisfies \\[ F(x) = \\mathbb{P}(X \\le x). \\] They are usually functions of parameters. Here are some examples. Figure 1.2: Some distribution functions. 1.2.2.3.1 Human Connectome Project Brain volume example A brain. Human Connectome Project data Study designed to understand how regions of the brain are interconnected Code hcp = read.csv(&#39;../datasets/hcp/hcp.csv&#39;) mu = mean(hcp$FS_TotCort_GM_Vol, na.rm=T) sigma = sd(hcp$FS_TotCort_GM_Vol, na.rm=T) mu ## [1] 510019.7 Code sigma ## [1] 53940.92 Code x = seq(mu - 3*sigma, mu + 3*sigma, length.out=1000) fOfX = dnorm(x, mean = mu, sd=sigma) plot(x, fOfX, type=&#39;l&#39;, xlab=&#39;Brain volume&#39;, ylab=&#39;f(Brain Volume)&#39;) Code hist(hcp$FS_TotCort_GM_Vol, xlab=&#39;Brain Volume&#39;, xlim=c(mu - 3*sigma, mu + 3*sigma)) For discrete random variables the derivative of the CDF does not exist because it is a step function, but the probability mass function is the amount the CDF jumps up at that location, heuristically we can define it as \\[ f(x) = F(x+\\Delta x) - F(x), \\] for an infinitesimal value \\(\\Delta x\\). 1.2.2.3.2 Wordle CDF example \\(Y=\\)Number of tries \\(P(Y|\\text{Simon})\\) \\(P(Y|\\text{Lillie})\\) 1 0 0 2 0.03 0.05 3 0.28 0.24 4 0.40 0.44 5 0.18 0.19 6 0.11 0.08 Code wordle1 = c(0, 2, 17, 25, 11, 7) wordle2 = c(0, 2, 9, 16, 7, 3) wordle1 = cumsum(wordle1/sum(wordle1)) wordle2 = cumsum(wordle2/sum(wordle2)) x = 0:7 plot(x, c(0,wordle1, 1), main=&#39;Wordle CDFs&#39;, type=&#39;s&#39;, ylab=&#39;P(X&lt;=x)&#39;) points(x, c(0,wordle2, 1), type=&#39;s&#39;, col=&#39;red&#39;) 1.2.2.3.3 Human Connectome Project CDF example (continued) We can compute probabilities that people lie within a given region using the CDF. Code x = seq(mu - 3*sigma, mu + 3*sigma, length.out=1000) fOfX = dnorm(x, mean = mu, sd=sigma) plot(x, fOfX, type=&#39;l&#39;, xlab=&#39;Brain volume&#39;, ylab=&#39;f(Brain Volume)&#39;) Probability someone is between \\(450,000\\mathrm{mm}^3\\) and \\(450,000\\mathrm{mm}^3\\) Probability someone is less than \\(400,000\\mathrm{mm}^3\\). probability someone is greater than\\(500,000\\mathrm{mm}^3\\) Code # center pnorm(550000, mean=mu, sd=sigma) - pnorm(450000, mean=mu, sd=sigma) ## [1] 0.6377898 Code # lower tail pnorm(400000, mean=mu, sd=sigma) ## [1] 0.0206934 Code # upper tail 1-pnorm(600000, mean=mu, sd=sigma) ## [1] 0.0476453 1.2.2.4 Quantile functions The quantile function is the inverse of the CDF. For a given probability \\(p\\), it spits out a value \\(Q(p)\\) such that that \\(F(Q(p)) = p\\). The interpretation is that for a given probability \\(p\\), There’s a \\(p\\) percent probability that the random variable will be below \\(Q(p)\\). Sometimes, it’s possible to find the quantile function explicitly, but many times it isn’t. Also can call these “percentiles” if you multiply them by 100. 1.2.2.4.1 HCP example 5% of people have a brain volume larger than what value? What is the middle value (median; .5 quantile) of brain volumes? What is interquartile range (difference between .75 quantile and .25 quantile)? Code # 95 percentile of brain volume qnorm(1-0.05, mean=mu, sd=sigma) ## [1] 598744.6 Code # Median qnorm(0.5, mean=mu, sd=sigma) ## [1] 510019.7 Code # IQR qnorm(0.75, mean=mu, sd=sigma) - qnorm(0.25, mean=mu, sd=sigma) ## [1] 72765.19 1.2.3 Expectations 1.2.3.1 Overview Many things we care about about a random variable are expectations. The expectation is an “operator” on a random variable, meaning it takes function of a random variable \\(g(X)\\) for a (somewhat) arbitrary function \\(g\\) and is defined by \\[ \\mathbb{E} g(X) = \\int_{\\mathcal{X}} g(x) p(x) dx, \\] where \\(p(x)\\) is the density function of \\(X\\) and the \\(\\mathcal{X}\\) subscript is to denote that we are integrating over the domain of values \\(X\\) can take. 1.2.3.2 Great expectations The mean is the most common expectation \\[ \\mathbb{E} X = \\int_{\\mathcal{X}} x p(x) dx. \\] The integral notation is in the sense of “real analysis” type integrals that can refer to sums or integrals. This is to emphasize that the definition is the same with continuous or discrete random variables. Another great expectation is the variance \\[ \\text{Var}(X) = \\mathbb{E} (X - \\mathbb{E}X)^2 = \\mathbb{E}X^2 - (\\mathbb{E}X)^2 \\] Properties of the variance are homework questions. In general, \\[ \\mathbb{E}X^k \\] is call the \\(k\\)th moment of \\(X\\). 1.2.3.3 Properties of expectations \\(\\mathbb{E}a X + b = a \\mathbb{E}X + b\\) \\(\\mathbb{E}\\{ \\mathbb{E}X\\} = \\mathbb{E}X\\) (\\(\\mathbb{E}X\\) is a constant) 1.2.3.4 Expected value for Bernoulli For the Bernoulli \\(X\\sim \\text{Be}(p)\\) the expectation is \\[ \\mathbb{E}X = \\sum_{i=0}^1 x_i f_X(x_i) = 1 \\times p + 0 \\times (1-p) = p \\] 1.2.3.5 Expected value for Multinomial \\(Y\\) \\(P(Y)\\) \\(P(Y)\\) \\(P(Y)\\) 1 1/4 .1 .7 2 1/4 .2 .1 3 1/4 .3 .1 4 1/4 .4 .1 1.2.3.6 Expected value for Wordle score \\(Y=\\)Number of tries \\(P(Y)\\) 1 0 2 0.03 3 0.28 4 0.40 5 0.18 6 0.11 Code wordle = c(0, 2, 17, 25, 11, 7) #wordle/sum(wordle) #round(wordle/sum(wordle), 2) Wordle results 1.2.3.7 Expected value for Poisson random variable Poisson random variables are useful for modeling skewed counts. E.g. number of drinks of alcohol in a week. E.g. score on a depression inventory or other psychology/scale. \\[ f(x; \\lambda) = \\frac{\\lambda^x\\ e^{-\\lambda}}{x!} \\] Expectation and Variance of Poisson distribution Code x = seq(0, 15) plot(x, dpois(x, lambda=5), main=&#39;Poisson(5)/Poisson(0.5)&#39;, type=&#39;p&#39;, ylab=&#39;P(X=x)&#39;, ylim=c(0,1)) points(x, dpois(x, lambda=0.5), type=&#39;p&#39;, col=&#39;red&#39;) 1.2.3.8 Expected value for standard Normal distribution Start with the standardized normal distribution \\[\\begin{align*} \\mathbb{E}X &amp; = \\int_{-\\infty}^\\infty x \\left(2\\pi \\right)^{-1/2} \\exp\\left\\{-\\frac{1}{2} x^2 \\right\\}\\\\ &amp; = \\left(2\\pi \\right)^{-1/2} \\int_{0}^\\infty \\exp\\{-u\\} du - \\left(2\\pi \\right)^{-1/2} \\int_{0}^\\infty \\exp\\{-u\\} du \\end{align*}\\] where \\(u = x^2/2\\). This equals zero. 1.2.3.9 Expected value for Normal distribution Start with the standardized normal distribution and use change of variables. For \\(X\\sim N(0,1)\\), let \\(Y = X\\sigma + \\mu\\). What is \\(\\mathbb{E}Y\\)? Then \\[\\begin{align*} \\mathbb{P}(Y&lt;z) = \\mathbb{P}((X\\sigma+\\mu)&lt;z) = \\mathbb{P}(X&lt; (z - \\mu)/\\sigma) \\\\ = \\int_{-\\infty}^{(z-\\mu)/\\sigma} \\left(2\\pi \\right)^{-1/2} \\exp\\left\\{-\\frac{1}{2} x^2 \\right\\} dx\\\\ = \\int_{-\\infty}^{y} \\left(2\\pi \\sigma^2\\right)^{-1/2} \\exp\\left\\{-\\frac{1}{2\\sigma^2} (w-\\mu)^2 \\right\\} dw \\end{align*}\\] This is the CDF a \\(N(\\mu, \\sigma^2)\\). 1.2.3.10 Properties of variance \\(\\mathrm{Var}(aX +b) = a^2 \\mathrm{Var}(X)\\) 1.3 Multivariate random variables 1.3.0.1 Overview Let \\(W = (X, Y) \\in \\mathcal{B}\\) be a multivariate random variable. \\(X\\) and \\(Y\\) can be continuous or discrete. For example \\(X,Y\\) can be multivariate normal. 1.3.0.2 Example For \\(X\\in\\{1,2\\}\\) and \\(Y \\in \\{1,2,3\\}\\) Joint probability table Marginal probabilities Conditional probabilities (intuitively) Draw the 3 different tables. Code probs = data.frame( X=rep(1:3, each=2), Y = rep(c(1,2), 3)) probs$p = paste0(&#39;$p_{&#39;, probs$X, probs$Y, &#39;}$&#39;) tabout = t(table(probs$X, probs$Y)) tabout[,] = probs$p tabout = t(tabout) knitr::kable(tabout, row.names = TRUE, escape = FALSE ) 1 2 1 \\(p_{11}\\) \\(p_{12}\\) 2 \\(p_{21}\\) \\(p_{22}\\) 3 \\(p_{31}\\) \\(p_{32}\\) 1.3.0.3 Example: Umbrella and raining A common example is whether someone brings an umbrella with them It’s not raining It’s raining I don’t bring umbrella 0.05 0.17 I bring umbrella 0.35 0.43 Another example It’s not precipitating It’s raining It’s snowing I don’t bring umbrella 0.03 0.17 0.02 I bring umbrella 0.35 0.40 0.03 1.3.1 Distribution functions The distribution function for multivariate random variables is often written in terms of subsets \\(B \\subset \\mathcal{B}\\) \\[ F_W(B) = \\mathbb{P}(W \\in B). \\] If \\(W\\) has a density then we can also write for values \\(x\\) and \\(y\\) (in the appropriate domain) \\[ \\mathbb{P}(W \\in B) = \\int_{B} f_W(x, y)dx dy, \\] where \\(f_W\\) is the PDF or PMF of \\(W = (X,Y)\\). 1.3.2 Marginal probability The marginal probability, \\(\\mathbb{P}(Y=y)\\) is the probability for \\(Y\\) ignoring whatever is going on with \\(X\\). This can be found by integrating out the \\(X\\) variable. \\[ f_Y(y) = \\int_\\mathcal{X} f_{X,Y}(x, y)dx \\] Joint multinomial above to demonstrate this. 1.3.3 Conditional distribution Conditional distributions can be written in terms of the underlying probability space. For sets \\(A, B \\subset \\mathcal{B}\\) \\[ \\mathbb{P}(A \\mid B ) = \\frac{\\mathbb{P}( A \\cap B)}{\\mathbb{P}(B)} \\] Venn diagram of sets Conceptually, the denominator adjusts the numerator for the fact that we are only considering events that include B occurring. This makes the conditional probabilities sum to 1. For multivariate random variables the definition is similar \\[ \\mathbb{P}(Y=y \\mid X=x) = \\frac{\\mathbb{P}(X=x, Y=y)}{\\mathbb{P}(X=x)} \\] Can think of the Venn diagram in terms of the joint random variable falling into the set. Probability I bring and umbrella given that it’s raining Probability it’s raining given it’s not precipitating (Conditioning on itself) 1.3.4 Examples 1.3.4.1 Insurance dataset children and region The insurance dataset is in the RESI R package, which you can install with the following code Code install.packages(&#39;RESI&#39;) There are some cool multivariate distributions in this data set. Consider the probability of having a certain number of children living in a certain area. Code library(RESI) # contains insurance dataset childByRegion = table(insurance$region, insurance$children) childByRegion = childByRegion/sum(childByRegion) knitr::kable(round(childByRegion, 2)) 0 1 2 3 4 5 northeast 0.11 0.06 0.04 0.03 0.01 0.00 northwest 0.10 0.06 0.05 0.03 0.00 0.00 southeast 0.12 0.07 0.05 0.03 0.00 0.00 southwest 0.10 0.06 0.04 0.03 0.01 0.01 Let \\(X\\) be a random variable denoting number of children Is it categorical/continuous/ordinal? Let \\(Y\\) be a random variable denoting region Is it categorical/continuous/ordinal? joint distribution is a function of both variables \\(\\mathbb{P}(X=x, Y=y) = f(x,y)\\). Questions about regional differences and number of children can be determined from the table What is the probability of having zero kids and living in the east? What is the probability of having zero kids? 1.3.4.2 Insurance data multivariate distribution of age and charges Code library(RESI) name=&#39;charges&#39; hist(insurance[,name], xlab=name, main=name, freq=FALSE) lines(density(insurance[,name], adjust=1.5), lwd = 2) Relationship between age and charges in the insurance data Code plot(insurance[,&#39;age&#39;], insurance$charges, ylab=&#39;Charges&#39;, xlab=&#39;Age&#39;, main=paste(&#39;Age&#39;, &#39;and&#39;, &#39;Charges&#39;) ) The scatter plot can be thought of as a dataset version of a joint density \\(f_{X,Y}(x,y)\\) We can get the conditional histograms for a few different age groups Code par(mar=c(8,2.8,1.8,.2), mgp=c(6,.7,0)) nbin = 15 insCat = with(insurance, data.frame(age=cut(age, breaks = seq(min(age), max(age), length.out=7), include.lowest=T), charges=cut(charges/1000, breaks = seq(min(charges/1000), max(charges/1000), length.out=nbin), include.lowest=T) ) ) condTab = do.call(cbind, by(insCat$charges, insCat$age, function(x){res=table(x); res/sum(res)})) barplot(condTab, beside=TRUE, col=rep(cols[1:ncol(condTab)], each=nbin-1), names.arg = rep(rownames(condTab), ncol(condTab) ), las=2, xlab=&#39;Charges (in thousands)&#39;, main=&#39;Conditional frequencies&#39;) legend(&#39;topright&#39;, fill=cols[1:ncol(condTab)], legend=colnames(condTab), bty=&#39;n&#39;) Code par(mar=c(8,2.8,1.8,.2), mgp=c(6,.7,0)) nbin = 15 jointTab = do.call(cbind, by(insCat$charges, insCat$age, function(x){res=table(x); res})) jointTab = jointTab/sum(jointTab) barplot(jointTab, beside=TRUE, col=rep(cols[1:ncol(jointTab)], each=nbin-1), names.arg = rep(rownames(jointTab), ncol(jointTab) ), las=2, xlab=&#39;Charges (in thousands)&#39;, main=&#39;Joint frequencies&#39;) legend(&#39;topright&#39;, fill=cols[1:ncol(jointTab)], legend=colnames(jointTab), bty=&#39;n&#39;) Code par(mar=c(8,2.8,1.8,.2), mgp=c(6,.7,0)) nbin = 15 test = barplot(t(jointTab), beside=FALSE, col=cols[rep(1:ncol(jointTab), nbin-1)], las=2, xlab=&#39;Charges (in thousands)&#39;, main=&#39;Marginal frequencies&#39;, space=0) legend(&#39;topright&#39;, fill=cols[1:ncol(jointTab)], legend=colnames(jointTab), bty=&#39;n&#39;) 1.3.5 Conditional means and variances Once you have conditional probabilities, you can do all the same stuff with it that you would do with a regular random variable For example, \\(\\mathbb{E}(Y \\mid X) = \\sum_{y} y f_{y\\mid x}(y \\mid x)\\) Conditional expectation is just an expectation with respect to a conditional distribution. \\[ \\begin{align*} \\mathbb{E}(Y \\mid X=x) &amp; = \\int_{\\mathcal{Y}} yf_{Y\\mid X=x}(y\\mid x)dy \\\\ &amp; = \\int_{\\mathcal{Y}} yf_{Y,X}(y, x)/f(x)dy \\\\ &amp; = \\int_{\\mathcal{Y}} yf_{Y,X}(y, X)/f(X)dy \\end{align*} \\] It can still be thought of as random with respect to the conditioning variable. \\(P(X=1)=.1\\) \\(P(X=2) = .7\\) \\(P(X=3)=.2\\) \\(Y\\) \\(P(Y|X=1)\\) \\(P(Y| X=2)\\) \\(P(Y| X=3)\\) 1 1/4 .1 .7 2 1/4 .2 .1 3 1/4 .3 .1 4 1/4 .4 .1 1.3.6 Properties of expectation for two random variables Expectation is linear because it is an integral. For example, for constants \\(a,b\\) and random variables \\(X,Y\\) \\[ \\mathbb{E}(aX + bY) = a \\mathbb{E} X + b\\mathbb{E}Y \\] 1.3.6.1 Example: discrete and continuous joint distribution Diagnosis and hippocampus volume in Alzheimer’s disease. \\(P(DX)\\) is multinomial, \\(P(Hipp\\mid DX)\\) assumed to be normal. Code adni = readRDS(&#39;../datasets/adni/hippocampus.rds&#39;) tab = round(do.call(rbind, by(adni$LEFTHIPPO, adni$DX, function(x) c(mean(x), var(x)) )), 0) pX = table(adni$DX); pX = as.data.frame(round(pX/sum(pX),2)); names(pX) = c(&#39;X&#39;, &#39;P(X)&#39;) colnames(tab) = c(&#39;Mean&#39;, &#39;Variance&#39;) knitr::kable(pX, row.names = FALSE, escape = FALSE ) X P(X) AD 0.26 HC 0.29 MCI 0.45 Code knitr::kable(tab, row.names = TRUE, escape = FALSE ) Mean Variance AD 1549 109794 HC 2122 89241 MCI 1803 131030 1.3.7 Independence Two random variables are independent if they factor \\(\\mathbb{P}(X=x, Y=y) = \\mathbb{P}(X=x)\\mathbb{P}(Y=y)\\) for all possible values of \\(x\\) and \\(y\\). Intuitively, this means that fixing one variable doesn’t affect the distribution of the other. Another way to express it is that \\(\\mathbb{P}(X=x\\mid Y=y) = \\mathbb{P}(X=x)\\). The table is pretty close to independent. Conditional probabilities are \\(\\mathbb{P}(\\text{N kids} | \\text{Region})\\). This means that they are independent if their CDFs or PDFs factor! If the table above were perfectly independent, it might look like this: Code rs = rowSums(childByRegion) cs = colSums(childByRegion) indepTab = outer(rs, cs) knitr::kable(round(indepTab, 3)) 0 1 2 3 4 5 northeast 0.104 0.059 0.043 0.028 0.005 0.003 northwest 0.104 0.059 0.044 0.029 0.005 0.003 southeast 0.117 0.066 0.049 0.032 0.005 0.004 southwest 0.104 0.059 0.044 0.029 0.005 0.003 Code barplot(indepTab, main=&#39;Joint probabilities&#39;, ylab=&#39;Probability&#39;, xlab=&#39;Number of children&#39;, beside=T, col=cols[1:nrow(indepTab)]) legend(&#39;topright&#39;, fill=cols[1:nrow(indepTab)], legend=rownames(indepTab), bty=&#39;n&#39; ) Code condTab = sweep(indepTab, 1, rowSums(childByRegion), FUN = &#39;/&#39;) barplot(condTab, main=&#39;Conditional probabilities&#39;, ylab=&#39;Probability&#39;, xlab=&#39;Number of children&#39;, beside=T, col=cols[1:nrow(condTab)]) legend(&#39;topright&#39;, fill=cols[1:nrow(condTab)], legend=rownames(condTab), bty=&#39;n&#39; ) Are charges and smoking independent? 1.3.8 Covariance and dependence Expand this and derive the other formula \\[ \\text{Cov}(X, Y) = \\mathbb{E}(X-\\mathbb{E}X)(Y-\\mathbb{E}Y) \\] Correlation is \\[ \\begin{align*} \\text{Cor}(X,Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} \\in [-1,1] \\end{align*} \\] Covariance implies dependence, but dependence does not imply covariance (homework question). Independence implies zero covariance, but dependence does not imply nonzero covariance. The covariance can be zero between two random variables, but they can still be dependent. Covariance summarizes the linear dependence between two random variables. 1.3.9 Pearson’s correlation Sampling two measurements on each subject \\(X_i\\) \\(Y_i\\). Correlation is a normalized variance \\[ \\begin{align*} \\rho = \\text{Cor}(X,Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} \\end{align*} \\] It takes values between -1 and 1. negative values means they two variables have a negative (approximately) linear relationship positive means they have a positive (approximately) linear relationship Correlation is not slope. A slope of zero implies no correlation correlation Can estimate correlation with \\[ \\begin{align*} \\hat\\rho = \\frac{\\widehat{\\text{Cov}}(X,Y)}{\\sqrt{\\widehat{\\text{Var}}(X)\\widehat{\\text{Var}}(Y)}} = \\frac{\\sum_{i=1}^n(X_i - \\bar X)(Y_i - \\bar Y)}{\\sqrt{\\sum_{i=1}^n(X_i - \\bar X)^2\\sum_{i=1}^n(Y_i - \\bar Y)^2}} \\end{align*} \\] 1.3.9.1 Examples Code plot(insurance[,&#39;age&#39;], insurance$charges, ylab=&#39;Charges&#39;, xlab=&#39;Age&#39;, main=paste(&#39;Age&#39;, &#39;and&#39;, &#39;Charges&#39;) ) Code cor(insurance[,&#39;age&#39;], insurance$charges) ## [1] 0.2990082 1.3.9.2 Examples Dependent but uncorrelated Code par(mfrow=c(2,1)) X = rnorm(100) Y = X^2 plot(X, Y, main=&#39;Uncorrelated dependent no noise&#39;) abline(lm(Y ~ X)) cor(X,Y) ## [1] 0.1224623 Code X = rnorm(100) Y = X^2 + rnorm(100) plot(X, Y, main=&#39;Uncorrelated dependent with noise&#39;) abline(lm(Y ~ X)) Code cor(X,Y) ## [1] -0.1366219 1.3.10 Properties of variances of sums Derive the variance of this \\(\\text{Var}(X + Y) = \\mathrm{Var}(X) + \\mathrm{Var}(Y) + 2\\text{Cov}(X, Y)\\) 1.3.11 Law of total expectation The law of total expectation is relatively simple, but super handy. \\[ \\mathbb{E}\\{\\mathbb{E}(X \\mid Y)\\} = \\mathbb{E}X \\] If you are trying to take a mean of a complicated random variable, then you can condition on part of it first and then take the expectation of the part you conditioned on. Example: continue from last table Example: Use diagnosis and hippocampal volume above Example from Rice: 1.3.12 Law of total variance The law of total variance states that \\[ \\text{Var}(Y) = \\mathbb{E}\\text{Var}(Y \\mid X) + \\text{Var}\\{ \\mathbb{E}(Y \\mid X)\\}. \\] Example: continue from last table Example: Use diagnosis and hippocampal volume above 1.4 Parameters, estimates, and estimators 1.4.1 Objectives Talk about parameters, estimates, and estimators Talk about how to assess estimators by comparing their variance and bias 1.4.2 Example: healthy sleep Startsleeping.org For this example let’s look at the sleep questionnaire from the HCP What proportion of people get healthy sleep (assuming 7-9 hours). Code hcp = read.csv(&#39;../datasets/hcp/hcp.csv&#39;) hist(hcp$PSQI_AmtSleep, main=&#39;Nightly sleep&#39;, xlab=&#39;Hours&#39;) Code hcp$healthySleep = ifelse(hcp$PSQI_AmtSleep&lt;=9 &amp; hcp$PSQI_AmtSleep&gt;=7, 1, 0) 1.4.3 Statistics is a way to learn about the world from a data set All three statistical philosophies we will discuss view research questions as trying to learn about an unknown parameter. For now, let’s work with the question, “What is the proportion of people in the united states who get a healthy amount of sleep?” What is my parameter of interest (target parameter)? Descriptively – proportion of people who get a healthy amount of sleep Mathematically – call this value \\(p\\) What is my population of interest? Descriptively – The United States population Quantitatively two possible things Distribution defined by the model below in point 4. \\(\\text{Be}(p)\\) Unknown statistical distribution that gives rise to whether someone reports between 7-9 hours of sleep. What is a data point? An answer from an individual in the population to the survey question. Coded as 1/0 if they do/don’t get 7-9 hours of sleep. What model can I use to describe how I get a data point? Most obvious one is \\(X_i \\sim \\text{Be}(p)\\), where \\(p\\) is the parameter in point 1. 1.4.4 A random sample A random sample is a collection of independent random variables that represent potential data points. Let \\(X_i \\sim \\text{Be}(p)\\) for \\(i=1,\\ldots, n\\). Our assumption about the population \\(X_i\\) is drawn from connects the data to the parameter of interest. Given our data, we have a parameter and estimate of the parameter. What are they? 1.4.5 Estimates Note, an estimate is a function of the observed sample and it is nonrandom (Why is it non random?). We often use lowercase letters to make that clear \\[ \\bar x = n^{-1} \\sum_{i=1}^n x_i. \\] 1.4.6 Estimators An estimator is a function of a random sample. The goal (usually) is to estimate a parameter of interest (here, \\(p\\)). Let’s consider the estimator \\[ \\hat p = \\bar X = n^{-1} \\sum_{i=1}^n X_i, \\] which we know is pretty reasonable since \\(\\mathbb{E}\\bar X = p\\). We can study the properties of estimators to learn about how they behave. If we like an estimator we can compute an estimate using our sample. We can use features of our estimator to make probabilistic statements about what might happen if we repeat our study. Dataset-to-dataset variability This perspective is considered to be the Frequentist philosophy of Statistics. 1.4.6.1 Properties of estimators Some common metrics are Bias: let \\(p\\) denote our target parameter, bias is defined as \\[ \\mathbb{E}(\\hat p - p). \\] Variance: this is the same as for other random variables \\[ \\mathbb{E}(\\hat p - \\mathbb{E}\\hat p)^2 \\] Mean Squared Error: this combines variance and bias: \\[ \\mathbb{E}(\\hat p - p)^2 \\] Consistency: this describes what happens to the estimator as \\(n\\to\\infty\\) \\[ \\hat p \\to_P p \\] The arrow is convergence in probability. More on this later. Asymptotically unbiased: is a less strong statement of what happens to the estimator as \\(n\\to\\infty\\) \\[ \\mathbb{E}\\hat p \\to p \\] 1.4.6.2 Bias, variance, and MSE of the proportion estimator The bias of the proportion estimator (used to estimate the proportion of people who get enough sleep) is: \\[ \\mathbb{E}( \\hat p - p) = 0 \\] The variance of the estimator is \\[ \\begin{align*} \\text{Var}(\\hat p) &amp; = n^{-2} \\sum_{i=1}^n\\text{Var}(X_i) \\\\ &amp; = n^{-1} p(1-p) \\end{align*} \\] The MSE is the same as the variance since \\(\\hat p\\) is unbiased. We will come back to this example to construct confidence intervals later. 1.4.7 HCP: example of bias, variance, and MSE In HCP data Code # Show what Bias and Variance mean in NSDUH data using simulations nstudies = 100000 p = 0.6 n = 100 phats = rep(NA, nstudies) for(study in 1:nstudies){ # random sample x = rbinom(n = n, prob = p, size=1) # estimate phat phats[study] = mean(x) } # mean of phat across the simulations mean(phats) ## [1] 0.5998757 Code hist(phats) Code # variance of phat across the simulations var(phats) ## [1] 0.002404844 Code # what the variance should be equal to p * (1-p)/n ## [1] 0.0024 1.4.8 Parameters, Estimators, Estimates To reiterate: Parameter – Target unknown feature of a population (nonrandom) Estimate – Value computed from observed data to approximate the parameter (nonrandom) Estimator – A function of a random sample to approximate the parameter In statistics, probability is used to define and describe the behavior of estimators. Often, the distribution of an estimator is makes it too hard to find the bias, variance, and MSE of the estimator. In this case, we use simulations to estimate the bias, variance, and MSE of an estimator. Important concepts for this session: Simulations can be used to estimate the bias and variance when it is too hard to find mathematically. Sometimes, the parameter of interest is not distributional parameter. 1.4.9 Another example: multiplexed immunofluorescence (mIF) microscopy mIF imaging uses antibody markers to identify protein in tissue samples. The protein Beta-catenin is known to be higher in tumor cells. beta catenin image 1.4.10 mIF imaging in a statistical framework Suppose we want to ask the question, “What is the mean concentration of Beta-catenin in the cells from a given tissue sample?” What is my parameter of interest (target parameter)? Mean cellular concentration of Beta-catenin \\(\\mathbb{E}X_i\\) What is my population of interest? All possible cells from the given tumor (potentially)? All possible cells from similar tumors? What is a data point? A single cell What model can I use to describe how I get a data point? That’s a good question. Here is the histogram of the data Code bc = readRDS(&#39;../datasets/betaCatenin.rds&#39;) hist(bc, main=&#39;Beta Catenin Histogram&#39;, xlab=&#39;Marker count&#39;) + The Beta-catenin concentration across cells could be modeled with a Gamma distribution. 1.4.11 A Gamma model for Beta-catenin concentration Previously, we defined the parameter of interest \\(p\\) based on what we were interested in the sleep problem and it also happened to be the parameter of the Bernoulli distribution. In this example that is not the case. Let \\(X_i\\) denote a randomly drawn cell from the tissue image. Assume \\(X_i \\sim \\text{Gamma}(\\alpha, \\beta)\\). Let’s consider three parameters \\(\\mathbb{E}X_i = \\alpha/\\beta\\) \\(\\alpha\\) (shape parameter) \\(\\beta\\) (rate parameter) Let’s assess estimators for each of these parameters. 1.4.12 MxIF example: Estimators I used method of moments (which you’ll learn in another class) to obtain estimators for these parameters. The estimators are \\[ \\begin{align*} \\hat \\mu &amp; = \\bar X = n^{-1} \\sum_{i=1}^n X_i \\\\ \\tilde \\alpha &amp; = \\frac{\\bar X^2}{\\left(\\overline{X^2} - \\bar X^2\\right)} \\\\ \\tilde \\beta &amp; = \\frac{\\bar X}{\\left(\\overline{X^2} - \\bar X^2\\right)} \\end{align*} \\] \\(\\tilde \\alpha\\) and \\(\\tilde \\beta\\) are complicated functions of random variables involving ratios. It might be hard to find their bias. It will definitely be hard to find their variance. Instead, let’s use simulations to assess the bias, variance, and MSE of these estimators. 1.4.13 Concept of simulation study The bias, variance, and MSE are defined with respect to the distribution of the statistic across repeated samples of the data. If I can repeat the experiment in R multiple times, then I can see multiple random versions of the estimator. A simulation is an experiment to study what happens across experiments. 1.4.14 Simulation study Code set.seed(100) # number simulation nsim = 10000 # sample sizes ns = c(10, 25, 50, 100, 200, 500) # values of alpha to consider alphas = c(0.5, 5) # values of beta to consider betas = c(0.25, 3) # presults = data.frame(p=ps, biasmuHat = rep(NA, np), biassigmaSqHat=rep(NA, np), biassigmaSqHat2=rep(NA, np), # varmuHat=rep(NA, np), varsigmaSqHat=rep(NA, np), varsigmaSqHat2=rep(NA, np)) presults = expand.grid(alpha = alphas, beta=betas, n=ns) colNames = paste(rep(c(&#39;muHat&#39;, &#39;alphaTilde&#39;, &#39;betaTilde&#39;), each=3), rep(c(&#39;Bias&#39;, &#39;Variance&#39;, &#39;MSE&#39;), 3)) presults[, colNames ] = NA alphaind = 1; betaind = 2; nind = 3 # loops through the parameter values for(alphaind in 1:length(alphas) ){ for(betaind in 1:length(betas)){ # data generating distribution parameters (for the gamma distribution) alpha = alphas[alphaind] beta = betas[betaind] for(nind in 1:length(ns)){ # get n for this simulation setting n = ns[nind] cat(which(presults$n==n &amp; presults$alpha==alpha &amp; presults$beta == beta), &#39;\\t&#39;) # loops through the simulations # each simulation is one realization of the world results = data.frame(muHat = rep(NA, nsim), alphaTilde=rep(NA, nsim), betaTilde=rep(NA, nsim) ) for(sim in 1:nsim){ # sample a data set of size n from a random variable whose distribution is determined by alpha and beta x = rgamma(n, shape=alpha, rate=beta) # compute estimators muHat = mean(x) alphaTilde = muHat^2 / var(x) betaTilde = muHat / var(x) #sigmaSqHat = sum((x-mean(x))^2)/(length(x)-1) results[sim, c(&#39;muHat&#39;, &#39;alphaTilde&#39;, &#39;betaTilde&#39;) ] = c(muHat, alphaTilde, betaTilde) } # end of the nsim loop # saving the results for each value of p #presults[pind, c(&#39;biasmuHat&#39;, &#39;biassigmaSqHat&#39;, &#39;biasSigmaSqHat2&#39;)] = colMeans(results) - c(p, p*(1-p), p*(1-p)) #presults[pind, c(&#39;varmuHat&#39;, &#39;varsigmaSqHat&#39;, &#39;varSigmaSqHat2&#39;)] = diag(var(results)) # Bias variance MSE for muHat presults[ which(presults$n==n &amp; presults$alpha==alpha &amp; presults$beta == beta), c(&#39;muHat Bias&#39;, &#39;muHat Variance&#39;, &#39;muHat MSE&#39;)] = c(mean(results$muHat) - alpha/beta, var(results$muHat), (mean(results$muHat) - alpha/beta)^2 + var(results$muHat) ) presults[ which(presults$n==n &amp; presults$alpha==alpha &amp; presults$beta == beta), c(&#39;alphaTilde Bias&#39;, &#39;alphaTilde Variance&#39;, &#39;alphaTilde MSE&#39;)] = c(mean(results$alphaTilde) - alpha, var(results$alphaTilde), (mean(results$alphaTilde) - alpha)^2 + var(results$alphaTilde) ) presults[ which(presults$n==n &amp; presults$alpha==alpha &amp; presults$beta == beta), c(&#39;betaTilde Bias&#39;, &#39;betaTilde Variance&#39;, &#39;betaTilde MSE&#39;)] = c(mean(results$betaTilde) - beta, var(results$betaTilde), (mean(results$betaTilde) - beta)^2 + var(results$betaTilde) ) } # loop through ns } # loop through the betas } # loop through the alphas ## 1 5 9 13 17 21 3 7 11 15 19 23 2 6 10 14 18 22 4 8 12 16 20 24 Code subres = presults[ presults$alpha==0.5 &amp; presults$beta ==0.25,] layout(matrix(1:6, nrow=2, byrow=TRUE)) # Bias plots plot(subres$n, subres[, &#39;muHat Bias&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of muHat&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;alphaTilde Bias&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of alphaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;betaTilde Bias&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of betaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;muHat Variance&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Variance&#39;, main=&#39;Variance of muHat&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;alphaTilde Variance&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Variance&#39;, main=&#39;Variance of alphaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;betaTilde Variance&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Variance&#39;, main=&#39;Variance of betaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) Code subres = presults[ presults$alpha==5 &amp; presults$beta ==3,] layout(matrix(1:6, nrow=2, byrow=TRUE)) # Bias plots plot(subres$n, subres[, &#39;muHat Bias&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of muHat&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;alphaTilde Bias&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of alphaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;betaTilde Bias&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of betaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;muHat Variance&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Variance&#39;, main=&#39;Variance of muHat&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;alphaTilde Variance&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Variance&#39;, main=&#39;Variance of alphaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;betaTilde Variance&#39;], xlab=&#39;Sample size&#39;, ylab=&#39;Variance&#39;, main=&#39;Variance of betaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) Percent bias instead of raw bias Code subres = presults[ presults$alpha==0.5 &amp; presults$beta ==0.25,] layout(matrix(1:6, nrow=2, byrow=TRUE)) # Bias plots plot(subres$n, subres[, &#39;muHat Bias&#39;]/(subres[,&#39;alpha&#39;]/subres[,&#39;beta&#39;]), xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Percent bias of muHat&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;alphaTilde Bias&#39;]/subres[,&#39;alpha&#39;]*100, xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Percent bias of alphaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, subres[, &#39;betaTilde Bias&#39;]/subres[,&#39;beta&#39;]*100, xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Percent bias of betaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, sqrt(subres[, &#39;muHat Variance&#39;])/(subres[,&#39;alpha&#39;]/subres[,&#39;beta&#39;])*100, xlab=&#39;Sample size&#39;, ylab=&#39;Percentage&#39;, main=&#39;Percent SE of muHat&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, sqrt(subres[, &#39;alphaTilde Variance&#39;])/subres[,&#39;alpha&#39;]*100, xlab=&#39;Sample size&#39;, ylab=&#39;Percentage&#39;, main=&#39;percent SE of alphaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) plot(subres$n, sqrt(subres[, &#39;betaTilde Variance&#39;])/subres[,&#39;beta&#39;]*100, xlab=&#39;Sample size&#39;, ylab=&#39;Percentage&#39;, main=&#39;percent SE of betaTilde&#39;, type=&#39;b&#39;) abline(h=0, lty=2, lwd=2) 1.4.15 Assessing estimators in the homework I left more interesting problems for you to do in the homework. There, you will compare two estimators for the same parameter, and pick which one you think is better. 1.4.16 MxIF example: Estimate The estimates in the real data are \\(\\hat\\mu=\\)3985.4, \\(\\tilde\\alpha=\\)8.7, and \\(\\tilde\\beta=\\)0.002. Code bc = readRDS(&#39;../datasets/betaCatenin.rds&#39;) alphaTilde = mean(bc)^2/var(bc) betaTilde = mean(bc)/var(bc) x = seq(from=min(bc), to=max(bc), length.out=1000) y = dgamma(x, shape=alphaTilde, rate=betaTilde) hist(bc, main=&#39;Beta Catenin Histogram&#39;, freq=FALSE, xlab=&#39;Marker count&#39;, ylim=range(y)) points(x, y, type=&#39;l&#39;) "],["law-of-large-numbers-and-central-limit-theorem.html", "2 Law of Large Numbers and Central Limit Theorem 2.1 Law of Large Numbers 2.2 Central Limit Theorems (CLTs)", " 2 Law of Large Numbers and Central Limit Theorem In this section we will: Introduce the Law of Large Numbers (LLN) We will use simulations to demonstrate the LLN Simulations -&gt; Math Math -&gt; Simulations Then we will create a simulation where the LLN doesn’t work 2.0.1 Conceptual overview This is to illustrate the law of large numbers using some example data. The law of large numbers describes what happens to the empirical average as it is taken over increasing sample sizes. Code # read in student names # each student is a researcher students = read.csv(&#39;../../unshared/students2023.csv&#39;) # read in data puf = readRDS(&#39;../datasets/nsduh/puf.rds&#39;) # ever tried cigarettes indicator triedCigs = puf$cigflag # make it a Bernoulli random variable triedCigs = ifelse(triedCigs==&#39;yes&#39;, 1, 0) ns = c(10, 50, 100, 200, 300, 400, 500) for(n in ns){ # Each person in the class is performing a study of smoking studies = lapply(c(students$First.Name, &#39;Kun&#39;, &#39;Simon&#39;), function(student) sample(triedCigs, size=n)) names(studies) = students$First.Name # get the mean for each person&#39;s study studyMeans = sapply(studies, mean) # histogram of the study means hist(studyMeans, xlim=c(0,1), breaks=10, main=paste0(&#39;n=&#39;, n)) abline(v=mean(triedCigs)) } Code #hist(sqrt(n)*(studyMeans-mean(triedCigs)), xlim=c(0,1), breaks=10, main=paste0(&#39;n=&#39;, n)) 2.1 Law of Large Numbers The LLN is a tool we can use to say that the average of a sample is close to its expected value (and get’s closer with larger sample sizes). I wouldn’t consider an estimator that doesn’t satisfy the LLN 2.1.1 Simulations -&gt; Math: illustrating the LLN with simulations 2.1.1.1 Initial simulation without convergence definition First, let’s choose a distribution. Then, let’s initialize empty vectors, x and means. For n in 1:maxn, Draw a sample from our distribution and add it to x, x&lt;-c(x,&lt;new random sample&gt;). Compute the mean of x and save it in another vector means[n]&lt;- mean(x). Plot the vector means. Code # distribution we&#39;re sampling from p = mean(triedCigs) RVfunc = function(n) rbinom(n, size=1, prob=p) # x is the observed sample x = c() # this is the mean of the observed sample means = c() # maximum sample size to get to maxn=5000 # for loop through samples for(n in 1:maxn){ xn = RVfunc(1) x = c(x, xn) means = c(means, mean(x)) } plot(1:maxn, means, type=&#39;l&#39;, xlab=&#39;&#39;, ylab=&#39;&#39;, ylim=c(0,1)) # what is this converging to? abline(h=p, lty=2) What do you notice about this plot? Let’s describe mathematically what we did. \\(X_i \\sim\\), for \\(n=1,2, \\ldots\\) \\(\\bar X_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\) \\(\\bar X_n \\to\\) what? What does this little arrow mean? 2.1.1.2 Convergence of random variables Definition: \\(Y_n\\) converges to \\(Y\\) in probability if for all \\(\\epsilon&gt;0\\), \\(\\lim_{n\\to\\infty}\\mathbb{P}(\\lvert Y_n - Y \\rvert \\le \\epsilon) = 1\\) as \\(n\\to\\infty\\). “Eventually, every world will have \\(Y_n\\) within \\(\\epsilon\\) of \\(Y\\).” “The probability that \\(Y_n\\) is within \\(\\epsilon\\) of \\(Y\\) goes to 1.” Definition: \\(Y_n\\) converges almost surely to \\(Y\\) if \\(\\mathbb{P}(\\lim_{n\\to \\infty}\\lvert Y_n - Y \\rvert =0) = 1\\) as \\(n\\to\\infty\\). “There is not a world where \\(Y_n\\) does not converge to \\(Y\\).” “The probability \\(Y_n\\) does not converge to \\(Y\\) is zero.” 2.1.2 Math -&gt; Simulations: adding convergence definition How do we incorporate one of these convergence definitions into our simulations? Someone in the class give epsilon&gt;0. For each sim in 1:nsim Then, let’s initialize empty vector, x and empty array means=matrix(NA, nrow=nsim, ncol=maxn). For n in 1:maxn, Draw a sample from our distribution and add it to x, x&lt;-c(x,&lt;new random sample&gt;). Compute the mean of x and save it in another vector means[sim,n]&lt;- mean(x). Use means to compute \\(\\mathbb{P}(\\lvert \\bar X_n - \\mathbb{E}X_i \\rvert &lt; \\epsilon)\\). Plot \\(\\mathbb{P}(\\lvert \\bar X_n - \\mathbb{E}X_i \\rvert &lt; \\epsilon)\\) as a function of n. Code epsilon = 0.02 nsim = 500 # distribution we&#39;re sampling from p = mean(triedCigs) RVfunc = function(n) rbinom(n, size=1, prob=p) # maximum sample size to get to maxn=10000 # this is the mean of the observed sample meansout = matrix(NA, nrow=nsim, ncol=maxn) for(sim in 1:nsim){ cat(sim, &#39;\\t&#39;) # for loop through samples # x is the observed sample x = c() means = c() x = RVfunc(maxn) meansout[sim,] = cumsum(x)/1:maxn # for(n in 1:maxn){ # xn = RVfunc(1) # x = c(x, xn) # means = c(means, mean(x)) # } # meansout[sim,] = means } ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 Code P_XbarMinusp = colMeans(abs(meansout - p) &lt; epsilon) plot(1:maxn, P_XbarMinusp, type=&#39;l&#39;, xlab=&#39;&#39;, ylab=&#39;&#39;, ylim=c(0,1)) Code # plot(1:maxn, means, type=&#39;l&#39;, xlab=&#39;&#39;, ylab=&#39;&#39;) # what is this converging to? # abline(h=, lty=2) 2.1.3 Formal definition of LLN 2.1.3.1 IID random variables IID stands for independent and identically distributed. For a sample \\(X_i, \\ldots, X_n\\): Independence means that their probability distributions factor Identical means \\(X_i \\sim F_x\\) (They all have the same distribution function). 2.1.3.2 Law of large numbers (Weak law) Weak LLN is about convergence in probability Theorem (Durrett, pg. 61): Let \\(X_1, X_2, \\ldots\\), be iid random variables with \\(\\mathbb{E}X_i = \\mu\\) and \\(\\mathbb{E}\\lvert X_i \\rvert &lt;\\infty\\). If \\(S_n = X_1 + \\ldots + X_n\\), then as \\(n\\to \\infty\\), \\[ S_n/n \\to_p \\mu. \\] Better weak laws can allow some dependence among the observations and usually just require that \\(\\mathbb{E}X_i^2 &lt; \\infty\\) (a slightly stronger assumption than \\(\\mathbb{E}\\lvert X_i \\rvert &lt;\\infty\\)). Check out google if you’re interested. The strong law is about almost sure convergence and doesn’t require any further assumptions. Intuition about LLN. What is the mean (expected value) of \\(S_n/n\\)? What is the variance of \\(S_n/n\\)? Mean Variance 2.1.3.3 How do we use theorems in research? Demonstrate that assumptions of theorem are satisfied for our case. Draw conclusion about our estimator. What if assumptions are violated? The average may or may not converge There are more precise statements that are necessary and sufficient. 2.1.4 Breaking the LLN: Cauchy distribution What is a Cauchy distribution (ratio of normal random variables; t RV on 1 DoF) The LLN can break if \\(\\mathbb{E}\\lvert X_i \\rvert\\) doesn’t exist (is infinite). What does this mean? It does not have any moments (\\(\\mathbb{E}X_i = \\infty\\)). Let’s use the simulations we wrote above to show that the mean of Cauchy random variables does not converge. Code epsilon = 0.01 nsim = 500 # Changed this to a Cauchy random variable! RVfunc = function(n) rcauchy(n) # maximum sample size to get to maxn=5000 # this is the mean of the observed sample meansout = matrix(NA, nrow=nsim, ncol=maxn) for(sim in 1:nsim){ cat(sim, &#39;\\t&#39;) # for loop through samples # x is the observed sample x = RVfunc(maxn) means = cumsum(x)/1:maxn meansout[sim,] = means } ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 Code P_XbarMinusp = colMeans(abs(meansout)&lt;epsilon) plot(1:maxn, P_XbarMinusp, type=&#39;l&#39;, xlab=&#39;&#39;, ylab=&#39;&#39;, ylim=c(0,1)) Code plot(1:maxn, means, type=&#39;l&#39;, xlab=&#39;n&#39;, ylab=&#39;Xbar&#39;) Note: we’ve already taken advantage of the LLN in the class. Does anyone know how? 2.2 Central Limit Theorems (CLTs) Today we’ll consider another theorem about a different type of convergence for random variables. The goals for today are: Illustrate the CLT using Simulations -&gt; Math Illustrate the CLT using the Math -&gt; Simulation approach with the Bernoulli distribution 2.2.1 Preliminary: Normalizing sums of random variables The CLT is about things that look like this: \\(X_i \\sim F\\) (IID arbitrary distribution) with \\(\\mathbb{E}X_i = \\mu\\) and \\(\\text{Var}(X_i) = \\sigma^2\\). \\(\\bar X = n^{-1} \\sum_{i=1}^n X_i\\) \\(Z = \\sqrt{n} (\\bar X - \\mu)/\\sigma\\) 2.2.2 Preliminary: The normal distribution Link Things about the normal distribution: Standard normal \\(Z\\sim N(0,1)\\) often denoted with a \\(Z\\). PDF often denoted by \\(\\phi(z)\\). CDF often denoted by \\(\\Phi(z)\\). For \\(Y \\sim N(\\mu, \\sigma^2)\\), \\((Y-\\mu)/\\sigma \\sim N(0, 1)\\) (often called Z-normalization). \\(\\mathbb{P}(\\lvert Z \\rvert\\le 1.96) = \\Phi(1.96) - \\Phi(-1.96) \\approx 0.95\\). \\(\\mathbb{P}( Z \\le 1.64) = \\Phi(1.64) \\approx 0.95\\). 2.2.3 Conceptual overview This is to illustrate the CLT numbers using some example data. Code # read in student names # each student is a researcher students = read.csv(&#39;../../unshared/students2023.csv&#39;) # read in data puf = readRDS(&#39;../datasets/nsduh/puf.rds&#39;) # ever tried cigarettes indicator triedCigs = puf$cigflag # make it a Bernoulli random variable triedCigs = ifelse(triedCigs==&#39;yes&#39;, 1, 0) mu = mean(triedCigs) sigma = sqrt(var(triedCigs)) ns = c(5, 10, 50, 100, 200, 300, 400, 500) students = rep(c(students$First.Name, &#39;Kun&#39;, &#39;Simon&#39;), 100) layout(matrix(1:8, nrow=2, byrow=TRUE)) for(n in ns){ # Each person in the class is performing a study of smoking studies = lapply(students, function(student) sample(triedCigs, size=n)) names(studies) = students # get the mean for each person&#39;s study studyMeans = sapply(studies, mean) stdMeans = sqrt(n)*(studyMeans - mu)/sigma # histogram of the study means hist(stdMeans, xlim = c(-3,3), breaks=10, main=paste0(&#39;n=&#39;, n)) } 2.2.4 Preliminary: Convergence in distribution Definition: A random variable \\(Y_n\\) with distribution function \\(F_n(y)\\) is said to converge in distribution to a limit \\(Y\\) with distribution function \\(F(y)\\) if, for all \\(y\\) that are continuity points of \\(F\\), \\(F_n(y) \\to F(y)\\). I’ll denote it \\(Y_n\\to_D Y\\). Let’s unpack the notation \\(F_n(y) \\to F(y)\\). This means for any given \\(y\\) and \\(\\epsilon&gt;0\\) there exists \\(N\\) such that for all \\(n\\ge N\\), \\[ \\lvert F_n(y) - F(y)\\rvert &lt; \\epsilon. \\] In other words, the distance between the distributions goes to zero as \\(n\\) gets larger. 2.2.5 The Central Limit Theorem The Central Limit Theorem (Durrett, pg. 124): Let \\(X_1, X_2, \\ldots\\) be iid with \\(\\mathbb{E}X_i = \\mu\\) and \\(\\text{Var}(X_i) = \\sigma^2 \\in (0, \\infty)\\). If \\(\\bar X_n = n^{-1} \\sum_{i=1}^n X_i\\), then \\[ n^{1/2}(\\bar X_n - \\mu)/\\sigma \\to_D X, \\] where \\(X \\sim N(0,1)\\). Comments: We need the variance to be finite (stronger assumptions than LLN) 2.2.6 The Lindeberg-Feller Theorem The Lindeberg-Feller Theorem (Wikipedia): Let \\(X_i\\) be independent random variables with \\(\\mathbb{E}X_i = \\mu _i\\) and variances \\(\\text{Var}(X_i) = \\sigma^2_i \\in (0, \\infty)\\). Let \\(\\sigma^2_n = \\sum_{i=1}^n \\sigma^2_i\\). If this sequence of random variables satisfies Lindeberg’s condition \\[ \\lim_{n\\to\\infty}\\sigma^{-2}_n \\sum_{i=1}^n \\mathbb{E}\\left\\{(X_i-\\mu_i)^2 I(\\vert X_i - \\mu_i\\rvert&gt;\\epsilon \\sigma_n) \\right\\} = 0, \\] for all \\(\\epsilon&gt;0\\). Then \\[ Z_n = \\sum_{i=1}^n (X_i-\\mu_i)/\\sigma_n \\to_D Z, \\] where \\(Z\\sim N(0,1)\\). Comments: Relaxes iid assumption to just independence! CLTs are well studied, there are other ones for some what dependent variables. Will review CLT statement Will look at what it means for Bernoulli example and using simulations 2.2.7 Example of CLT with Bernoulli distribution The Bernoulli is appealing because we can assess the CLT mathematically. Sum of Bernoulli RV is Binomial. Using the CLT, for samples \\(X_1, \\ldots, X_n\\), from this distribution the standardized mean is \\[ \\sqrt{n}\\frac{(\\bar X_n -p)}{p(1-p)} \\sim N(0,1) \\text{ (approximately)} \\] \\(\\mathbb{P}(\\sqrt{n} (\\bar X - p)/\\sqrt{p(1-p)} \\le z) = \\mathbb{P}\\left(n\\bar X \\le \\left(np(1-p)\\right)^{1/2}\\times z + np \\right) \\to \\mathbb{P}(Z\\le z)\\), where \\(Z\\sim N(0,1)\\) So how do we evaluate this: Pick a value for \\(p\\). Choose a vector for \\(n\\) and \\(z\\). Compare the CDFs by the sample size. Note: We don’t even need to run simulations because we can do it using the CDFs in R. Code ns = 1:5000 p = 0.01 z = seq(-2, 2, length.out=1000) probDiffs = rep(NA, length(ns)) for(n in ns){ probDiffs[n] = max(abs( pbinom(sqrt(n*p*(1-p))*z + n*p, size = n, prob=p) - pnorm(z) ) ) } plot(ns, probDiffs, xlab=&#39;Sample size&#39;, ylab=&#39;Distribution error&#39;, main=&#39;CLT for Bernoulli&#39;, type=&#39;l&#39;) abline(h=0, lty=2) Code ns = 1:5000 p = 0.01 z = 1.64 probDiffs = rep(NA, length(ns)) for(n in ns){ probDiffs[n] = abs( pbinom(sqrt(n*p*(1-p))*z + n*p, size = n, prob=p) - pnorm(z) ) } plot(ns, probDiffs, xlab=&#39;Sample size&#39;, ylab=&#39;Distribution error&#39;, main=&#39;CLT for Bernoulli&#39;, type=&#39;l&#39;) abline(h=0, lty=2) 2.2.8 QQ-plot! 2.2.8.1 Binomial proportion: Another look using simulations Code ns = seq(5, 100, by=10) layout(matrix(1:10, ncol=5, byrow=TRUE)) p = 0.75 for(n in ns){ means = replicate(10000, # compute mean 1000 times sqrt(n) * (mean(rbinom(n, 1, p))-p) / sqrt(p*(1-p)) ) hist(means,main=paste(&#39;n =&#39;, n), probability = TRUE, ylab=&#39;&#39;, xlab=&#39;&#39; ) # draw standard normal density x = qnorm(ppoints(1000)) points(x, dnorm(x), type=&#39;l&#39;) } Code layout(matrix(1:10, ncol=5, byrow=TRUE)) for(n in ns){ means = replicate(10000, # compute mean 1000 times sqrt(n)*(mean(rbinom(n, 1, p))-p)/sqrt(p*(1-p)) ) qqnorm(scale(means), main=paste(&#39;n =&#39;, n), ylab=&#39;Means quantiles&#39;, xlab=&#39;Normal quantiles&#39; ) abline(a=0, b=1) } 2.2.9 Comment about dependence in the CLT For a bunch of RVs with zero mean and nonzero covariance \\[ \\begin{aligned} \\text{Var}(n^{-1/2}\\bar X_n) &amp; = n^{-1}\\text{Cov}(S_n, S_n) \\\\ &amp; = \\sum_{i,j}^n \\text{Cov}(X_i, X_j) \\\\ &amp; = n^{-1}\\sum_{i=1}^n \\text{Var}(X_i) + n^{-1}\\sum_{i\\ne j} \\text{Cov}(X_j, X_k)\\\\ &amp; = \\text{Var}(X_i) + (n-1)\\text{Cov}(X_j, X_k)\\\\ &amp;\\text{(if Var and Cov are the same for all RVs)} \\end{aligned} \\] Comments: The first term converges under CLT assumptions. The second term has \\(n(n-1)\\) terms. We need the covariance terms to get “small enough” for the CLT to work. For example, by things that are “far away” having small covariance. 2.2.10 Conclusions of CLT The CLT allows us to make approximate probability statements for things that can be expressed as sums. This is handy when we don’t know the distribution of things. Some form of independence is necessary. 2.2.11 Take home points of LLN and CLT LLN is about the convergence of the mean estimator to a constant. CLT is about the convergence of the mean estimator times \\(\\sqrt{n}\\) to a normal distribution. CLT is used a lot in statistics to make approximate probability statements. 2.2.12 Example: HCP data set A brain. Human Connectome Project data Study designed to understand how regions of the brain are interconnected Code hcp = read.csv(&#39;../datasets/hcp/hcp.csv&#39;) corr = cor(hcp$FS_Total_GM_Vol, hcp$FS_TotCort_GM_Vol, use = &#39;pairwise.complete.obs&#39;) plot(hcp$FS_Total_GM_Vol, hcp$FS_TotCort_GM_Vol, xlab=&#39;Gray Matter Vol&#39;, ylab=&#39;Cortical GM Vol&#39;, main=&#39;Cortical GM Volume vs total GM vol&#39;) legend(&#39;topleft&#39;, legend=paste(&#39;Cor =&#39;, round(corr, 2) )) abline(lm(FS_TotCort_GM_Vol ~ FS_Total_GM_Vol, data=hcp)) Code corr = cor(hcp$FS_SubCort_GM_Vol, hcp$FS_TotCort_GM_Vol, use = &#39;pairwise.complete.obs&#39;) plot(hcp$FS_SubCort_GM_Vol, hcp$FS_TotCort_GM_Vol, xlab=&#39;Subcortical Vol&#39;, ylab=&#39;Cortical GM Vol&#39;, main=&#39;Cortical GM Volume vs Subcortical GM vol&#39;) legend(&#39;topleft&#39;, legend=paste(&#39;Cor =&#39;, round(corr, 2) )) Code #abline(lm(FS_TotCort_GM_Vol ~ FS_Total_GM_Vol, data=hcp)) Code hist(hcp$PSQI_Score) Code corr= cor(hcp$PSQI_Score, hcp$FS_TotCort_GM_Vol, use = &#39;pairwise.complete.obs&#39;) # compute correlation manually PSQI_Score = hcp$PSQI_Score[!is.na(hcp$PSQI_Score) &amp; !is.na(hcp$FS_TotCort_GM_Vol)] TotCorGMVol = hcp$FS_TotCort_GM_Vol[!is.na(hcp$FS_TotCort_GM_Vol) &amp; !is.na(hcp$PSQI_Score)] corr ## [1] -0.09299307 Code cov(PSQI_Score, TotCorGMVol)/sqrt(var(PSQI_Score)*var(TotCorGMVol)) ## [1] -0.09299307 Code sum( (PSQI_Score - mean(PSQI_Score)) *(TotCorGMVol - mean(TotCorGMVol)) ) /sqrt(sum( (PSQI_Score - mean(PSQI_Score))^2) * sum( (TotCorGMVol - mean(TotCorGMVol))^2)) ## [1] -0.09299307 Code plot(hcp$PSQI_Score, hcp$FS_TotCort_GM_Vol, xlab=&#39;PSQI scpre&#39;, ylab=&#39;Cortical GM Vol&#39;, main=&#39;Cortical GM Volume vs PSQI score&#39;) legend(&#39;topleft&#39;, legend=paste(&#39;Cor =&#39;, round(corr, 2) )) abline(lm(FS_TotCort_GM_Vol ~ PSQI_Score, data=hcp)) 2.2.13 Simulated data Code set.seed(100) # number of simulations per n and rho nsim = 2 # sample sizes ns = c(100) # correlation rhos = c(0.1) resultsTab = expand.grid(n=ns, rho=rhos) resultsTab$rhoBias = NA # each column is a draw of x and y for(rhoind in 1:length(rhos)){ rho = rhos[rhoind] Sigma = matrix(c(1, rho, rho, 1), nrow=2) sqrtSigma = svd(Sigma) sqrtSigma = sqrtSigma$u %*% diag(sqrt(sqrtSigma$d)) for(nind in 1:length(ns)){ n = ns[nind] # NEED TO DO SOMETHING HERE # need a vector to store the correlation values in simresults = rep(NA, nsim) for(sim in 1:nsim){ xy = tcrossprod(matrix(rnorm(n*2), ncol=2), sqrtSigma) # YOU NEED TO EDIT THE CODE HERE simresults[sim] = cor(xy[,1], xy[,2]) } # AND SOMETHING ELSE HERE (compute bias and assign in resultsTab) } } "],["confidence-intervals.html", "3 Confidence intervals 3.1 Recap on bias assessment 3.2 Confidence intervals for a mean 3.3 Computing confidence intervals 3.4 T- confidence interval 3.5 Evaluating confidence intervals 3.6 Evaluating confidence intervals under assumption violations 3.7 Assumption violations with T-interval 3.8 Confidence intervals for binomial proportions 3.9 Extra stuff", " 3 Confidence intervals 3.1 Recap on bias assessment Let’s do some more practice on computing bias using simulations and analytically. Consider the NSDUH data where the probability of the event is small. E.g. few people in the population have used PCP Code set.seed(555) puf = readRDS(&#39;../datasets/nsduh/puf.rds&#39;) pcptab = table( puf$pcpflag) pcptab/sum(pcptab) ## ## no yes ## 0.98537708 0.01462292 Code n = 50 # all &quot;no&quot;s pcpsamp = sample(puf$pcpflag, size = n) pcpsamp ## [1] no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no ## [34] no no no no no no no no no no no no no no no no no ## Levels: no yes In cases like this, sometimes people recommend using a modified estimator of \\(p\\), \\[ \\tilde p = \\frac{\\sum_{i=1}^n X_i + 1/2}{n + 1}, \\] which adds 1/2 observation to the “yes” category and 1/2 observation to the “no” category. What is expected value of \\(\\tilde p\\)? Plot the bias of \\(\\tilde p\\). Code n = 1:200 ps = c(0.01, 0.1, 0.25, 0.45) for(p in ps){ ptildeBias = (n * p + 0.5)/(n+1) - p # remove y-axis limits to rescale # divide by p for percent bias plot(n, ptildeBias/p, xlab=&#39;n&#39;, ylab=&#39;Bias(ptilde)&#39;, type=&#39;l&#39;, main=paste0(&#39;p=&#39;,p) ) abline(h=0) } We can also run simulations to assess the bias and the curves should agree with the results that we found in the other plots. Code nsim = 10000 n = 1:200 ns = c(10, 25, 50, 100, 200) ps = c(0.01, 0.1, 0.25, 0.45) for(p in ps){ # sample data for each sample size samps = replicate(nsim, {(rbinom(length(ns), size = ns, p) + 1/2)/(ns+1)} ) # take mean across simulations simBias = rowMeans(samps) - p ptildeBias = (n * p + 0.5)/(n+1) - p # divide by p for percent bias plot(n, ptildeBias/p, xlab=&#39;n&#39;, ylab=&#39;Bias(ptilde)&#39;, type=&#39;l&#39;, main=paste0(&#39;p=&#39;,p) ) points(ns, simBias/p, type=&#39;b&#39;) abline(h=0) } 3.2 Confidence intervals for a mean Today we will: Introduce a confidence interval for normally distributed data We will use spinal cord imaging to study these confidence intervals We will run a simulation to understand what the confidence interval means about dataset-to-dataset variability 3.2.1 Multiple sclerosis in the spinal cord Seth Smith’s research team is developing advanced spinal cord magnetic resonance imaging sequences to study multiple sclerosis (MS). These new sequences are making it possible to study the spinal cord in more detail through development and aging Today our research question is What is the cross-sectional area of the C3 segment of the spinal cord? 3.2.1.1 Spinal cord anatomy The cord section we are looking at is cervical section C3 (near the top). Damage here affects a large portion of the body. 3.2.1.2 Seth’s interest in the spinal cord MS is a progressive disease associated with demyelination of neurons (reduces signaling efficiency) that has significant detriment on many aspects of daily life, with motor symptoms being the most common. MRI has almost exclusively focused on the brain in MS and associated MRI-derived brain lesion measures with severity of MS symptoms Seth pointed out to the MS community that there are lesions in the spinal cord that scientists haven’t paid as much attention to. 3.2.1.3 Characterization of the C3 cross-sectional area What random variable models might be appropriate for these data? Code load(&#39;../datasets/smith_cervical_sc/tpmf.rdata&#39;) cex=1.5 par(mgp=c(1.7,.7,0), lwd=1.5, lend=2, cex.lab=0.8*cex, cex.axis=0.8*cex, cex.main=1*cex, mfrow=c(1,1), mar=c(2.8,2.8,1.8,.2), bty=&#39;l&#39;, oma=c(0,0,2,0)) # histogram of C3 CSA hist(mf$`C3 CSA`, main=&#39;C3 CSA&#39;, xlab=&#39;C3 CSA&#39;, freq=F) lines(seq(min(mf$`C3 CSA`), max(mf$`C3 CSA`), length.out=200), dnorm(seq(min(mf$`C3 CSA`), max(mf$`C3 CSA`), length.out=200), mean = mean(mf$`C3 CSA`), sd = sd(mf$`C3 CSA`))) What is a good model for these data? 3.2.1.4 CIs conceptually The concept of a CI highlights the distinction between a parameter, estimate, and estimator. What is the parameter? What is an estimate of the parameter? What is an estimator of the parameter, notationally? The concept of an estimator allows us to make probabilistic statements about the procedures we execute in our dataset. 3.2.2 Confidence interval definition Confidence intervals are an interval obtained from a sample that contains the true value of the parameter with a given probability. \\[ P\\{L(X_1, \\ldots, X_n) \\le p &lt; U(X_1, \\ldots, X_n) \\} = 1-\\alpha, \\] for a given value \\(\\alpha \\in (0,1)\\). Note what things are random here (the end points). The parameter is fixed. 3.2.3 Known variance confidence interval for the mean Let’s assume our spinal cord data \\(X_1, \\ldots X_n \\sim N(\\mu, \\sigma^2)\\) are IID and normally distributed. The empirical mean is an estimator for this value \\[ \\hat\\mu = n^{-1}\\sum_{i=1} X_i. \\] Let’s (unrealistically) assume that \\(\\sigma^2\\) is known. 3.2.3.1 The interval derivation The sum of IID normals is normal \\(N(\\mu, \\sigma^2/n)\\). This is exact (not an approximation). What is the distribution of \\(\\sqrt{n}(\\hat\\mu - \\mu)/\\sigma\\)? We can construct an \\(\\alpha\\) probability confidence interval for \\(\\mu\\) using this fact. \\[ \\begin{align*} \\mathbb{P}(z_{\\alpha/2} &lt; Z &lt; z_{1-\\alpha/2} ) &amp; = \\Phi(z_{1-\\alpha/2}) - \\Phi(z_{\\alpha/2} ) \\\\ &amp; = 1-\\alpha/2 - \\alpha/2\\\\ &amp;= 1-\\alpha \\end{align*} \\] So we can create the interval \\[ \\begin{align*} \\mathbb{P}(z_{\\alpha/2} &lt; Z &lt; z_{1-\\alpha/2} ) &amp; = \\mathbb{P}(z_{\\alpha/2} &lt; \\sqrt{n}(\\hat\\mu - \\mu)/\\sigma &lt; z_{1-\\alpha/2} ) \\end{align*} \\] 3.3 Computing confidence intervals Recap of constructing normal confidence interval Computing the confidence interval in the spinal cord data 3.3.1 Constructing the confidence interval in the Spinal cord data set Code x = mf$`C3 CSA` alpha = 0.01 # get n n = length(x) # get the mean muHat = mean(x) # get the sd stdev = sqrt(var(x)) # sd(x) # get z_alpha/2 and z_(1-alpha/2) qnorm(1-alpha/2) ## [1] 2.575829 Code zalpha = qnorm(1- alpha/2) # construct the interval interval = c(muHat - zalpha * stdev /sqrt(n), muHat + zalpha * stdev /sqrt(n) ) hist(mf$`C3 CSA`, main=&#39;C3 CSA&#39;, xlab=&#39;C3 CSA&#39;, freq=F) lines(seq(min(mf$`C3 CSA`), max(mf$`C3 CSA`), length.out=200), dnorm(seq(min(mf$`C3 CSA`), max(mf$`C3 CSA`), length.out=200), mean = mean(mf$`C3 CSA`), sd = sd(mf$`C3 CSA`))) abline(v=interval, lty=2, lwd=2) Code # What is the interpretation of this interval The mean in my data set, \\(\\bar X_n\\), lies within this interval with probability 1-alpha. This interval contains the true mean parameter with probability 1-alpha. The procedure we used to create this interval captures the mean parameter 1-alpha% of the time. Across a large number of samples, approximately (1-alpha)% of the intervals will contain the true value of the parameter. 3.3.2 Dataset-to-dataset variability Code mu = 1 sigma = 0.8 n = 500 nsim = 100 alpha = 0.05 CIs = data.frame(mean=rep(NA, nsim), lower=rep(NA, nsim), upper=rep(NA, nsim)) for(sim in 1:nsim){ # draw a random sample X = rnorm(n, mean=mu, sd=sigma) stdev = sd(X) # construct the confidence interval CIs[sim, ] = c(mean(X), mean(X) + c(-1,1)*qnorm(1-alpha/2)*stdev/sqrt(n)) } CIs$gotcha = ifelse(CIs$lower&lt;=mu &amp; CIs$upper&gt;=mu, 1, 2) # range(c(CIs$lower, CIs$upper)) plot(1:nsim, CIs$mean, pch=19, ylim = c(0,2), main=paste(nsim, &#39;experiments&#39;), col=CIs$gotcha ) segments(x0=1:nsim, y0=CIs$lower, y1=CIs$upper, col=CIs$gotcha) abline(h=mu, lty=2 ) 3.3.3 Estimating the variance Almost always, the variance of the data is unknown. We need an estimate of \\(\\sigma^2\\) from the data. Two are common \\[ \\begin{align*} \\tilde \\sigma^2 &amp; = n^{-1} \\sum_{i=1}^n (X_i - \\bar X)^2 \\text{ (maximum likelihood estimator)}\\\\ \\hat \\sigma^2 &amp; = (n-1)^{-1} \\sum_{i=1}^n (X_i - \\bar X)^2 \\text{ (unbiased estimator)}\\\\ \\end{align*} \\] We’ll focus on the second estimator. 3.3.4 Unknown variance approximate interval What is the distribution of \\(\\sqrt{n}(\\hat\\mu - \\mu)/\\hat\\sigma\\)? If we don’t know the distribution, then there is theoretical justification (using Slutsky’s theorem) to say \\[ \\sqrt{n}(\\hat\\mu - \\mu)/\\hat\\sigma \\sim N(0,1) \\text{ (approximately)} \\] Approximately means asymptotically, which means that if we can control how big our sample is, then we can make this approximation as precise as we want by choosing a big enough sample size. This suggests a confidence interval \\[ \\hat \\mu \\pm z_{\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}. \\] 3.4 T- confidence interval Today we will: Find an exact interval for the mean when the data are normally distributed Compare the intervals we’ve derived, so far Discuss our assumptions and learn how to assess the assumptions 3.4.1 Unknown variance T-interval We need some preliminaries: If \\(Z_i \\sim N(0, 1)\\) are iid, then (by definition) \\(X = \\sum_{i=1}^{(n-1)}Z_i^2\\) is Chi-squared distributed on \\((n-1)\\) degrees of freedom. Usually denoted \\(X\\sim \\chi^2(n-1)\\). If \\(Z \\sim N(0, 1)\\) and \\(X\\sim \\chi^2(n-1)\\) are independent, then \\[ T = \\frac{Z}{\\sqrt{X/(n-1)}} \\sim t(n-1). \\] where \\(t(n-1)\\) denotes the t-distribution on \\(n-1\\) degrees of freedom. 3.4.1.1 How does this help us and what does it have to do with beer? We already know that, \\[ \\sqrt{n}(\\bar X - \\mu)/\\sigma \\sim N(0,1). \\] It turns out that \\[ (n-1)\\hat \\sigma^2/\\sigma^2 \\sim \\chi^2(n-1), \\] and (surprisingly!) \\(\\hat \\sigma^2\\) and \\(\\bar X\\) are independent! (Which implies that the two random variables above are also independent) Then the test statistic we’ve been working with is \\[ \\sqrt{n}(\\hat\\mu - \\mu)/\\hat\\sigma = \\sqrt{n}(\\hat\\mu - \\mu)/\\sigma \\times \\sqrt{\\frac{\\sigma^2}{\\hat\\sigma^2} } =_D Z \\times \\sqrt{\\frac{n-1}{X}} =_D T, \\] \\(Z \\sim N(0, 1)\\) and \\(X\\sim \\chi^2(n-1)\\), and \\(T\\sim t(n-1)\\) This is the one-sample t-test (or confidence interval). 3.4.1.2 T-distribution shape Code # plotting T distribution t = seq(-4, 4, length.out = 1000) ns = c(5, 10, 15, 20, 25) n = ns[1] plot(t, dnorm(t), ylab=&#39;density&#39;, type = &#39;l&#39;, ylim = c(0, 0.6)) for(n in ns){ lines(t, dt(t, n-1), ylab=&#39;density&#39;, col=which(ns %in% n)+1) } legend(&#39;topright&#39;, legend=ns, fill=1:5+1) 3.4.1.3 But what does it have to do with beer!?!? William Gossett published the t-test when he was working for Guinness and was required to publish under a pseudoname. Wikipedia has more. Guinness 3.4.1.4 Possible intervals (so far) Here are our intervals then \\[ \\begin{align*} \\hat \\mu \\pm z_{1-\\alpha/2} \\times \\sigma/\\sqrt{n} \\\\ \\hat \\mu \\pm z_{1-\\alpha/2} \\times \\hat\\sigma/\\sqrt{n} \\\\ \\hat \\mu \\pm t_{n-1,\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}. \\end{align*} \\] Code x = mf$`C3 CSA` alpha = 0.05 # get n n = length(x) # get the mean muHat = mean(x) # get the sd stdev = sqrt(var(x)) # sd(x) # get z_alpha/2 and z_(1-alpha/2) qnorm(alpha/2) ## [1] -1.959964 Code zalpha = qnorm(1- alpha/2) talpha = qt(1-alpha/2, n-1) qt(alpha/2, n-1) ## [1] -1.986675 Code # construct the interval Zinterval = c(muHat - zalpha * stdev /sqrt(n), muHat + zalpha * stdev /sqrt(n) ) Tinterval = c(muHat - talpha * stdev /sqrt(n), muHat + talpha * stdev /sqrt(n) ) hist(mf$`C3 CSA`, main=&#39;C3 CSA&#39;, xlab=&#39;C3 CSA&#39;, freq=F, xlim=c(65,85)) lines(seq(min(mf$`C3 CSA`), max(mf$`C3 CSA`), length.out=200), dnorm(seq(min(mf$`C3 CSA`), max(mf$`C3 CSA`), length.out=200), mean = mean(mf$`C3 CSA`), sd = sd(mf$`C3 CSA`))) abline(v=Zinterval, lty=2) abline(v=Tinterval, lty=2, col=&#39;red&#39;) Code # What is the interpretation of this interval 3.5 Evaluating confidence intervals Review assumptions of our three intervals so far. Weaken the assumptions a little bit more. Assess confidence intervals using simulations. 3.5.1 Checking assumptions What assumptions have we made for what reason? (One is kind of silly) We can relax two of these at the expense of having approximate intervals. 3.5.2 Checking assumptions: Q-Q plot A Q-Q plot compares the distribution of the observed data (sample quantiles) compared to the theoretical distribution (here a standard normal) Rank the data and normalize \\(y_i = (x_{(i)}/ - \\bar x)/{\\tilde \\sigma}\\) Plot is x=qnorm(i/n), y=y_i. If data are normal the points will be on the line Check out more details on Wikipedia These data are surprisingly close to a normal distribution! Code cex=1.5 par(mgp=c(1.7,.7,0), lwd=1.5, lend=2, cex.lab=0.8*cex, cex.axis=0.8*cex, cex.main=1*cex, mfrow=c(1,1), mar=c(2.8,2.8,1.8,.2), bty=&#39;l&#39;, oma=c(0,0,2,0)) qqnorm(scale(mf$`C3 CSA`), main=&#39;Normal Q-Q plot&#39;) abline(a=0, b=1, col=&#39;blue&#39;) 3.5.3 Review of what we just did so far We identified a parameter of interest (population mean of C3 CSA). We made some assumptions about the data. We identified three Frequentist confidence intervals. 3.5.4 Aside: What is the interpretation of these intervals? \\[ \\mathbb{P}(\\hat \\mu - z_{1-\\alpha/2} \\times \\hat\\sigma/\\sqrt{n} &lt; \\mu &lt; \\hat \\mu + z_{1-\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}) \\approx 1-\\alpha \\] …this interpretation is all of Frequentist statistics. 3.5.4.1 Relaxing assumptions (normality and identicality) There’s one theorem we mentioned in class last week that can relax both of these assumptions This suggests that we can basically reduce our assumptions to independence and finite variance (and the extra condition in the theorem). Then we can use this interval a lot of the time: \\[ \\mathbb{P}(\\hat \\mu - z_{1-\\alpha/2} \\times \\hat\\sigma/\\sqrt{n} &lt; \\mu &lt; \\hat \\mu + z_{1-\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}) \\approx 1-\\alpha \\] This depends on 2 approximations: Large sample (asymptotic) normality of the mean “plugging-in” \\(\\hat\\sigma\\) for the unknown parameter \\(\\sigma\\). In practice, it seems that it’s always safer to use the T- distribution over the normal distribution for confidence intervals (more on this later) 3.6 Evaluating confidence intervals under assumption violations Today we will: Estimate a confidence interval in the C3 cross sectional data Run simulations to assess performance of confidence intervals You can use this code to run your simulations for homework 3 Check how sensitive our confidence intervals are to assumptions Define some confidence intervals for the binomial proportion 3.6.1 Confidence intervals for the mean in the spinal cord data set Code load(&#39;../datasets/smith_cervical_sc/tpmf.rdata&#39;) hist(mf$`C3 CSA`) Code t.test(mf$`C3 CSA`) ## ## One Sample t-test ## ## data: mf$`C3 CSA` ## t = 81.738, df = 90, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 74.56922 78.28441 ## sample estimates: ## mean of x ## 76.42682 Code m = mean(mf$`C3 CSA`) n = nrow(mf) df = n-1 stdev = sd(mf$`C3 CSA`) m ## [1] 76.42682 Code df ## [1] 90 Code # alpha = 0.05 m + c(-1, 1)*qt(0.975, df = df)*stdev/sqrt(n) ## [1] 74.56922 78.28441 3.6.2 Two types of confidence intervals \\[ \\begin{align*} \\hat \\mu \\pm z_{\\alpha/2} \\times \\sigma/\\sqrt{n} \\text{ (don&#39;t know sigma)} \\\\ \\hat \\mu \\pm z_{\\alpha/2} \\times \\hat\\sigma/\\sqrt{n} \\\\ \\hat \\mu \\pm t_{n-1,\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}. \\end{align*} \\] This interval \\(\\hat \\mu \\pm t_{n-1,\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}\\) is approximate/exact. What are the assumptions? This interval \\(\\hat \\mu \\pm z_{\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}\\) is approximate/exact. Assuming you are using the central limit theorem, the assumptions are 3.6.3 Simulation setup We run simulations to evaluate the confidence intervals in finite samples. What are the metrics we care about, here? Coverage – an \\(\\alpha\\) level Frequentist interval should contain the true parameter at least \\(1-\\alpha\\) percent of the time. Width – a smaller interval (that has the right coverage) is better. How do we setup the simulations? We have a few variables we can set: \\(n\\), \\(\\mu\\), \\(\\sigma^2\\), \\(\\alpha\\), number of simulations. Need a way to sample the data \\(X_i\\) given \\(n\\), \\(\\mu\\), and \\(\\sigma^2\\). Need a function to construct the CIs given the sample. Need a function to assess the coverage and width of the confidence intervals. Need a way to assess violations of normality. Need to do simulations for some different values of some of the parameters. Need to create some nice looking plots for the results. Code mu = 1 sigma = 1 ns = (1:10) * 10 nsim = 5000 alpha = 0.05 # to simulate the null in the ECT data # ect = read.csv(&#39;../datasets/ect/ect.csv&#39;) # ECT = ect$cgi.i simResults = data.frame(n = ns) simResults[ , c(&#39;Zexact_coverage&#39;, &#39;Zapprox_coverage&#39;, &#39;T_coverage&#39;, &#39;Zexact_width&#39;, &#39;Zapprox_width&#39;, &#39;T_width&#39;)] = NA for(n in ns){ CIs = data.frame(&#39;mean&#39; = rep(NA, nsim)) CIs[, paste(rep(c(&#39;Zexact&#39;, &#39;Zapprox&#39;, &#39;T&#39;), each=2), rep(c(&#39;lower&#39;, &#39;upper&#39;), 3), sep=&quot;_&quot; )] = NA for(sim in 1:nsim){ # draw a random sample, normal or skewed X = mu + (rgamma(n, shape = 1.2, rate = 5) - 1.2/5)/sqrt(1.2)*5 # rnorm(n, sd=sigma)# + (rgamma(n, shape = 1.2, rate = 5) - 1.2/5)/sqrt(1.2)*5 # rnorm(n, sd=sigma) # # sample(n, fakeECT, replace=TRUE) stdev = sd(X) # construct the Zexact confidence interval CIs$mean[sim] = mean(X) CIs[sim, c(&#39;Zexact_lower&#39;, &#39;Zexact_upper&#39;) ] = c(mean(X) + c(-1,1)*qnorm(1-alpha/2)*sigma/sqrt(n)) # construct two more CIs # Z approximate interval CIs[sim, c(&#39;Zapprox_lower&#39;, &#39;Zapprox_upper&#39;) ] = c(mean(X) + c(-1,1)*qnorm(1-alpha/2)*stdev/sqrt(n)) # T-interval CIs[sim, c(&#39;T_lower&#39;, &#39;T_upper&#39;) ] = c(mean(X) + c(-1,1)*qt(1-alpha/2, n-1)*stdev/sqrt(n)) } CIs$Zexact_gotcha = ifelse(CIs$Zexact_lower&lt;=mu &amp; CIs$Zexact_upper&gt;=mu, 1, 0) CIs$Zapprox_gotcha = ifelse(CIs$Zapprox_lower&lt;=mu &amp; CIs$Zapprox_upper&gt;=mu, 1, 0) CIs$T_gotcha = ifelse(CIs$T_lower&lt;=mu &amp; CIs$T_upper&gt;=mu, 1, 0) # This computing the width of the confidence interval CIs[paste(c(&#39;Zexact&#39;, &#39;Zapprox&#39;, &#39;T&#39;), &#39;width&#39;, sep=&quot;_&quot;)] = CIs[, grep(&#39;_upper&#39;, names(CIs))] - CIs[, grep(&#39;_lower&#39;, names(CIs))] simResults[which(simResults$n==n), grep(&#39;coverage&#39;, names(simResults), value = TRUE)] = colMeans(CIs[ , grep(&#39;_gotcha&#39;, names(CIs), value=TRUE) ] ) simResults[which(simResults$n==n), grep(&#39;width&#39;, names(simResults), value = TRUE)] = colMeans(CIs[ , grep(&#39;_width&#39;, names(CIs), value=TRUE) ] ) } plot(simResults$n, simResults$Zexact_coverage, ylim=c(0.5, 1), type=&#39;b&#39;, ylab=&#39;Coverage (proportion)&#39;, xlab=&#39;n&#39;, main=&#39;CI coverage&#39;) points(simResults$n, simResults$Zapprox_coverage, type=&#39;b&#39;, col=&#39;red&#39;) points(simResults$n, simResults$T_coverage, type=&#39;b&#39;, col=&#39;blue&#39;) abline(h=1-alpha, lty=2) legend(&#39;bottomright&#39;, legend=c(&#39;Zexact&#39;, &#39;Zapprox&#39;, &#39;T&#39;), col=c(&#39;black&#39;, &#39;red&#39;, &#39;blue&#39;), bty=&#39;n&#39;, lty=2) Code plot(simResults$n, simResults$Zexact_width, type=&#39;b&#39;, ylim=c(0, 2), ylab=&#39;CI width&#39;, xlab=&#39;n&#39;, main=&#39;CI width&#39;) points(simResults$n, simResults$Zapprox_width, type=&#39;b&#39;, col=&#39;red&#39;) points(simResults$n, simResults$T_width, type=&#39;b&#39;, col=&#39;blue&#39;) legend(&#39;topright&#39;, legend=c(&#39;Zexact&#39;, &#39;Zapprox&#39;, &#39;T&#39;), col=c(&#39;black&#39;, &#39;red&#39;, &#39;blue&#39;), bty=&#39;n&#39;, lty=2) Code # range(c(CIs$lower, CIs$upper)) Don’t interpret width without having proper coverage. These estimates are noisy, just like the bias/variance simulations. Use more to get better estimates. Rerun these simulations with the gamma errors. With errors from ECT data 3.7 Assumption violations with T-interval Another collaborator I have is evaluating the effect of ECT to treat depression and psychosis symptoms. For this study, my collaborator has reported CGI-I scores The value 4 represents “no change” and he wants to know whether the population mean is likely to be far from 4. What do we do when the assumptions of the T-test aren’t met? Code # hist(ect$cgi.i, xlab=&#39;CGI-I&#39;, breaks = c(0:8)-0.5) # qqnorm(scale(ect$cgi.i)); abline(a=0, b=1) # ect$cgi.i - mean(ect$cgi.i) # t.test(ect$cgi.i) 3.8 Confidence intervals for binomial proportions 3.8.1 CIs using the central limit theorem Remember the CLT: The Central Limit Theorem (Durrett, pg. 124): Let \\(X_1, X_2, \\ldots\\) be iid with \\(\\mathbb{E}X_i = \\mu\\) and \\(\\text{Var}(X_i) = \\sigma^2 \\in (0, \\infty)\\). If \\(\\bar X_n = n^{-1} \\sum_{i=1}^n X_i\\), then \\[ n^{1/2}(\\bar X_n - \\mu)/\\sigma \\to_D X, \\] where \\(X \\sim N(0,1)\\). The CLT allows us to make probabilistic statements about estimators that can be expressed as sums. Since it is an “asymptotic” approximation (infinite sample size), we don’t know how it works in finite samples. Most often, we use simulations to evaluate the finite sample approximation. For homework Problem 1a you will derive this interval, just like we do here. \\[ \\mathbb{P}\\left(\\bar X_n - Z_{0.975}\\times \\sqrt{p(1-p)/n} &lt; p &lt; \\bar X_n + Z_{0.975}\\times \\sqrt{p(1-p)/n}\\right) \\approx 0.95. \\] You will work with this interval for homework 3.8.2 Clopper-Pearson interval for the binomial proportion This is an exact interval (sort of), meaning the probability of coverage is not approximate. To me, it’s not intuitive why this works as a confidence interval (Clopper. Pearson). Conditional on the value \\(X_o \\sim \\text{Binom}(p)\\) (treat it as nonrandom), define \\(p_\\ell(X_o)\\) as the value that satisfies \\[ 0.975 \\ge \\sum_{k=0}^{X_o-1}{ n \\choose k} p_{\\ell}^k(1-p_\\ell)^{n-k} \\] and \\(p_u(X_o)\\) as the value that satisfies \\[ 0.025 \\le \\sum_{k=0}^{X_o}{ n \\choose k} p_{u}^k(1-p_u)^{n-k} \\] 3.8.3 Picture of this interval Let’s say \\(n=50\\), \\(\\sum_i x_i = 30\\), then choose \\(p\\) so that Code n=50 si = 30 alpha = 0.05 x = 0:n plower = uniroot(function(p) pbinom(si, n, p) - (1-alpha/2), interval=c(0.1, 0.9))$root pupper = uniroot(function(p) pbinom(si, n, p) - alpha/2, interval=c(0.1, 0.9))$root yl = dbinom(x, size=n, prob=plower) yu = dbinom(x, size=n, prob=pupper) plot(x, yl, ylab=&#39;P(sumXi=x)&#39;, xlab=&#39;x&#39;, type=&#39;h&#39;, col=&#39;red&#39;) abline(v=si, col=&#39;black&#39;, lty=2) abline(v=plower*n, col=&#39;red&#39;, lty=2) legend(&#39;topleft&#39;, legend=c(&#39;sumXi&#39;, &#39;lower CI&#39;, &#39;upper CI&#39;), lty=2, col=c(&#39;black&#39;, &#39;red&#39;, &#39;blue&#39;)) Code plot(x, yu, ylab=&#39;P(sumXi=x)&#39;, xlab=&#39;x&#39;, type=&#39;h&#39;, col=&#39;blue&#39;) abline(v=si, col=&#39;black&#39;, lty=2) abline(v=pupper*n, col=&#39;blue&#39;, lty=2) legend(&#39;topleft&#39;, legend=c(&#39;sumXi&#39;, &#39;lower CI&#39;, &#39;upper CI&#39;), lty=2, col=c(&#39;black&#39;, &#39;red&#39;, &#39;blue&#39;)) Code plot(x, yl, ylab=&#39;P(sumXi=x)&#39;, xlab=&#39;x&#39;, type=&#39;h&#39;, col=&#39;red&#39;) points(x, yu, type=&#39;h&#39;, col=&#39;blue&#39;) abline(v=si, col=&#39;black&#39;, lty=2) abline(v=plower*n, col=&#39;red&#39;, lty=2) abline(v=pupper*n, col=&#39;blue&#39;, lty=2) Picture of the interval. 3.8.4 Beta distribution The Beta distribution is a two parameter distribution \\[ f(y; \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}y^{\\alpha-1}(1-y)^{\\beta-1}. \\] Note its similarity to the binomial distribution \\[ p^{\\sum_i x_i}(1- p)^{n-\\sum_i x_i} \\] It turns out that this duality implies that the boundaries for the Clopper-Pearson interval can be expressed in terms of quantiles of the beta distribution \\[ \\left(\\text{qbeta}(\\alpha/2, X, n-X +1), \\text{qbeta}(1-\\alpha/2, X+1, n-X) \\right) \\] 3.9 Extra stuff Code # sample size ns = c(5, 10,50,100,200,500) # correlation rhos = c(0, -0.7) # creating blank output table results = expand.grid(rho=rhos , n=ns) colNames = paste(rep(c(&quot;rhoHat&quot;), each=3), rep(c(&#39;Bias&#39;, &#39;Variance&#39;, &#39;MSE&#39;), 1)) results[, colNames ] = NA for(simInd in 1:nrow(results)){ rho = results[simInd,&#39;rho&#39;] n = results[simInd, &#39;n&#39;] # generate data Sigma = matrix(c(1, rho, rho, 1), nrow=2) sqrtSigma = svd(Sigma) sqrtSigma = sqrtSigma$u %*% diag(sqrt(sqrtSigma$d)) # each column is a draw of x and y rhoHats = replicate(n = 10000, cor(tcrossprod(matrix(rnorm(n*2), ncol=2), sqrtSigma))) # compute bias, variance, MSE of estimators results[simInd, c(&#39;rhoHat Bias&#39;, &#39;rhoHat Variance&#39;)]= c(mean(rhoHats[1,2,])-rho , var(rhoHats[1,2,])) } subres = results[results$rho== -0.7, ] subres2 = results[results$rho== 0,] plot(subres$n, subres$`rhoHat Bias`, xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of rhoHat when rho = -0.7&#39;, type=&#39;b&#39;) Code plot(subres2$n, subres2$`rhoHat Bias`, xlab=&#39;Sample size&#39;, ylab=&#39;Bias&#39;, main=&#39;Bias of rhoHat when rho = 0&#39;, type=&#39;b&#39;) "],["hypothesis-testing.html", "4 Hypothesis testing 4.1 Recap of confidence intervals 4.2 Single mean example using the Alzheimer’s disease neuroimaging intiative (ADNI) 4.3 Hypothesis testing philosophy 4.4 Retaining or rejecting the null 4.5 Using the t.test function in ADNI 4.6 Parallel between CIs and hypothesis testing 4.7 Two-tailed hypotheses 4.8 One-tailed test in the ADNI data 4.9 Practice questions 4.10 Example HCP dataset 4.11 Alternatives to T-test 4.12 Simulations to evaluate hypothesis testing 4.13 (Frequentist) Confidence intervals for two means 4.14 Wald statistic for two means 4.15 Unequal variances: Welch’s t-test 4.16 Mean difference in linear regression 4.17 Permutation test for two means", " 4 Hypothesis testing 4.1 Recap of confidence intervals 4.1.1 hat is the interpretation of confidence intervals? \\[ \\mathbb{P}(\\hat \\mu - z_{\\alpha/2} \\times \\hat\\sigma/\\sqrt{n} &lt; \\mu &lt; \\hat \\mu + z_{\\alpha/2} \\times \\hat\\sigma/\\sqrt{n}) \\approx 1-\\alpha \\] …this interpretation is all of Frequentist statistics. 4.1.2 What do I tell Seth? Code load(&#39;../datasets/smith_cervical_sc/tpmf.rdata&#39;) ttest = t.test(mf$`C3 CSA`) ttest ## ## One Sample t-test ## ## data: mf$`C3 CSA` ## t = 81.738, df = 90, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 74.56922 78.28441 ## sample estimates: ## mean of x ## 76.42682 The mean C3 cross-sectional area was 76.43 with a 95% confidence interval (74.57, 78.28). 4.2 Single mean example using the Alzheimer’s disease neuroimaging intiative (ADNI) 4.2.1 The ADNI data Cognitive impairment in the ADNI data set it classified into 3 broad categories Healthy controls (HC) Mild cognitive impairment (MCI) Alzheimer’s disease (AD) Cognitive decline (in general and in AD) is characterized most strongly by changes to the hippocampus Hippocampus is the part of the brain associated with memory formation (and other memory processes). Memory decline in AD is related to deterioration of the hippocampus Code set.seed(12345) hipp = readRDS(&#39;../datasets/adni/hippocampus.rds&#39;) hipp = hipp[!duplicated(hipp$RID),] layout(matrix(1:2, ncol=2)) hist(hipp$LEFTHIPPO, main=&#39;Left hippocampus&#39;, xlab=&#39;Volume (mm)&#39;) hist(hipp$RIGHTHIPPO, main=&#39;Right hippocampus&#39;, xlab=&#39;Volume (mm)&#39;) We’re going to use the ADNI data to study some features of the hippocampus in healthy people and also compare to people with mild cognitive impairment. These are the research questions “In healthy subjects, is there a difference in the size of the left and right hippocampi?” “Is there a difference in the size of the left/right hippocampus between HC and those with MCI?” What is the difference between these hypotheses? 4.2.2 Single mean/Paired t-test example We’ve already constructed some CIs for a single continuous mean. A single mean t-test is the testing analog of a single mean CI. A “paired” t-test is an example of a single mean hypothesis test. Hypothesis testing is convenient for research questions like “Are \\(A\\) and \\(B\\) different?” And not for questions like “What is the difference between \\(A\\) and \\(B\\)?” Code # subsample data to make it more interesting n = 200 hip = hipp[sample(nrow(hipp), n),] layout(matrix(1:2, ncol=2)) hist(hip$LEFTHIPPO, main=&#39;Left hippocampus&#39;, xlab=&#39;Volume (mm)&#39;) hist(hip$RIGHTHIPPO, main=&#39;Right hippocampus&#39;, xlab=&#39;Volume (mm)&#39;) 4.2.3 Paired data setup If \\(L_i \\sim N(\\mu_0, \\sigma^2_0)\\) and \\(R_i \\sim N(\\mu_1, \\sigma^2_1)\\), then \\(X_i = L_i - R_i \\sim N(\\delta, \\sigma^2)\\) where \\(\\delta=\\mu_0 - \\mu_1\\). For the paired t-test \\(\\text{Cov}(L_i, R_i) \\ne 0\\), and contributes to \\(\\sigma^2\\). Code hist(hip$LEFTHIPPO-hip$RIGHTHIPPO, main=&#39;Left-Right hippocampus&#39;, xlab=&#39;Volume (mm)&#39;) Code plot(hip$LEFTHIPPO, hip$RIGHTHIPPO, xlab=&#39;Left Hipp Vol&#39;, ylab=&#39;Right Hipp Vol&#39;) 4.3 Hypothesis testing philosophy State the hypothesis. Set probability threshold for a decision. Compute the test statistic and the p-value. Retain or reject the null. 4.3.1 Null hypothesis Hypothesis testing compares two hypotheses, quantified by restricting the range of a parameter. The Null hypothesis is the uninteresting hypothesis, usually, this is what people are trying to show is likely to be wrong. It can be described generally in terms of a parameter \\[ H_0: \\delta \\in \\Delta_0 \\subset \\mathbb{R}, \\] where \\(\\Delta_0\\) is a “closed” subset of \\(\\mathbb{R}\\). In most cases \\(\\Delta_0\\) is chosen as a single point (zero); this is often called a two tailed test. For the difference in left and right hippocampal volume \\[ H_0: \\delta := \\mu_0 - \\mu_1 = 0. \\] Another option of the null for our given research question is that the left hippocampus is smaller than the right (called a one tailed test) \\[ H_0: \\delta \\ge 0. \\] 4.3.2 Alternative hypotheses The alternative hypothesis can be defined as a particular point, called a simple hypothesis \\[ H_a: \\delta = \\delta_a \\notin \\Delta_0 \\] Most often though, the alternative hypothesis is defined as the compliment to \\(\\Delta_0\\), called a composite hypothesis. For the null \\(H_0: \\delta=0\\) \\[ H_a: \\delta \\ne 0. \\] For the null \\(H_0: \\delta \\ge 0\\) \\[ H_A: \\delta &lt; 0. \\] 4.3.3 Hypothesis test probabilities The Frequentist framework uses dataset-to-dataset probabilities to make a decision about the hypothesis The interpretation is similar to how we constructed confidence intervals. 4.3.3.1 Test statistic version of hypothesis testing We rely on the fact that \\(T = \\sqrt{n}(\\hat\\delta - \\delta_0)/\\hat \\sigma \\sim t(n-1)\\) if \\(\\delta_0\\) is the true value of the parameter. Where \\(\\hat \\delta = \\bar X\\) and \\(\\hat \\sigma^2 = (n-1)^{-1} \\sum_{i=1}^n (X_i - \\bar X)^2\\). \\(T\\) is called the test statistic. In this Frequentist approach, an \\(\\alpha\\) level test of \\(H_0\\) chooses a threshold \\(t_{1-\\alpha/2,(n-1)}\\) such that \\(\\mathbb{P}(\\lvert T \\rvert &gt; t_{1-\\alpha/2,(n-1)} | H_0) \\le \\alpha\\). In words, \\(\\alpha\\) is the probability that we observed a statistic larger than \\(t_{1-\\alpha/2,(n-1)}\\) under the null. We “reject” the null hypothesis if our observed test statistics \\(\\lvert T_{obs} \\rvert&gt;t_{1-\\alpha/2,(n-1)}\\). I.e. of the standardized difference between left and right hippocampus is far away from zero in our observed data, that implies that it is probably far away from zero in the population. 4.3.4 Example: performing the test in the ADNI hippocampus data To do this in practice, we specify the null hypothesis, choose the alpha level, and compute the test statistic Code X = hip$LEFTHIPPO - hip$RIGHTHIPPO delta0 = 0 deltaHat = mean(X) sigmaHat = sd(X) n = nrow(hip) # Rejection threshold for t-distributed statistic such the probability it is beyond this value is equal to alpha=0.05 alpha = 0.05 c(lowerTquantile=qt(alpha/2, df=n-1), upperTquantile=qt(1-alpha/2, df=n-1)) ## lowerTquantile upperTquantile ## -1.971957 1.971957 Code # test statistic in observed data c(deltaHat=deltaHat, sigmaHat = sigmaHat, Tobs = deltaHat/sigmaHat*sqrt(n)) ## deltaHat sigmaHat Tobs ## -52.176545 204.881850 -3.601528 4.3.5 p-value version of testing To do hypothesis testing with a p-value we plug in the observed test statistic into our probability statement \\[ p = \\mathbb{P}(\\lvert T \\rvert \\ge \\lvert T_{obs} \\rvert ) \\le \\mathbb{P}(\\lvert T \\rvert &gt; t_{1-\\alpha/2,(n-1)} | H_0) \\le \\alpha \\] In words, the p-value is the probability we get a statistic at least as large as the one we observed if the null hypothesis is true. Code X = hip$LEFTHIPPO - hip$RIGHTHIPPO delta0 = 0 deltaHat = mean(X) sigmaHat = sd(X) n = nrow(hip) # test statistic in observed data c(deltaHat=deltaHat, sigmaHat = sigmaHat, Tobs = deltaHat/sigmaHat*sqrt(n)) ## deltaHat sigmaHat Tobs ## -52.176545 204.881850 -3.601528 Code pvalue = 2 *(1- pt(abs(deltaHat/sigmaHat*sqrt(n)), n-1)) pvalue = 2 * pt(-abs(deltaHat/sigmaHat*sqrt(n)), n-1) 4.4 Retaining or rejecting the null The decision to retain or reject is based on the probability of observing a result as or more extreme than we do in our observed data if the null hypothesis were true. the \\(\\alpha\\) decides how strict we want to be about rejecting our hypothesis. What happens if we decrease \\(\\alpha\\)? 4.4.1 Type 1 and type 2 errors After making a decision, there are 4 possible outcomes that can occur Retain \\(H_0\\) Reject \\(H_0\\) \\(H_0\\) True True negative \\(\\mathbb{P}(\\lvert T \\rvert&lt; t_{1-\\alpha/2,(n-1)} | H_0)\\) Type 1 error \\(\\mathbb{P}(\\lvert T \\rvert \\ge t_{1-\\alpha/2,(n-1)} | H_0)\\) \\(H_0\\) False Type 2 error \\(\\mathbb{P}(\\lvert T \\rvert&lt; t_{1-\\alpha/2,(n-1)} | H_a)\\) Power \\(\\mathbb{P}(\\lvert T \\rvert\\ge t_{1-\\alpha/2,(n-1)} | H_a)\\) 4.5 Using the t.test function in ADNI Methods In order to test whether left and right hippocampal volumes are equal in healthy older adults, we performed a t-test on the difference in volume for each subject (left - right). Code ttest = t.test( hip$LEFTHIPPO - hip$RIGHTHIPPO, alternative = &#39;two.sided&#39;) ttest ## ## One Sample t-test ## ## data: hip$LEFTHIPPO - hip$RIGHTHIPPO ## t = -3.6015, df = 199, p-value = 0.0003995 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -80.74494 -23.60815 ## sample estimates: ## mean of x ## -52.17654 Code t.test(hip$LEFTHIPPO, hip$RIGHTHIPPO, paired = TRUE, alternative = &#39;two.sided&#39;) ## ## Paired t-test ## ## data: hip$LEFTHIPPO and hip$RIGHTHIPPO ## t = -3.6015, df = 199, p-value = 0.0003995 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -80.74494 -23.60815 ## sample estimates: ## mean difference ## -52.17654 For results sections, if the analysis is complicated and will take a paragraph to describe, I might remind the reader what we’re doing in the first sentence of the results. Results We used a one-sample t-test to test whether the difference in left and right hippocampal volume was equal to zero. There was evidence for a difference between left and right hippocampal volumes (\\(T = \\text{-3.6}\\), \\(\\mathrm{df}= \\text{199}\\), \\(p&lt;0.001\\) ) with the left hippocampus being smaller on average (\\(\\text{left-right}=\\text{-52.18mm}^3\\), confidence interval (CI)= [-80.74, -23.61]). More realistically, for a t-test I would just present the result. Results We found evidence for a difference between left and right hippocampal volumes (\\(T = \\text{-3.6}\\), \\(\\mathrm{df}= \\text{199}\\), \\(p&lt;0.001\\) ) with the left hippocampus being smaller on average (\\(\\text{left-right}=\\text{-52.18mm}^3\\), 95% confidence interval (CI)= [-80.74, -23.61]). 4.6 Parallel between CIs and hypothesis testing The hypothesis test for a given \\(\\alpha\\) is related to the confidence interval. In words, if an \\(\\alpha\\) level confidence interval contains a given value, then your data do not have enough evidence to reject that value with an \\(\\alpha\\) level test. If you reject a value \\(\\delta_0\\) with an \\(\\alpha\\) level test, then the \\(\\alpha\\) level confidence interval does not contain that value. \\[ \\begin{align*} 1-\\alpha &amp; \\le 1-\\mathbb{P}(\\lvert T \\rvert\\ge t_{1-\\alpha/2,(n-1)} \\mid H_0: \\delta=\\delta_0)\\\\ &amp; = \\mathbb{P}(\\vert T\\rvert &lt; t_{1-\\alpha/2,(n-1)} \\mid H_0: \\delta=\\delta_0) \\\\ &amp; = \\mathbb{P}(-t_{1-\\alpha/2,(n-1)} &lt; T &lt; t_{1-\\alpha/2,(n-1)} \\mid H_0: \\delta=\\delta_0) \\\\ &amp; = \\mathbb{P}(\\hat\\delta- t_{1-\\alpha/2,(n-1)} \\times \\hat\\sigma/\\sqrt{n} &lt; \\delta_0 &lt;\\hat\\delta+ t_{1-\\alpha/2,(n-1)}\\times \\hat\\sigma/\\sqrt{n} \\mid H_0: \\delta=\\delta_0) \\end{align*} \\] 4.7 Two-tailed hypotheses We were using the absolute value because our hypothesis was just that the left and right hippocampus were different. Most commonly, people perform a two-tailed test We can also do a one-tailed hypothesis test 4.8 One-tailed test in the ADNI data Code X = hip$LEFTHIPPO - hip$RIGHTHIPPO delta0 = 0 deltaHat = mean(X) sigmaHat = sd(X) n = nrow(hip) # Rejection threshold for t-distributed statistic such the probability it is beyond this value is equal to alpha=0.05 alpha = 0.05 qt(0.05, df=n-1) ## [1] -1.652547 Code # test statistic in observed data deltaHat ## [1] -52.17654 Code sigmaHat ## [1] 204.8819 Code deltaHat/sigmaHat*sqrt(n) ## [1] -3.601528 Code # compute p-value pt(deltaHat/sigmaHat*sqrt(n), df=n-1) ## [1] 0.0001997614 Code # one tailed paired t-test t.test(hip$LEFTHIPPO, hip$RIGHTHIPPO, paired = TRUE, alternative = &#39;less&#39;) ## ## Paired t-test ## ## data: hip$LEFTHIPPO and hip$RIGHTHIPPO ## t = -3.6015, df = 199, p-value = 0.0001998 ## alternative hypothesis: true mean difference is less than 0 ## 95 percent confidence interval: ## -Inf -28.23555 ## sample estimates: ## mean difference ## -52.17654 Code t.test(hip$LEFTHIPPO, hip$RIGHTHIPPO, paired = TRUE) ## ## Paired t-test ## ## data: hip$LEFTHIPPO and hip$RIGHTHIPPO ## t = -3.6015, df = 199, p-value = 0.0003995 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -80.74494 -23.60815 ## sample estimates: ## mean difference ## -52.17654 4.9 Practice questions 4.9.1 Types of errors Review with questions: Retain \\(H_0\\) Reject \\(H_0\\) \\(H_0\\) True True Negative \\(\\mathbb{P}(\\lvert T \\rvert&lt; t_{1-\\alpha/2,(n-1)} | H_0)\\) 1. _____ \\(\\mathbb{P}(\\lvert T \\rvert \\ge t_{1-\\alpha/2,(n-1)} | H_0)\\) \\(H_0\\) False 2. _____ \\(\\mathbb{P}(\\lvert T \\rvert&lt; t_{1-\\alpha/2,(n-1)} | H_a)\\) 3. _____ \\(\\mathbb{P}(\\lvert T \\rvert\\ge t_{1-\\alpha/2,(n-1)} | H_a)\\) How to compute a test statistic for \\(H_0: \\mu = 2100\\)? \\[ \\frac{(4. \\underline{\\hspace{2em}} - 5. \\underline{\\hspace{2em}})}{6.\\underline{\\hspace{2em}} / 7.\\underline{\\hspace{2em}}} \\] How to compute a two-tailed p-value? 4.9.2 Performing a two-tailed test in the HCP sleep data Use a t-test to test whether the population mean of sleep is equal to 8. Hint You will have to set the null value equal to 8. Write code to reproduce all the output from the t-test command you ran (t, df, p-value, 95 percent confidence interval, mean of x). Code hcp = read.csv(&#39;../datasets/hcp/hcp.csv&#39;) # amount of sleep variable # hcp$PSQI_AmtSleep 4.9.3 Performing a one-tailed test in the HCP sleep data Arguably, sleeping more than 8 hours is less harmful than not sleeping enough. Use a t-test to test whether the population mean of sleep is greater than or equal to 8. Hint You will have to set the null value equal to 8. Write code to reproduce all the output from the t-test command you ran (t, df, p-value, 95 percent confidence interval, mean of x). Code #hcp = read.csv(&#39;../datasets/hcp/hcp.csv&#39;) sleep = c(5,6,6.5,8,7,7,4,7,5.5,5.5,8,6.5,8.5,8,6.5,8,5,7.5,6,4,5.5,6.5,5,4,6.5,8,7,7,7,7,8,7.5,8,8.5,8,6,4.5,7,5.5,8.5,6.5,7,5,8,7,6,7,6,7,8,5.5,4.5,7,6.5,5.5,7,8.5,7.5,6.5,6,5,7,7.5,6,7,7,8,5,7,5,5,5.5,7,7,6,9,8,4,5,7,7.5,6,6,8.5,7.25,6,7.5,5,5,4,6,5.5,7.5,5,7,5,6.5,6.5,8,5,7,4,7,7,7,8.5,5,7.5,6,7,7,7,7,8,7,5,7,7,6.5,8,7,7.5,7,7,7,6,8,2.5,7.5,7,6,6,5,5,8.5,3.5,6,8,7,7,7,6.5,8,6,7,7.5,6.5,6,7.5,8,7,8,6,8.5,7,7,7,6.5,8,7,8.5,7,6,7,6,6,7,7,5.5,7.5,6,7,7,7.5,6.5,9,7,5,8,8,8,7,7.5,7,6.5,7,6,7,7,8,7.5,5,6.5,6,7,7,6,7,7.5,7,7,8,8,8,7.5,8,8,8.5,6,7,7,8,6.5,7.5,5.5,7,6.5,7,5,6,8.5,7.5,6.5,8,9,9.5,5,5,6,7.5,6,7.5,2,5,7,7,7,7,6,6,8,4.5,6.5,5,6,7,4.5,6.5,6,9,7,7,11,6,7,7,4.5,8,6.5,6.5,8,6,6.5,6.5,7.5,6.5,7.5,7.5,7.5,7,8,7,6.5,8,6,6.5,7.5,6,5,7.5,7,4.5,7,7,5,8.5,6,6,6,6,7,5.5,6.5,7,6,9,7,6.75,8.5,9.5,4.75,8.5,6.5,8,8,7,7.5,7,7,5,8,7,7.5,6.5,7,7,7,6.5,7.5,5,7,7,7.5,10.5,7,8,8,5.5,8,6.5,7,12,7,5,7,7,6,4,6,9,6,7,7.5,5,6.5,8,7,8,8,6,7,6,8,7,7,6.5,7,8,5.5,5,7,5.5,5,8,8,9,8,6.5,7,5.5,3,8,8,8,7.5,8,7.5,8.5,7.5,8,7.5,7,6,6,8,5,6,8,9,4.5,7,7,5,8,6.5,7,7,7.5,7,8,7,5,7,8.5,7,6,7,7.5,7,8,6,6,6.5,6.5,7.5,6,8.5,7.5,6,5,8,8,6,7,5.5,7.5,5,6,8,6.5,6,12,6,7,6,7,3.5,6.5,7,7.25,7,7,7,4,9,6,7.5,7,7.5,4,8,7,9,6.5,5,6.5,8.5,8,7.5,6,7,7,7,5,7,7,5.5,6,6,6,5,8.5,7.5,7,7,7,8,7.5,6.5,7,6,8,7,5.5,5.5,5,6.5,7,7.5,9,7.5,7,8,6,7,8,4,6,7,7,6.5,8,7,8,7,7,7,7,4.5,6,8.5,7.5,7,7,6,7,7,9,7,8,6,7.5,6.5,6.5,4,5.5,8,6,8,7,8,5,7,5,6.75,8,7,8,8,6.5,7,6,7,5,6.5,8.5,7.5,6,8,8,9,5.5,7,6.5,7,8.5,8,7.5,8,5.5,7.5,8,8,5,7,7,7.5,4,9,7,7.5,7,8,10.5,6,7.5,8,7,9,6,5.5,6.5,5.5,6,7.5,6,6,7,6,6,8,9,6,7,6,7.25,5.5,7.5,6.5,6,8,6,6,7.5,5,6,6,6,5.5,7.5,5,6,7.5,6.5,6.5,7,6,9,4,6.5,9,8,4,3.5,3,7,6,7,7,6,7,7,7,5.5,6,8,6.5,6,6.5,6.5,7,8,7,9,8,7.5,6.5,6,8,3,6.5,7.5,5,5,7,5,8,7,5,6,8.5,7,7,7,8,8,7,7.5,5,8,6,8,7,8,7,6,6,7,6,6,6,6.5,7.5,8,7,7,7,9,3.5,7.5,6,5,4.5,7,7,6.5,7,7,8,7.5,7,8,8,7,7.5,6.5,7,7.5,7.5,7.75,7,6,6.2,7,8,8,6.5,7,7.5,7.5,8,7,7.5,9,5,7.5,6.5,7.5,8.5,8,7.5,7,7,6,8,6,7.5,8,5,5,5,4,7.5,7,7,7,8,7,8,7,6.5,7.5,6.5,6,8,8,5,6.5,6,7.5,6,6,6,8,7,6,7,8,6,6,6,6.5,6,7,7,6,7,6.5,6,6.5,8,6,8,6,6.5,4.67,8,7,4,6.5,8,7.5,6,6,9,7,6.3,7.5,7,5.5,8,6.5,8,7.5,7.5,7,6,8,9.5,6.5,7,7,7,7,6,6,6,8,6,7,6,7,8,7,7.25,8,7.5,7,7,6,6.5,7,5.5,6.5,6,6,7,6.5,6,10,8,6,7,6,6,6.5,8,5,6.5,7,9,5.5,6,7,8.5,7,7.5,7,6.5,7,8,6,6.5,6.5,8,7,5,6,8,7.5,5,7,7,5,8,7.5,5,6.5,5,5,4,6,8,4,8,7,9,10.5,7.5,8,6.5,5,7,7,4,7,6,7.5,8,8,6,5.5,6,6,8,7,9,6,7,7,6,8,6,8,6,6,8,6,4,8,8,6.5,7,6.5,7,8.5,7.5,7,8,7,5,8,6,8,6,5.5,7.5,8,8,8,8,7,7,8,7,7.5,8,6.5,7.5,8,7,7,7,7.5,7,8,7.5,8,8,6.5,8,6,6,6,8,8,7,7.5,7.5,7,6.5,7,6,7,6,6,7,6.5,7,6.5,9,7,6,6,7,4.5,8,5,8,6,9,7,7,8,8,8,7.5,5) # amount of sleep variable # hcp$PSQI_AmtSleep 4.10 Example HCP dataset In the human connectome project participants perform an emotion recognition task We might be interested in comparing whether people are as accurate with identifying fearful faces as they are identifying angry faces Code hcp = read.csv(&#39;../datasets/hcp/hcp.csv&#39;) hist(hcp$ER40ANG - hcp$ER40FEAR, main=&#39;Anger-Fear&#39;) Code qqnorm(scale(hcp$ER40ANG - hcp$ER40FEAR)); abline(a=0, b=1, col=&#39;orange&#39;) Code # two-tailed t.test(hcp$ER40ANG, hcp$ER40FEAR, paired = TRUE) ## ## Paired t-test ## ## data: hcp$ER40ANG and hcp$ER40FEAR ## t = -3.0013, df = 1197, p-value = 0.002744 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -0.2098178 -0.0439385 ## sample estimates: ## mean difference ## -0.1268781 Code # one-tail t.test(hcp$ER40ANG, hcp$ER40FEAR, paired = TRUE, alternative=&#39;less&#39;) ## ## Paired t-test ## ## data: hcp$ER40ANG and hcp$ER40FEAR ## t = -3.0013, df = 1197, p-value = 0.001372 ## alternative hypothesis: true mean difference is less than 0 ## 95 percent confidence interval: ## -Inf -0.05728953 ## sample estimates: ## mean difference ## -0.1268781 4.10.1 One-tailed hypotheses We can define one tailed hypotheses if we believe the result should be in a particular direction. E.g. if my null hypothesis is that the Anger emotion identification is at least as accurate as fearful. \\[ H_0: \\mathbb{E}A_i - \\mathbb{E}F_i = \\delta \\ge 0 \\] Because there is not a single value for \\(\\delta_0\\), we choose a value that is most conservative This usually occurs at the boundary of the null set, in this case \\(\\delta_0 = 0\\). So the test statistic is (same as before). \\[ T = \\frac{\\hat \\delta}{ \\hat \\sigma/\\sqrt{n}} \\] For our test, only smaller values of the test statistic are evidence against the null (values larger than zero imply \\(\\hat\\delta&gt;0\\), which is in the null set. So we choose the rejection threshold \\(t_{\\alpha,(n-1)}\\), so that \\[ \\mathbb{P}(T&lt;t_{\\alpha,(n-1)}) = \\alpha \\] When our observed test statistics \\(T_{obs}&lt;t_{\\alpha,(n-1)}\\) we reject the null Alternatively, we can compute the p-value \\[ p = \\mathbb{P}(T&lt;T_{obs}) \\] and reject when \\(p&lt;\\alpha\\) 4.11 Alternatives to T-test 4.11.1 Z-test If the underlying data are not normally distributed, then we use the CLT approximation \\[ \\frac{\\bar X_n - \\delta_0}{\\hat\\sigma/\\sqrt{n}} \\approx_D Z \\sim N(0,1) \\] Using the Lindeberg-Feller Theorem also allows us to relax the identicality assumption. We can then do all the same stuff we did with hypothesis testing for the single mean. A natural question is, which of the two tests performs better? We can use simulations to answer this question. 4.11.2 One-sample permutation test Permutation testing is a very flexible and popular nonparametric way to test hypotheses that makes minimal assumptions. Conceptually, it assumes that if the null hypothesis is true \\(H_0: \\delta=0\\) and the data distribution is symmetric, if you randomly flipped the sign of each data point then that dataset would be as likely to occur as the original data. 4.12 Simulations to evaluate hypothesis testing What are the metrics we care about, here? Type 1 error rate \\(\\mathbb{P}(\\vert T \\rvert &gt; t_{1-\\alpha/2,(n-1)} )\\). By design it should be \\(\\alpha=0.05\\). Another way to check type 1 error rate is using the p-value. \\[\\begin{align*} \\alpha = \\mathbb{P}\\{\\vert T \\rvert &gt; t_{1-\\alpha/2,(n-1)} \\} &amp; = \\mathbb{P}(2\\times pt(\\vert T \\rvert, n-1) &gt; 2 \\times pt(t_{1-\\alpha/2,(n-1)} )\\}\\\\ &amp; = \\mathbb{P}(p &lt; \\alpha) \\end{align*}\\] What does this probability mean? It is about dataset-to-dataset variability. A Z-test is the same thing with the Z-distribution as the reference distribution. Power is another metric we care about – we have to pick the alternative. How to simulate non-normality? Synthetically sampling data from the gamma distribution. What are the parameters? n, alpha, nsim, the density function I will use for sampling (gamma distribution) Retain \\(H_0\\) Reject \\(H_0\\) \\(H_0\\) True True negative \\(\\mathbb{P}(\\lvert T \\rvert&lt; t_{1-\\alpha/2,(n-1)} | H_0)\\) Type 1 error \\(\\mathbb{P}(\\lvert T \\rvert \\ge t_{1-\\alpha/2,(n-1)} | H_0)\\) \\(H_0\\) False Type 2 error \\(\\mathbb{P}(\\lvert T \\rvert&lt; t_{1-\\alpha/2,(n-1)} | H_a)\\) Power \\(\\mathbb{P}(\\lvert T \\rvert\\ge t_{1-\\alpha/2,(n-1)} | H_a)\\) 4.12.1 Research question for the simulations: Are t-test and z-test affected by data that have a nonnormal distribution? \\(X_i \\sim Gamma(\\alpha,\\beta)\\) (iid). T-test assumes \\(X_i\\sim N(\\mu, \\sigma^2)\\) (violated). Z-test is approximation, no assumption on distribution of \\(X_i\\). Which performs better? Code set.seed(12345) # creating blank output table mu = 0 ns = seq(10, 100, length.out=10) alphas = c(0.01, 0.05, 0.1) nsim = 1000 results = expand.grid( n=ns, alpha=alphas) colNames = c(&#39;t-test type 1 error&#39;, &#39;z-test type 1 error&#39;) results[, colNames ] = NA ### Loop through parameter settings and run simulations # (Potential states of the world) # loop through &quot;n&quot; only instead for(n in ns){ # draw one sample of size n from our random variable nsim times settingResults = matrix(NA, ncol=2, nrow=nsim) for(sim in 1:nsim){ # generate the sample simulatedData = mu + (rgamma(n, shape = 1.2, rate = 5) - 1.2/5)/sqrt(1.2)*5 tResult = t.test(simulatedData) # p-value for the t-test settingResults[sim, 1] = tResult$p.value # p-value for the Z-test settingResults[sim, 2] = 2*pnorm(abs(tResult$statistic), lower.tail = FALSE) } # compute type 1 error rate across the simulations results[results$n==n, c(&#39;t-test type 1 error&#39;, &#39;z-test type 1 error&#39;)] = t(sapply(results[ results$n==n,&#39;alpha&#39;], function(a) colMeans(settingResults&lt;a, na.rm=TRUE))) } Code # plotting simulation results cols = gray.colors(length(ns)) # T-test plot(results$alpha, results$`z-test type 1 error`, type=&#39;n&#39;, xlab=&#39;Target type 1 error&#39;, ylab=&#39;Observed type 1 error&#39;, main=&#39;T-test&#39;) trash = by(results, results$n, function(df) points(df$alpha, df$`t-test type 1 error`, type=&#39;b&#39;, col=cols[which(ns %in% df$n)])) abline(a=0,b=1) legend(&#39;topleft&#39;, fill=cols, legend=ns, bty=&#39;n&#39;) Code # Z-test plot(results$alpha, results$`z-test type 1 error`, type=&#39;n&#39;, xlab=&#39;Target type 1 error&#39;, ylab=&#39;Observed type 1 error&#39;, main=&#39;Z-test&#39;) trash = by(results, results$n, function(df) points(df$alpha, df$`z-test type 1 error`, type=&#39;b&#39;, col=cols[which(ns %in% df$n)])) abline(a=0,b=1) legend(&#39;topleft&#39;, fill=cols, legend=ns, bty=&#39;n&#39;) Code # Both results = results[results$n %in% c(10, 50, 100),] plot(results$alpha, results$`z-test type 1 error`, type=&#39;n&#39;, xlab=&#39;Target type 1 error&#39;, ylab=&#39;Observed type 1 error&#39;, main=&#39;Both&#39;) trash = by(results, results$n, function(df) points(df$alpha, df$`t-test type 1 error`, type=&#39;b&#39;, col=cols[which(ns %in% df$n)])) trash = by(results, results$n, function(df) points(df$alpha, df$`z-test type 1 error`, type=&#39;b&#39;, col=cols[which(ns %in% df$n)], lty=2)) abline(a=0,b=1) legend(&#39;topleft&#39;, fill=cols, legend=unique(results$n), bty=&#39;n&#39;) 4.13 (Frequentist) Confidence intervals for two means We will study mean differences between two groups. We’ll construct some confidence intervals for a difference in means The concepts are the same, with a few more complexities 4.13.1 Mean differences in the spinal cord data Code histinfo = hist(hip$RIGHTHIPPO, plot = FALSE) hist(hip$RIGHTHIPPO[ hip$DX==&#39;HC&#39;], breaks = histinfo$breaks, main=&quot;Histogram of R hippocampus&quot;, xlab=&quot;Volume&quot;, col=rgb(1,0,0,.5), border=NA) hist(hip$RIGHTHIPPO[ hip$DX==&#39;MCI&#39;], breaks=histinfo$breaks, col=rgb(0,0,1,.5), add=TRUE, border=NA) legend(&#39;topright&#39;, fill=c(rgb(1,0,0,.5), rgb(0,0,1,.5)), legend=c(&#39;HC&#39;, &#39;MCI&#39;), bty=&#39;n&#39;) “Is there a difference in the size of the left/right hippocampus between HC and those with MCI?” Let \\(\\mu_h\\) denote the mean for healthy participants and \\(\\mu_p\\) denote the mean for patients. 4.13.2 Mean differences Here is the context: \\[ \\begin{align*} Y_i &amp; \\sim N(\\mu_0, \\sigma^2_h) \\text{ for $i=1,\\ldots,n_h$}\\\\ Y_i &amp; \\sim N(\\mu_1, \\sigma^2_p) \\text{ for $i=n_h+1, \\ldots, n_h+n_p$} \\end{align*} \\] where \\(n_h\\) – number in group 0 (controls). \\(n_p\\) – number in group 1 (patients). \\(n := n_h + n_p\\). \\(\\delta := \\mu_p - \\mu_h\\). We’ll start by assuming equal variances \\(\\sigma^2_h = \\sigma^2_p\\). We will start off simple and relax some assumptions. 4.13.3 Hypothesis testing philosophy (recap) State the hypothesis. Set probability threshold for a decision. Compute the test statistic and the p-value. Retain or reject the null. 4.13.3.1 Null hypothesis What’s the null hypothesis? 4.13.3.2 Alternative hypotheses What’s the alternative hypothesis? 4.13.3.3 Probability of rejection Pick a probability for rejection. \\(\\alpha=\\) 4.14 Wald statistic for two means The Wald statistic with known variance is defined as \\((\\hat \\delta - \\delta)/\\sqrt{\\text{Var}(\\hat\\delta)}\\). We need to find \\(\\hat \\delta\\) and \\(\\widehat{\\text{Var}}(\\hat\\delta)\\), just like we did for the single mean example. Derive the estimators. 4.14.1 What is the distribution of the Wald statistic? What is the variance of each mean estimator? \\[ \\text{Var}(\\hat \\mu_h) = \\frac{\\sigma^2_h}{n_h} \\] What is the variance of \\(\\hat\\delta\\) \\[ \\text{Var}(\\hat \\delta) = n_h^{-1} \\sigma^2_h + n_p^{-1} \\sigma^2_p = (n_h^{-1} + n_p^{-1})\\sigma^2 \\] (last line assumes equal variance) Under normality with known variance then a Z-test statistic is \\[ \\frac{(\\hat \\delta - \\delta)}{\\sqrt{(n_h^{-1} + n_p^{-1})\\sigma^2}} \\sim N(0, 1) \\] As is usual, the variance is not known. What is an estimator of variance? Variance for \\(\\widehat{\\text{Var}}(\\hat\\mu_h) = \\hat\\sigma^2_h/n_h\\) \\[ \\hat\\sigma^2_h= (n_h-1)^{-1}\\sum_{i=1}^{n_h}(X_i - \\hat\\mu_h)^2 \\] Variance estimator for \\(\\hat \\mu_1\\) is the same under equal variance assumption. Equal variance pooled variance estimator \\[ \\hat\\sigma^2 = \\frac{ \\sum_{i=1}^{n_h}(X_i - \\hat\\mu_h)^2 + \\sum_{i=1}^{n_p}(X_i - \\hat\\mu_p)^2}{ (n_h-1) + (n_p-1)} \\] This gives the usual form of the test statistic that we can use for confidence intervals and testing, except now with flavors of two means. \\[ \\frac{\\{ \\hat\\delta-\\delta \\}}{\\sqrt{(n_h^{-1} + n_p^{-1})\\hat\\sigma^2}} = \\frac{\\{ (\\hat\\mu_h - \\hat\\mu_p)-(\\mu_h - \\mu_p)\\}}{\\sqrt{(n_h^{-1} + n_p^{-1})\\hat\\sigma^2}} \\] Code nh = sum(hip$DX==&#39;HC&#39;) np = sum(hip$DX==&#39;MCI&#39;) hc = hip$RIGHTHIPPO[hip$DX==&#39;HC&#39;] mci = hip$RIGHTHIPPO[hip$DX==&#39;MCI&#39;] muhHat = mean(hc) mupHat = mean(mci) # variance of the X_i&#39;s pooledVar = (var(hc)*(nh-1) + var(mci)*(np-1))/(nh+np-2) Tstat = (mupHat-muhHat)/sqrt( (1/nh + 1/np)*pooledVar ) TtestResults = t.test(mci, hc, var.equal = TRUE) # assuming test statistic under H_0 is t(nf+nm-2) alpha = 0.05 qt(1-alpha/2, df = nh+np-2) ## [1] 1.975799 Code pt(abs(Tstat), df = nh+np-2, lower.tail=FALSE) * 2 ## [1] 2.145791e-07 Code # Under H_0, T (our test statistic) ~ t(nf +nm-2), T_obs=abs(4.2596) # all do the same thing #2*(1-pt(, df = nf+nm-2)) #2*(pt(, df = nf+nm-2, lower.tail = FALSE)) #pt(, df = nf+nm-2, lower.tail = TRUE) + pt(, df = nf+nm-2, lower.tail = FALSE) # assess normality qqnorm(c(scale(hc), scale(mci))) abline(a=0, b=1) 4.14.2 Assumptions we’ve made for equal variance two-sample t-test so far Equal variance 4.15 Unequal variances: Welch’s t-test 4.15.1 Unequal variance formula When the variances are not equal, the variance of \\(\\hat\\delta\\) is \\[ \\sigma_{\\hat\\delta}^2 = n_0^{-1} \\sigma^2_0 + n_1^{-1} \\sigma^2_1 \\] \\[ \\begin{align*} \\hat \\sigma^2_0 &amp; = (n_0-1)^{-1} \\sum_{i=1}^{n_0}(X_i - \\hat\\mu_0)^2 \\end{align*} \\] Then, plugging-in to get a variance estimator for \\(\\hat\\delta\\) \\[ \\hat\\sigma^2 = n_0^{-1} \\hat\\sigma^2_0 + n_1^{-1} \\hat\\sigma^2_1 \\] 4.15.2 Unequal variances test statistic What is the distribution of \\[ \\frac{(\\hat \\delta - \\delta)}{\\sqrt{n_0^{-1} \\hat\\sigma^2_0 + n_1^{-1} \\hat\\sigma^2_1}} \\] Nobody knows the distribution this statistic. 4.15.3 Satterthwaite approximation Satterthwaite came-up with a way to approximate the distribution of \\(\\hat \\sigma^2 =n_0^{-1} \\hat\\sigma^2_0 + n_1^{-1} \\hat\\sigma^2_1\\) with a chi-square distribution Note that \\(\\mathbb{E}\\hat\\sigma^2 = \\sigma^2\\) This is the general premise: \\((n_0-1)\\hat\\sigma^2_0/\\sigma_0^2 \\sim \\chi^2(n_0-1)\\), and same for \\(\\hat\\sigma^2_1\\) Imagine if we could approximate the distribution of \\(\\nu \\frac{\\hat\\sigma^2}{\\sigma^2}\\) with a chi-squared distribution on \\(\\nu\\) degrees of freedom, then \\[ \\frac{(\\hat \\delta - \\delta)/\\sigma^2}{ \\sqrt{\\nu \\hat\\sigma^2/\\sigma^2/\\nu}} \\sim t(\\nu) \\text{ (approximately) }, \\] because \\(\\nu \\hat\\sigma^2/\\sigma^2 \\sim \\chi^2(\\nu)\\) How do we find \\(\\nu\\)? Satterthwaite proposed finding \\(\\nu\\) by matching the mean and variance of \\(\\nu W/\\sigma^2\\) to a chi-squared distribution and solving for \\(\\nu\\). That yields the formula \\[ \\nu = \\frac{ \\left(n_0^{-1}\\hat\\sigma^2_0 + n_1^{-1}\\hat\\sigma^2_1 \\right)}{n_0^{-2}(n_0-1)\\hat\\sigma^4_0 + n_1^{-2}(n_1-1)\\hat\\sigma^4_1} \\] Welch was the one who did it for the t-test. It’s a very ugly formula, but the approximation works very well, such that it is the default t-test in R. 4.15.4 Unequal variance t-test in CS C4 data Code nh = sum(hip$DX==&#39;HC&#39;) np = sum(hip$DX==&#39;MCI&#39;) hc = hip$RIGHTHIPPO[hip$DX==&#39;HC&#39;] mci = hip$RIGHTHIPPO[hip$DX==&#39;MCI&#39;] muhHat = mean(hc) mupHat = mean(mci) # This is no longer the correct variance estimator pooledVar = (var(hc)*(nh-1) + var(mci)*(np-1))/(nh+np-2) Tstat = (muhHat-mupHat)/sqrt((1/nh + 1/np)*pooledVar ) satterTstat = (muhHat-mupHat) / sqrt(var(hc)/nh + var(mci)/np) TtestResults = t.test(hc, mci) # assuming test statistic under H_0 is t(nf+nm-2) alpha = 0.05 qt(1-alpha/2, df = nh+np-2) ## [1] 1.975799 Code # p-value is equal to the probability of a result as or more extreme as T_obs #T_obs = abs(-4.2731) #2*pt(abs(T_obs), df=78.365, lower.tail=FALSE) # assuming test statistic under H_0 is t(nf+nm-2) #alpha = 0.05 #qt(1-alpha/2, df = 78.365) 4.16 Mean difference in linear regression 4.17 Permutation test for two means \\[ \\begin{align*} Y_i &amp; \\sim N(\\mu_0, \\sigma^2_h) \\text{ for $i=1,\\ldots,n_h$}\\\\ Y_i &amp; \\sim N(\\mu_1, \\sigma^2_p) \\text{ for $i=n_h+1, \\ldots, n_h+n_p$} \\end{align*} \\] where \\(n_h\\) – number in group 0 (healthy). \\(n_p\\) – number in group 1 (patients). \\(n := n_h + n_p\\). \\(\\delta := \\mu_p - \\mu_h\\). We’ll start by assuming equal variances \\(\\sigma^2_h = \\sigma^2_p\\). Our test statistic is \\[ T = (\\hat\\mu_1 - \\hat\\mu_0)/\\sqrt{\\hat{\\text{Var}}(\\hat\\mu_1 - \\hat\\mu_0)} = T(Y) \\] 4.17.1 Intuition If the null is true \\(\\mu_1 = \\mu_0\\). If the variances are equal, then all observations are exchangeable, meaning any observation could have been as likely to come from any group. We can permute the values \\(Y_i\\), and the result is equally likely under the null and we could compute a test statistic \\[ T^{p} = T(Y^p) \\] where \\(Y^p\\) is the permuted hippocampal data. In this case, there are \\({n \\choose n_1}\\) possible pairings. That’s a lot. In practice, because there are so many possible permutations, we just randomly choose a large number of permutations Permutation tests compute a p-value this way for \\(p=1, \\ldots, P\\) \\[ 1/P \\sum_{p=1}^P I\\{ T(Y^p) \\ge T\\} \\] The average number of data sets where the test statistics is equal or larger than the observed value. Code permutationTest = function(X, Y, nperm=1000){ Tobs = t.test(Y[X==0], Y[X==1])$statistic # randomly permutes X Tperms = replicate(nperm, {Xperm = sample(X, replace=FALSE); t.test(Y[Xperm==0], Y[Xperm==1])$statistic} ) c(Tobs=Tobs, pvalue=mean(abs(c(Tperms, Tobs))&gt;=abs(Tobs))) } # In the subset of data y = hip$RIGHTHIPPO[ hip$DX !=&#39;AD&#39; ] x = ifelse(hip$DX[hip$DX !=&#39;AD&#39; ]==&#39;MCI&#39;, 1, 0) permtest = permutationTest(Y=y, X = x) wtest = wilcox.test(y[x==1], y[x==0], conf.int = TRUE) ttest = t.test(y[x==1], y[x==0]) permtest ## Tobs.t pvalue ## 5.759983979 0.000999001 Code wtest ## ## Wilcoxon rank sum test with continuity correction ## ## data: y[x == 1] and y[x == 0] ## W = 1362, p-value = 7.944e-07 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## -434.9001 -208.6899 ## sample estimates: ## difference in location ## -322.6506 Code ttest ## ## Welch Two Sample t-test ## ## data: y[x == 1] and y[x == 0] ## t = -5.76, df = 124.49, p-value = 6.21e-08 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -424.0599 -207.1636 ## sample estimates: ## mean of x mean of y ## 1814.981 2130.593 Code # In the full sample permtest = permutationTest(Y=puf$iralcfm, X = as.numeric(puf$mrjmon==&#39;yes&#39;)) wtest = wilcox.test(puf$iralcfm[ puf$mrjmon==&#39;yes&#39;], puf$iralcfm[ puf$mrjmon==&#39;no&#39;], conf.int = TRUE) ttest = t.test(puf$iralcfm[ puf$mrjmon==&#39;yes&#39;], puf$iralcfm[ puf$mrjmon==&#39;no&#39;]) permtest ## Tobs.t pvalue ## -37.058361322 0.000999001 Code wtest ## ## Wilcoxon rank sum test with continuity correction ## ## data: puf$iralcfm[puf$mrjmon == &quot;yes&quot;] and puf$iralcfm[puf$mrjmon == &quot;no&quot;] ## W = 226081314, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## 2.000021 2.000031 ## sample estimates: ## difference in location ## 2.000047 Code ttest ## ## Welch Two Sample t-test ## ## data: puf$iralcfm[puf$mrjmon == &quot;yes&quot;] and puf$iralcfm[puf$mrjmon == &quot;no&quot;] ## t = 37.058, df = 7352.6, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 3.691486 4.103838 ## sample estimates: ## mean of x mean of y ## 6.926761 3.029099 "],["bayesian-statistics.html", "5 Bayesian Statistics 5.1 Overview 5.2 Beginning of Bayesian Inference 5.3 Binomial proportion 5.4 Assessing frequentist probabilities for Bayesian methods 5.5 Extra stuff", " 5 Bayesian Statistics 5.1 Overview Today we will: Introduce Bayesian concepts in the context of the binomial proportion Important concepts from Bayesian statistics are: The parameter is considered random. The prior is used to incorporate prior information into the result. The posterior is used to interpret the results after observing the data. Interpretation of Bayesian results are about where the parameter is likely to be. 5.2 Beginning of Bayesian Inference Probabilities in Frequentist and evidentialist phisosophies represent what would happen upon repeated samplings of the data In Bayesian statistics the probability represents a subject belief about the unknown world In all philosophies the state of the world is expressed in the form of parameters. Bayesian statistics is about updating our belief of the world using Bayes theorem \\(H\\) is my current hypothesis about the state of the world, expressed in the form of parameters, \\(X\\) is the observed data, then \\[ \\mathbb{P}(H \\mid X) = \\frac{\\mathbb{P}(X \\mid H) \\mathbb{P}(H)}{\\mathbb{P}(X)} \\] In Bayesian statistics, the state of the world is treated as a random variable, thus we have \\(P(H)\\) \\(P(H)\\) is subjective \\(\\mathbb{P}(X) = \\sum_{h} \\mathbb{P}(X \\mid H=h) \\mathbb{P}(H=h)\\), in practice it is usually an integral. Definitions Prior \\(\\mathbb{P}(H)\\) Likelihood \\(\\mathbb{P}(X \\mid H)\\) Posterior \\(\\mathbb{P}(H \\mid X)\\) 5.2.1 COVID-19 dog example Scent dog detection example Jendrny et al, 2020 These are the estimates of accuracy for the dogs identifying nCov presence Positive Test Negative Test nCov Absent 4% 96% nCov Present 83% 17% Let’s say a dog barks at an airport visitor. Bayesian statistics tries to understand the probability that the person is actually nCov positive using Bayes theorem \\[ \\mathbb{P}(\\text{nCov} | + ) = \\frac{\\mathbb{P}(+ \\mid \\text{nCov} ) \\mathbb{P}(\\text{nCov}) }{\\mathbb{P}(+ \\mid \\text{nCov} ) \\mathbb{P}(\\text{nCov}) + \\mathbb{P}(+ \\mid \\text{no nCov} ) \\mathbb{P}(\\text{no nCov})} \\] The person testing positive for COVID is the data point. The person having COVID for real is the parameter. The probability someone comes into the airport with nCov is unknown. We can specify this probability from prior data. The number of current cases is 9,165,744 Worldometer. The US population is (approximately) 333,000,000 US population clock Thus we can approximate \\(\\mathbb{P}(\\text{nCov}) = 9,165,744/333,000,000 = 0.0275\\). We can then compute the probability that someone is sick, given that the the dog barked \\[ \\mathbb{P}(\\text{nCov} | + ) = \\frac{0.83 \\times 0.0275 }{0.83 \\times 0.0275 + 0.04 \\times (1-0.275)} \\approx 0.37 \\] There’s less than 50% chance the person actually has nCov given the test is positive. This is because the false positive rate is high enough and the COVID is rare enough that the majority of people who test positive are false positives. Obviously, a decision still needs to be made about what to do with the person. Fundamental difference in interpretation: Parameter is “random.” Probability represents our belief about the unknown value. 5.2.2 Bayesian analysis overview Decide a reasonable model for the data. Choose a reasonable prior the parameters in the model. Use Bayes theorem to compute the posterior, \\(P(H \\mid X)\\). Do stuff with \\(P(H \\mid X)\\): Create intervals. Compute Bayes Factors. Compute point estimates (most likely values for unknown parameters). 5.3 Binomial proportion 5.3.1 Examples in the NSDUH data set Let’s consider binomial data from the NSDUH data set again. psilcy - “yes”/“no” for having ever taken psilocybin, a psychedelic (and recreational) drug recently used in clinical trials for psychiatric treatment. psyanyflag - “yes”/“no” for having ever taken a psychiatric medication. What is a reasonable model for these? Bernoulli What is a reasonable prior for the parameter? Flat? Skewed left? Skewed right? Centered? – Will depend on the drug type. 5.3.2 Flat prior for binomial proportions Binomial proportion with flat prior \\[ \\begin{align*} \\mathbb{P}(H) &amp; = \\mathbb{P}(\\pi) = 1, \\text{ for $\\pi \\in [0,1]$} \\\\ \\mathbb{P}(X \\mid H) &amp; = \\pi^{\\sum_{i=1} x_i}(1-\\pi)^{n-\\sum_{i=1} x_i} \\\\ \\mathbb{P}(X) &amp; = \\int_0^1 \\pi^{\\sum_{i=1} x_i}(1-\\pi)^{n-\\sum_{i=1} x_i} d\\pi = B\\left(\\sum_{i=1} x_i+1, n - \\sum_{i=1} x_i+1\\right) \\end{align*} \\] We can then compute the distribution of the parameter conditional on the data \\[ \\mathbb{P}(\\pi \\mid X) = \\frac{\\mathbb{P}(X \\mid \\pi) \\times \\mathbb{P}(\\pi)}{\\mathbb{P}(X)} = \\frac{\\pi^{\\sum_{i=1} x_i}(1-\\pi)^{n-\\sum_{i=1} x_i}}{B\\left(\\sum_{i=1} x_i+1, n - \\sum_{i=1} x_i+1\\right)} \\] This is a Beta distribution \\(\\pi \\mid x \\sim \\text{Beta}(\\sum_{i=1} x_i+1, n-\\sum_{i=1} x_i+1)\\) Evaluated at \\(n=0\\), we get the flat prior… If we collect no data, we just get our prior hypothesis back. This prior is called a flat prior. It implies that we do not have a prior preference for any particular value of the parameter. (Every value of the parameter is equally probable). Evaluation over 1 sample that’s one and zero. Code pi = ppoints(100) n = 0 S = 0 prob = dbeta(pi, S+1, n -S + 1) plot(pi, prob, ylab=&#39;P(pi| x)&#39;, type=&#39;l&#39;, ylim=c(0,3), xlim=c(0,1), col=cols[1] ) n = 1 S = 1 prob = dbeta(pi, S+1, n -S + 1) points(pi, prob, type=&#39;l&#39;, col=cols[2] ) n = 1 S = 0 prob = dbeta(pi, S+1, n -S + 1) points(pi, prob, type=&#39;l&#39;, col=cols[3] ) legend(&#39;topright&#39;, legend=c(&#39;n=0, S=0&#39;, &#39;n=1, S=1&#39;, &#39;n=1, S=0&#39;), col=cols[1:3], lty=1, bty=&#39;n&#39;) Plot for a few random samples for the question about psychiatric drug use. Code set.seed(1234) puf = readRDS(&#39;../datasets/nsduh/puf.rds&#39;) ns = c(2, 5, 10, 50, 100) pi = ppoints(1000) puf$psyanyflag = ifelse(puf$psyanyflag==&#39;yes&#39;, 1, 0) S=0 for(n in 1:max(ns)){ S = S + sample(puf$psyanyflag, size = 1) prob = dbeta(pi, S+1, n -S + 1) if(n==ns[1]){ plot(pi, prob, ylab=&#39;P(pi| x)&#39;, type=&#39;l&#39;, ylim=c(0,15), xlim=c(0,1), col=cols[1], main=&#39;Any psychiatric medicine&#39; ) } else if(n %in% ns) { points(pi, prob, type=&#39;l&#39;, col=cols[which(ns %in% n)] ) } } legend(&#39;topright&#39;, legend=ns, col=cols[1:length(ns)], lty=1, bty=&#39;n&#39;) Same plots for psilocybin drug use Code puf$psilcy = ifelse(puf$psilcy==&#39;yes&#39;, 1, 0) S = 0 for(n in 1:max(ns)){ S = S + sample(puf$psilcy, size = 1) prob = dbeta(pi, S+1, n -S + 1) if(n==ns[1]){ plot(pi, prob, ylab=&#39;P(pi| x)&#39;, type=&#39;l&#39;, ylim=c(0,15), xlim=c(0,1), col=cols[1], main=&#39;Psilocybin&#39; ) } else if(n %in% ns) { points(pi, prob, type=&#39;l&#39;, col=cols[which(ns %in% n)] ) } } legend(&#39;topright&#39;, legend=ns, col=cols[1:length(ns)], lty=1, bty=&#39;n&#39;) What are some things you notice about the plots? What happens as the sample size gets larger? 5.3.3 Triangle shaped priors How about if we think the parameter \\(\\pi\\) lies toward the lower end of the interval (prior to looking at the data)? We could use a prior \\(2(1-\\pi)\\). Going through the math again gives us the posterior \\[ \\pi \\mid x \\sim \\text{Beta}(\\sum_{i=1} x_i+1, n-\\sum_{i=1} x_i+2) \\] Code set.seed(1234) S=0 for(n in 1:max(ns)){ S = S + sample(puf$psyanyflag, size = 1) prob = dbeta(pi, S+1, n -S + 2) if(n==ns[1]){ plot(pi, prob, ylab=&#39;P(pi| x)&#39;, type=&#39;l&#39;, ylim=c(0,15), xlim=c(0,1), col=cols[1], main=&#39;Any psychiatric medicine&#39; ) } else if(n %in% ns) { points(pi, prob, type=&#39;l&#39;, col=cols[which(ns %in% n)] ) } } legend(&#39;topright&#39;, legend=ns, col=cols[1:length(ns)], lty=1, bty=&#39;n&#39;) For the psilocybin data: Code S = 0 for(n in 1:max(ns)){ S = S + sample(puf$psilcy, size = 1) prob = dbeta(pi, S+1, n -S + 2) if(n==ns[1]){ plot(pi, prob, ylab=&#39;P(pi| x)&#39;, type=&#39;l&#39;, ylim=c(0,15), xlim=c(0,1), col=cols[1], main=&#39;Psilocybin&#39; ) } else if(n %in% ns) { points(pi, prob, type=&#39;l&#39;, col=cols[which(ns %in% n)] ) } } legend(&#39;topright&#39;, legend=ns, col=cols[1:length(ns)], lty=1, bty=&#39;n&#39;) 5.3.4 Posterior inference using Bayesian statistics Because we have the full posterior distribution of \\(\\pi\\), we can do whatever we want with it, e.g. reporting mean and variance. 5.3.4.1 The posterior mode A point estimate for the parameters can be obtained from posterior mode of the parameter (sort of like maximum likelihood) The posterior mode is helpful to compare to the frequentist maximum likelihood estimator. Mode of a \\(\\text{Beta}(a, b)\\) distribution is the value where the maximum occurs, it is (from wikipedia) \\[ \\frac{a-1}{a+b-2}, \\] For the posterior with the uniform prior, the mode is \\[ \\frac{1 +\\sum_{i=1}x_i - 1}{2 + n - 2 }. \\] When \\(\\alpha,\\beta=1\\) the prior is uniform on \\((0,1)\\), \\[ p(\\pi \\mid x) \\propto p(x \\mid \\pi) p(\\pi) = \\mathbb{P}(X=x \\mid \\pi) \\times 1 = L(\\pi \\mid x) \\] the mode in this case is the MLE! 5.3.4.2 Bayesian credible intervals Bayesians generally frown upon just reporting the mean and report quantiles instead. Posterior interval \\[ \\mathbb{P}(\\ell(x) &lt; \\pi &lt; u(x) \\mid x) = \\int_\\ell^u f(\\pi \\mid x) d\\pi = 1-\\alpha \\] Bayesian intervals are called Credible intervals. They show where the parameter is likely to be given the data. Distinction: \\(\\pi\\) is random!!!! Since it follows a beta distribution, we can get quantiles using R. Code set.seed(111) # S - the numnber of events/ Yes answers # n - the sample size flatPriorBinom = function(S, n, probs=c(0.025, 0.975)){ qs = qbeta(probs, S+1, n -S + 1) names(qs) = paste(&#39;quantile&#39;, probs, sep=&#39;_&#39;) c(mode=S/n, mean = (S+1)/(n + 2), qs) } n = 100 pi = ppoints(1000) X = sample(puf$psilcy, size = n) res = flatPriorBinom(sum(X), n) S = sum(X) prob = dbeta(pi, S+1, n -S + 1) poly = data.frame(x=c(pi,rev(pi)), y=c(prob, rep(0, length(pi)))) poly = poly[ poly$x&gt;= res[&#39;quantile_0.025&#39;] &amp; poly$x&lt;=res[&#39;quantile_0.975&#39;], ] plot(pi, prob, ylab=&#39;P(pi| x)&#39;, type=&#39;l&#39;, ylim=c(0,15), xlim=c(0,0.5), col=cols[1] ) polygon(poly$x, poly$y, border = NA, col=cols[2]) Code round(flatPriorBinom(sum(X), n), 3) ## mode mean quantile_0.025 quantile_0.975 ## 0.090 0.098 0.049 0.162 Code # True value of the parameter in the &quot;population&quot; mean(puf$psilcy) ## [1] 0.07784242 Amazing part of Bayes is the interpretation! Parameter lies in the interval with 95% probability. Represents subjective probability. Dependent on the prior. 5.3.5 Introducing other notation Think of \\(H\\) as a parameter value or vector Prior depends on other parameters that are unknown (We need to set them) \\[ \\begin{align*} \\text{likelihood } p(x \\mid \\theta) \\\\ \\text{prior } p(\\theta \\mid \\gamma) \\\\ \\text{posterior } p(\\theta \\mid x, \\gamma) \\end{align*} \\] 5.3.6 Conjugate prior \\[ \\begin{align*} p(\\pi \\mid \\alpha, \\beta) &amp; = \\frac{ \\pi^{\\alpha-1 }(1-\\pi)^{\\beta-1}}{B(\\alpha, \\beta)} \\\\ p(x \\mid \\pi) &amp; = \\pi^{\\sum_{i=1} x_i}(1-\\pi)^{n-\\sum_{i=1} x_i} \\\\ p(x) &amp; = \\text{ not going to worry about this here.} \\end{align*} \\] \\[ p(\\pi \\mid x) \\propto \\frac{ \\pi^{\\alpha-1 }(1-\\pi)^{\\beta-1}}{B(\\alpha, \\beta)} \\times \\pi^{\\sum_{i=1} x_i}(1-\\pi)^{n-\\sum_{i=1} x_i} \\] \\[ \\pi \\mid x \\sim \\text{Beta}(\\alpha +\\sum_{i=1}x_i, \\beta + n-\\sum_{i=1} x_i ) \\] Conjugate priors are priors whose posterior is the same distributional family as the prior (but with different parameters that depend on the data; this was a conjugate prior) Uniform distribution is technically also a conjugate prior with \\(\\alpha = \\beta = 1\\). Jeffreys prior for binomial likelihood is the one you used for the Homework in Module 4, \\(\\alpha = \\beta = 1/2\\). Also considered an uninformative prior. Code pi = ppoints(100) prob = dbeta(pi, 1/2, 1/2) plot(pi, prob, ylab=&#39;P(pi)&#39;, type=&#39;l&#39;, ylim=c(0,5), xlim=c(0,1), col=cols[1], main=&#39;Jeffreys prior&#39; ) Prior that adds one observation to each category Code pi = ppoints(100) prob = dbeta(pi, 1+1/2, 1+1/2) plot(pi, prob, ylab=&#39;P(pi)&#39;, type=&#39;l&#39;, ylim=c(0,5), xlim=c(0,1), col=cols[1], main=&#39;Add-one-half prior&#39; ) 5.3.7 Interpretation of these priors A point estimate for the parameters can be obtained from posterior mode of the parameter (sort of like maximum likelihood) Mode of a \\(\\text{Beta}(a, b)\\) distribution is the value where the maximum occurs, it is (from wikipedia) \\[ \\frac{a-1}{a+b-2}, \\] For the posterior the mode it is \\[ \\frac{\\alpha +\\sum_{i=1}x_i - 1}{\\beta +\\alpha + n - 2 }. \\] When \\(\\alpha,\\beta=1\\) the prior is uniform on \\((0,1)\\), \\[ p(\\pi \\mid x) \\propto p(x \\mid \\pi) p(\\pi) = \\mathbb{P}(X=x \\mid \\pi) \\times 1 = L(\\pi \\mid x) \\] the mode in this case is the MLE! When \\(\\alpha,\\beta = 1/2\\) it is equivalent to subtracting 1/2 from the count for psilocybin users and psilocybin users. 5.3.8 Plot the posteriors in the results Compare Jeffreys and Uniform priors Before looking at the posteriors associated with each prior distribution, which posterior do you think will be closer to 1/2? Code set.seed(1234) n = 50 psil = sample(puf$psilcy, size = n) S = sum(psil) pi = ppoints(1000) alpha = beta = 1 plot(pi, dbeta(pi, shape1=alpha+S, shape2=beta+n-S), type=&#39;l&#39;, col=cols[1], ylab=&#39;P(pi|X)&#39;, main=&#39;Posterior distribution&#39;) alpha = beta = 1/2 points(pi, dbeta(pi, shape1=alpha+S, shape2=beta+n-S), type=&#39;l&#39;, col=cols[2]) legend(&#39;topright&#39;, legend=paste0(&#39;alpha,beta=&#39;, c(1,1/2)), bty=&#39;n&#39;, lty=1, col=cols[1:2]) 5.3.9 Informative priors Incorporate subjectivity into our analysis What type of data are each of these priors appropriate for? A disease prevalence? A coin flip? Which priors are more “informative” (they are more certain about where the parameter should be)? Which priors do you think will be more responsive to the data (i.e. the posterior will be more influenced by the data)? Formula reminder for posterior mode: \\[ \\frac{\\alpha +\\sum_{i=1}x_i - 1}{\\beta +\\alpha + n - 2 }. \\] Code params = data.frame(alpha=c(1,5,10,5,50), beta=c(1,5,5,20,50)) alpha = beta = 1 pi = ppoints(1000) pOfpi = dbeta(pi, shape1=alpha, shape2=beta) plot(pi, pOfpi, col=cols[1], ylab=&#39;P(pi|X)&#39;, type=&#39;n&#39;, ylim=c(0,20), main=&#39;Beta Priors&#39;) for(ind in 1:nrow(params)){ alpha = params$alpha[ind] beta = params$beta[ind] pOfpi = dbeta(pi, shape1=alpha, shape2=beta) points(pi, pOfpi, col=cols[ind], type=&#39;l&#39;) } legend(&#39;topright&#39;, bty=&#39;n&#39;, legend=paste0(&#39;(alpha, beta)=&#39;, &#39;(&#39;, params$alpha, &#39;,&#39;, params$beta, &#39;)&#39;), lty=1, col=cols[1:nrow(params)] ) 5.3.10 Posteriors with small and large sample sizes 5.3.10.1 For the psychiatric medicine data Code params = data.frame(alpha=c(1,5,10,5,50), beta=c(1,5,5,20,50)) alpha = beta = 1 pi = ppoints(1000) pOfpi = dbeta(pi, shape1=alpha, shape2=beta) ns = c(20, 200, 2000) for(n in ns){ psych = sample(puf$psyanyflag, size = n) S = sum(psych) if(n&lt;=200) ymax=30 else ymax=70 plot(pi, pOfpi, col=cols[1], ylab=&#39;P(pi|X)&#39;, type=&#39;n&#39;, ylim=c(0,ymax), main=paste0(&#39;Beta Posterior, n=&#39;,n)) for(ind in 1:nrow(params)){ alpha = params$alpha[ind] beta = params$beta[ind] pOfpi = dbeta(pi, shape1=alpha+S, shape2=beta+n-S) points(pi, pOfpi, col=cols[ind], type=&#39;l&#39;) } legend(&#39;topright&#39;, bty=&#39;n&#39;, legend=paste0(&#39;(alpha, beta)=&#39;, &#39;(&#39;, params$alpha, &#39;,&#39;, params$beta, &#39;)&#39;), lty=1, col=cols[1:nrow(params)] ) } 5.3.10.2 For the psilocybin data Code params = data.frame(alpha=c(1,5,10,5,50), beta=c(1,5,5,20,50)) alpha = beta = 1 pi = ppoints(1000) pOfpi = dbeta(pi, shape1=alpha, shape2=beta) ns = c(20, 200, 2000) for(n in ns){ psil = sample(puf$psilcy, size = n) S = sum(psil) if(n&lt;=200) ymax=30 else ymax=70 plot(pi, pOfpi, col=cols[1], ylab=&#39;P(pi|X)&#39;, type=&#39;n&#39;, ylim=c(0,ymax), main=paste0(&#39;Beta Posterior, n=&#39;,n)) for(ind in 1:nrow(params)){ alpha = params$alpha[ind] beta = params$beta[ind] pOfpi = dbeta(pi, shape1=alpha+S, shape2=beta+n-S) points(pi, pOfpi, col=cols[ind], type=&#39;l&#39;) } legend(&#39;topright&#39;, bty=&#39;n&#39;, legend=paste0(&#39;(alpha, beta)=&#39;, &#39;(&#39;, params$alpha, &#39;,&#39;, params$beta, &#39;)&#39;), lty=1, col=cols[1:nrow(params)] ) } Take home points: Bayesian approaches are not a magic bullet for small samples In large samples posterior doesn’t matter, as \\(n\\to \\infty\\) the parameters \\(\\alpha\\) and \\(\\beta\\) are small relative to the contribution of the data. \\[ \\text{Beta}(\\alpha +\\sum_{i=1}x_i, \\beta + n-\\sum_{i=1} x_i ) \\] 5.4 Assessing frequentist probabilities for Bayesian methods Binomial proportion After a Bayesian analysis we can get a PI \\[ p(\\ell(x, \\alpha) &lt; \\pi &lt; u(x, \\alpha) \\mid x ) = 1-\\alpha \\] What is the interpretation of this interval? Although the interpretation is conditional on the observed data, we still have an interval that we can evaluate across data sets in the frequentist sense. Code # number of simulations nsim = 1000 # sample sizes ns = round(seq(10, 5000, length.out=10)) # parameter pis = c(0.001,0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99,0.999) # Desired coverage probability (1-alpha) alpha = 0.05 # Function to compute Bayesian Posterior Intervals for pi # S - sum of the X_i&#39;s number successes or proportion LSD users # alpha and beta are prior parameter values bayesBinomPI = function(S, n, alpha=1/2, beta=1/2, probs=c(0.025, 0.975)){ qs = t(apply(cbind(alpha, beta), 1, function(row) qbeta(probs, S+row[1], n -S + row[2]) )) colnames(qs) = paste(&#39;quantile&#39;, probs, sep=&#39;_&#39;) data.frame(alpha=alpha, beta=beta, mode=(S+alpha-1)/(n + alpha + beta - 2), qs) } # enter some more priors priors = data.frame(&#39;alpha&#39; = c(1/2, 1, 50, 10), &#39;beta&#39; = c(1/2, 1, 50, 50)) # creating blank output table results = expand.grid(pi=pis , n=ns) priornames = paste(paste0(names(priors)[1], priors[,1]), paste0(names(priors)[2], priors[,2]), sep=&#39;_&#39;) colNames = paste(rep(priornames, each=2), rep(c(&#39;Coverage&#39;, &#39;Width&#39;), nrow(priors))) results[, colNames ] = NA for(paramSetting in 1:nrow(results)){ pi = results[paramSetting,&#39;pi&#39;] n = results[paramSetting, &#39;n&#39;] #matrix(rlnorm(n * nsim, meanlog = mu, sdlog=sqrt(sigmaSq)), nrow=n) simres = matrix(NA, ncol=ncol(results)-2, nrow=nsim, dimnames=list(NULL, names(results)[-c(1,2)]) ) for(sim in 1:nsim){ # Computes the number of events/ &quot;yes&quot; S = sum(rbinom(n, 1, pi)) # Computes the posterior interval for all parameter values PIs = bayesBinomPI(S, n, alpha=priors[,&#39;alpha&#39;], beta=priors[,&#39;beta&#39;]) # Get whether the interval covered the parameter simres[sim, paste(priornames, &#39;Coverage&#39;)] = (PIs[,4]&lt;=pi &amp; PIs[,5]&gt;=pi) # Get the width of the interval simres[sim, paste(priornames, &#39;Width&#39;)] = PIs[,5] - PIs[,4] } results[paramSetting, -c(1,2)] = colMeans(simres) } ### Plot the results layout(matrix(1:length(ns), nrow=2, byrow = TRUE) ) for(n in ns){ subres = results[ results$n==n, ] # create the plots plot(subres$pi, subres[,paste(priornames[1], &#39;Coverage&#39;)], xlab=&#39;pi&#39;, ylab=&#39;Coverage&#39;, type=&#39;n&#39;, ylim=c(0,1), main=paste0(&#39;n=&#39;, n)) columnNames = paste(priornames, &#39;Coverage&#39;) trash = sapply(1:length(columnNames), function(ind) points(subres$pi, subres[,columnNames[ind]], type=&#39;b&#39;, col=cols[ind] ) ) abline(h=0.95, lty=2) } legend(&#39;bottomright&#39;, bg=&#39;white&#39;, fill=cols[1:length(columnNames)], legend=columnNames) 5.5 Extra stuff 5.5.1 Bayesian continuous mean analysis Preliminary info: Writing one-sample and two-sample models as linear models. 5.5.2 One sample mean I am using the brms package, which relies on Stan to do MCMC The package needs to compile stan code for each analysis, which takes about 30 seconds The MCMC part takes fractions of a second (it’s super fast) My approach here for the “noninformative” prior is by choosing a very large variance Code set.seed(122) library(brms) n = 100 adni = readRDS(&#39;../..//datasets/adni/hippocampus.rds&#39;) adni = adni[sample(nrow(adni), n),] adni$diff = adni$LEFTHIPPO - adni$RIGHTHIPPO # Prior at zero # not very informative noninform = set_prior(&quot;normal(0,1000)&quot;, class = &quot;Intercept&quot;) # more informative inform = set_prior(&quot;normal(0,2)&quot;, class = &quot;Intercept&quot;) # very informative veryInform = set_prior(&quot;normal(0,0.25)&quot;, class = &quot;Intercept&quot;) # defaults to flat prior - should be close to the t-test bayesNonInformResults = brm(diff ~ 1, data=tp, prior = noninform) bayesInformResults = brm(diff ~ 1, data=tp, prior = inform) bayesVeryInformResults = brm(diff ~ 1, data=tp, prior = veryInform) ttestResults = t.test(tp$diff) 5.5.3 Bayesian two sample normal means analysis \\(\\mathbb{E}Y_i \\mid \\text{F} = \\mu_0 = \\beta_0\\) \\(\\mathbb{E}Y_i \\mid \\text{M} = \\mu_1 = \\beta_0 + \\beta_1\\) Implies \\(\\beta_1 = \\mu_1 - \\mu_0\\). Code library(brms) # removing spaces from names names(mf) = gsub(&#39; &#39;, &#39;_&#39;, names(mf)) # Prior at zero # not very informative noninform = c(set_prior(&quot;normal(0,1000)&quot;, class = &quot;Intercept&quot;), set_prior(&quot;normal(0,1000)&quot;, class=&#39;b&#39;) ) # more informative inform = c(set_prior(&quot;normal(0,2)&quot;, class=&#39;b&#39;)) # very informative veryInform = c(set_prior(&quot;normal(0,0.25)&quot;, class=&#39;b&#39;)) bayesModels = list( # defaults to flat prior - should be close to the t-test bayesNoPriorResults = brm(C4_CSA ~ Sex, data=mf), # our own noninformative prior bayesNonInformResults = brm(C4_CSA ~ Sex, data=mf, prior = noninform), bayesInformResults = brm(C4_CSA ~ Sex, data=mf, prior = inform), bayesVeryInformResults = brm(C4_CSA ~ Sex, data=mf, prior = veryInform) ) lapply(bayesModels, prior_summary) ttestResults = t.test(mf$C4_CSA~mf$Sex) lapply(bayesModels, function(x) summary(x)$fixed) Today we will: Evaluate the Bayesian binomial proportion using simulations Explore Bayesian concepts in the context of a single mean Distinction from binomial proportion is that we have normal distribution and two parameters (mean and variance) 5.5.4 Normal mean with known variance For the normal mean with known variance the normal is also the conjugate prior for the mean \\[ \\begin{align*} p(\\mu \\mid \\nu, \\tau^2) &amp; = (2\\pi\\tau^2)^{-1/2}\\exp\\left\\{-\\frac{1}{2\\tau^2}(\\mu - \\nu)^2\\right\\} \\\\ p(x \\mid \\mu) &amp; = (2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(X_i - \\mu)^2\\right\\}\\\\ p(x) &amp; = \\text{ don&#39;t need to worry about this.} \\end{align*} \\] You’ll derive the posterior for your homework and explore how the prior affects the results I’ll do it here too. The posterior is \\[ \\mu \\mid x, \\nu, \\tau^2 \\sim N\\left\\{\\frac{\\tau^2}{\\sigma^2/n + \\tau^2} \\bar x + \\frac{\\sigma^2/n}{\\sigma^2/n + \\tau^2} \\mu, \\left( \\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}\\right)^{-1} \\right\\} \\] 5.5.5 Unknown mean, unknown variance uninformative priors 5.5.5.1 With noninformative priors Flat prior is proportional to 1 (an improper prior) Normal as the variance goes to infinity 5.5.5.2 Marginalizing out variance to get t-distribution with uninformative priors \\[ \\begin{align*} p(x\\mid \\mu, \\sigma^2) &amp; = (2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(X_i - \\mu)^2\\right\\}\\\\ p(\\mu) &amp; \\propto 1 \\\\ p(\\sigma^2) &amp; \\propto 1/\\sigma^2 \\end{align*} \\] Then the posterior is \\[ \\begin{align*} \\int_{\\sigma^2} p(\\mu, \\sigma^2 \\mid x) &amp; \\propto p(x\\mid \\mu,\\sigma^2)p(\\mu)p(\\sigma^2) \\\\ &amp; = \\int_{\\sigma^2}(2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i - \\mu)^2\\right\\} \\times 1/\\sigma^2 \\\\ &amp; \\propto \\int_{\\sigma^2}(\\sigma^2)^{-(n+2)/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i - \\mu)^2\\right\\} \\\\ &amp; = \\Gamma((n-1)/2)\\times \\left(\\frac{1}{2}\\sum_{i=1}^n(x_i - \\mu)^2\\right)^{-n/2} \\\\ &amp; \\propto \\left(\\tilde\\sigma^2\\left[1+ \\frac{n(\\bar x - \\mu)^2}{\\tilde\\sigma^2} \\right] \\right)^{-(n-1 + 1)/2} \\end{align*} \\] \\(\\sigma^2\\) is a nuisance parameter, we can integrate it out (called marginalizing with respect to \\(\\sigma^2\\)). This will give us the marginal distribution of \\(\\mu\\). Take home points of this We get the t-distribution. We can interpret the t- confidence interval in a Bayesian framework, assuming a flat prior on \\(\\mu\\) and a prior proportional to \\(1/\\sigma\\) for \\(\\sigma^2\\). 5.5.6 Informative priors for the normal likelihood 5.5.6.1 Known mean, unknown variance 5.5.6.2 Preliminaries Inverse gamma distribution: If \\(\\sigma^2 \\sim \\text{IG}(\\alpha, \\beta)\\) it has PDF \\[ f(s) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}s^{-\\alpha-1}e^{-\\beta/s} \\] \\(\\Gamma(\\alpha)\\) is the gamma function (it’s just a normalizing constant so that the integral is equal to 1). For the normal with known mean and unknown variance, the inverse gamma is the conjugate prior (for the variance) \\[ \\begin{align*} p(\\sigma^2 \\mid \\alpha, \\beta) &amp; = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}(\\sigma^2)^{-\\alpha-1} e^{-\\beta/\\sigma^2} \\\\ p(x\\mid \\mu, \\sigma^2) (2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(X_i - \\mu)^2\\right\\} \\\\ p(x \\mid \\alpha, \\beta) = \\text{ don&#39;t need to worry about this.} \\end{align*} \\] \\[ \\begin{align*} p(\\sigma^2\\mid x) &amp; \\propto p(x\\mid \\sigma^2) p(\\sigma^2 \\mid \\alpha, \\beta) \\\\ &amp; = (2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(X_i - \\mu)^2\\right\\} \\times \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}(\\sigma^2)^{-\\alpha-1} e^{-\\beta/\\sigma^2} \\\\ &amp; \\propto (\\sigma^2)^{-\\alpha-n/2-1}\\exp\\left\\{ -\\frac{\\frac{1}{2}\\sum_{i=1}^n(X_i - \\mu)^2 + \\beta}{\\sigma^2}\\right\\} \\\\ &amp;\\propto IG\\left(\\alpha+n/2, \\beta + 1/2\\sum_{i=1}^n(X_i - \\mu)^2 \\right) \\end{align*} \\] 5.5.6.3 Unknown mean, unknown variance informative priors Review about definition of dependent/independent random variables Conditional on \\(x\\), \\(\\sigma^2\\) and \\(\\mu\\) are dependent More advanced Bayesian approaches are needed for this (Markov chain Monte Carlo) 5.5.6.4 Bayesian inference in practice Performing inference in R. Aside: Using a linear model perform a one sample t-test 5.5.6.5 Comparing two means using Bayesian statistics in R Code library(brms) load(&#39;~/Box Sync/teaching/PMB/datasets/smith_cervical_sc/tpmf.rdata&#39;) tp$diff = tp$`C4 CSA_tp2` - tp$`C4 CSA_tp1` # Prior at zero # not very informative noninform = set_prior(&quot;normal(0,500)&quot;, class = &quot;Intercept&quot;) # more informative inform = set_prior(&quot;normal(0,2)&quot;, class = &quot;Intercept&quot;) # very informative veryInform = set_prior(&quot;normal(0,0.25)&quot;, class = &quot;Intercept&quot;) # defaults to flat prior - basically the same as a t-test bayesNonInformResults = brm(diff ~ 1, data=tp, prior = noninform ) bayesInformResults = brm(diff ~ 1, data=tp, prior = inform) bayesVeryInformResults = brm(diff ~ 1, data=tp, prior = veryInform) ttestResults = t.test(tp$diff) 5.5.7 Software There is good software to do Bayesian inference for complicated models Stan, Inla, Bugs – I think all can be called from R and Python. 5.5.8 Flat priors in general When can we use them? Edwards et al. describe 3 assumptions. Distinction between \\(\\mathbb{P}(H \\mid X)\\) and \\(\\mathbb{P}(X \\mid H)\\) as a function of \\(H\\). (The second is not necessarily a PDF/PMF. Does not have the same form for \\(X\\) and \\(H\\). Improper prior 5.5.9 Informative priors For penalization, e.g. regularized regression Horseshoe priors, Lasso priors Random effects models "],["categorical-data.html", "6 Categorical data 6.1 Contingency tables 6.2 Cohort sampling 6.3 Case-control sampling 6.4 Design considerations for case-control versus cohort samples 6.5 Probability models for the two designs 6.6 Pearson’s chi-squared test 6.7 Categorical versus ordinal variables 6.8 Contingency table concepts 6.9 Things not talked about here", " 6 Categorical data This will be to catch some of the things I think you will need that we haven’t covered yet. Contingency tables Nonparametric tests 6.1 Contingency tables Today we will: Introduce Pearson’s chi-squared test for two way tables Extend to larger tables Case control sampling Cohort study sampling Introduce contingency table concepts Risk difference Relative Risk Odds ratio A contingency table is an array of counts associated with one or more categorical or ordinal variables. The number of dimensions of the table depends on the number of variables and the size of each dimension depends on the number of categories. Code set.seed(1333) puf = readRDS(&#39;../datasets/nsduh/puf.rds&#39;) knitr::kable(matrix(c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;), nrow=2, dimnames=list(c(&#39;X=0&#39;, &#39;X=1&#39;), c(&#39;Y=0&#39;, &#39;Y=1&#39;) ) ) ) Y=0 Y=1 X=0 a c X=1 b d 6.1.1 Example: Marijuana and LSD use Code mjlsdtab = with(puf, table(mrjflag, lsdflag)) pander::pander(descr::CrossTable(mjlsdtab, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE))   mrjflag lsdflag no   yes   Total no N Total(%)   33033 58.0575%   75 0.1318%   33108 yes N Total(%)   19281 33.8876%   4508 7.9231%   23789 Total 52314 4583 56897 6.2 Cohort sampling Code # Cohort sampleing n = 200 # number in each group dat = puf[sample(nrow(puf), size = n), c(&#39;mrjflag&#39;, &#39;lsdflag&#39;)] Cohortmjlsdtab = with(dat, table(mrjflag, lsdflag)) pander::pander(descr::CrossTable(Cohortmjlsdtab, prop.r = TRUE, prop.t=FALSE, prop.c = FALSE, prop.chisq = FALSE))   mrjflag lsdflag no   yes   Total no N Row(%)   117 100.0000%   0 0.0000%   117 58.5000% yes N Row(%)   63 75.9036%   20 24.0964%   83 41.5000% Total 180 20 200 The way proportions are computed matters. If we are sampling from a cohort study, then no margins are fixed. The cells can be represented by joint or conditional probabilities. If we are sampling using a case-control study, then a single margin is fixed. The cells should be represented with conditional probabilities. 6.3 Case-control sampling In case-control sampling, the data are sampled conditional on the outcome. For example, if I sample patients and controls in equal proportions. Case-control studies sample conditional on one variable (e.g. diagnosis, or MJ use). Code # case control sampling n = 200 # number in each group lsdflag = factor(c(sample(puf$lsdflag[ puf$mrjflag==&#39;no&#39;], n), # samples lsd use for 200 people who have never used MJ sample(puf$lsdflag[ puf$mrjflag==&#39;yes&#39;], n) ), # samples lsd use for 200 people who have used MJ levels = c(&#39;no&#39;, &#39;yes&#39;), labels=c(&#39;no&#39;, &#39;yes&#39;) ) dat = data.frame(mrjflag=rep(c(&#39;no&#39;, &#39;yes&#39;), each=n), lsdflag=lsdflag ) CCmjlsdtab = with(dat, table(mrjflag, lsdflag)) pander::pander(descr::CrossTable(CCmjlsdtab, prop.r = TRUE, prop.t=FALSE, prop.c = FALSE, prop.chisq = FALSE))   mrjflag lsdflag no   yes   Total no N Row(%)   200 100%   0 0%   200 50% yes N Row(%)   158 79%   42 21%   200 50% Total 358 42 400 6.4 Design considerations for case-control versus cohort samples If the disease outcome is rare, it’s probably better to use a case-control design to ensure that there are enough cases. Case-control designs don’t allow you to estimate the risk difference or ratio of the disease, because you’ve fixed the number of patient and control subjects. 6.5 Probability models for the two designs 6.5.1 Binomial conditional on \\(Y\\). Let \\(Y_i\\) denote the marijuana use yes/no for subject \\(i\\) and \\(X_i\\) denote the LSD use for \\(i=1,\\ldots, n\\). Conditional on \\(Y_i\\), we can assume that \\(Y_i=0\\) for all \\(i=1, \\ldots, n_0\\), and \\(Y_i=1\\) for all \\(i=n_0 + 1, \\ldots, n\\). This allows us to write this like we did for the two means problem \\[ \\begin{align*} X_i &amp; \\sim \\mathrm{Bern}(\\pi_0) \\text{ for $i=1,\\ldots,n_0$}\\\\ X_i &amp; \\sim \\mathrm{Bern}(\\pi_1)\\text{ for $i=n_0+1,\\ldots,n_0+n_1$} \\end{align*} \\] 6.5.2 Multinomial where probabilities depend on shape of array. The probability someone falls into a given cell can be modeled with a multinomial distribution. Let \\(x_i = [x_{i1}, x_{i2}, x_{i3}, x_{i4}]\\), where \\(x_{ij}=0,1\\) and only one of the elements \\(x_{ij}=1\\). \\[ \\mathbb{P}(X_i=[x_{i1}, x_{i2}, x_{i3}, x_{i4}] ) = \\pi_1^{x_1}\\pi_2^{x_2}\\pi_3^{x_3} \\pi_4^{x_4} \\] and \\(\\sum \\pi_j = 1\\) The multinomial probability describes how likely someone falls into a cell with a given combination yes/no answers. Have to decide some order about how the \\(\\pi_j\\) correspond to elements of the table. 6.5.3 Independence hypothesis Conditional probabilities are equal \\[ \\pi_0 = \\pi_1 \\] Product of marginals \\[ P(X_i=j, Y_i = k) = P(X_i =j)P(Y_i=k) \\] 6.6 Pearson’s chi-squared test Pearson’s chi-squared test is a way to test this hypothesis The degrees of freedom depends on the model \\[ \\chi^2 = \\sum_{i=1}^{n} \\frac{(O_i - E_i)^2}{E_i} = N \\sum_{i=1}^n \\frac{\\left(O_i/N - p_i\\right)^2}{p_i} \\] Derivation of the test statistic distribution uses linear algebra 6.6.1 Using the chi-squared test Specify the null hypothesis of independence for the case-control and cohort designs \\(H_0 : \\mathbb{P}(X_{ij}=x_{ij}) = \\text{product of marginal probabilities}\\) Implies independence of the two variables. Code # how should I compute the null probabilities for this? cs = colSums(CCmjlsdtab) pihat = cs[2]/(cs[2]+ cs[1]) nullprobs = matrix(c(1-pihat, 1-pihat, pihat, pihat), nrow=2) #chisq.test(CCmjlsdtab, p = nullprobs) CC = chisq.test(CCmjlsdtab, p=nullprobs) # also tests the same thing othernull = matrix(rep(1/4, 4), nrow=2) chisq.test(CCmjlsdtab, p=othernull, correct = FALSE) ## ## Pearson&#39;s Chi-squared test ## ## data: CCmjlsdtab ## X-squared = 46.927, df = 1, p-value = 7.367e-12 Code #pander::pander(descr::CrossTable(CCmjlsdtab, chisq=TRUE, expected=TRUE, prop.t=FALSE, prop.c = FALSE,prop.chisq=FALSE)) descr::CrossTable(CCmjlsdtab, chisq=TRUE, expected=TRUE, prop.t=FALSE, prop.c = FALSE,prop.chisq=FALSE) ## Cell Contents ## |-------------------------| ## | N | ## | Expected N | ## | N / Row Total | ## |-------------------------| ## ## ============================== ## lsdflag ## mrjflag no yes Total ## ------------------------------ ## no 200 0 200 ## 179 21 ## 1.00 0.00 0.50 ## ------------------------------ ## yes 158 42 200 ## 179 21 ## 0.79 0.21 0.50 ## ------------------------------ ## Total 358 42 400 ## ============================== ## ## Statistics for All Table Factors ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 46.92737 d.f. = 1 p = 7.37e-12 ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ------------------------------------------------------------ ## Chi^2 = 44.71934 d.f. = 1 p = 2.27e-11 Code # how should I compute the null probabilities for this? cs = colSums(Cohortmjlsdtab) rs = rowSums(Cohortmjlsdtab) pihat = cs[2]/(cs[2]+ cs[1]) pihat2 = rs[2]/(cs[2]+ cs[1]) nullprobs = outer(c(1-pihat2, pihat2), c(1-pihat, pihat)) #chisq.test(CCmjlsdtab, p = nullprobs) cohort = chisq.test(Cohortmjlsdtab, p = nullprobs) # also tests the same thing othernull = matrix(rep(1/4, 4), nrow=2) chisq.test(Cohortmjlsdtab, p=othernull) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: Cohortmjlsdtab ## X-squared = 28.705, df = 1, p-value = 8.428e-08 Code # renders it in a nice output, but removes test #pander::pander(descr::CrossTable(CCmjlsdtab, chisq=TRUE, expected=TRUE, prop.t=FALSE, prop.c = FALSE,prop.chisq=FALSE)) descr::CrossTable(CCmjlsdtab, chisq=TRUE, expected=TRUE, prop.t=FALSE, prop.c = FALSE,prop.chisq=FALSE) ## Cell Contents ## |-------------------------| ## | N | ## | Expected N | ## | N / Row Total | ## |-------------------------| ## ## ============================== ## lsdflag ## mrjflag no yes Total ## ------------------------------ ## no 200 0 200 ## 179 21 ## 1.00 0.00 0.50 ## ------------------------------ ## yes 158 42 200 ## 179 21 ## 0.79 0.21 0.50 ## ------------------------------ ## Total 358 42 400 ## ============================== ## ## Statistics for All Table Factors ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 46.92737 d.f. = 1 p = 7.37e-12 ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ------------------------------------------------------------ ## Chi^2 = 44.71934 d.f. = 1 p = 2.27e-11 6.6.2 Age by LSD use Test is appropriate for arbitrary number of categories. Uses normal (chi-squared) approximation so requires sufficient numbers in each cell. Might not be very accurate with extremely rare events. Code puf$age = as.character(puf$age) # looking at subset of ages 18 and older agelsdtab = with(puf[puf$age!=&#39;12-17&#39;,], table(age, lsdflag)) descr::CrossTable(agelsdtab, chisq=TRUE, expected=TRUE, prop.t=FALSE, prop.c = FALSE,prop.chisq=FALSE) ## Cell Contents ## |-------------------------| ## | N | ## | Expected N | ## | N / Row Total | ## |-------------------------| ## ## ======================================= ## lsdflag ## age no yes Total ## --------------------------------------- ## 18-25 12543 1117 13660 ## 12254.1 1405.9 ## 0.918 0.082 0.320 ## --------------------------------------- ## 26-34 7907 844 8751 ## 7850.3 900.7 ## 0.904 0.096 0.205 ## --------------------------------------- ## 35-49 9830 1531 11361 ## 10191.7 1169.3 ## 0.865 0.135 0.267 ## --------------------------------------- ## 50 or older 7958 895 8853 ## 7941.8 911.2 ## 0.899 0.101 0.208 ## --------------------------------------- ## Total 38238 4387 42625 ## ======================================= ## ## Statistics for All Table Factors ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 195.204 d.f. = 3 p &lt;2e-16 6.7 Categorical versus ordinal variables Test above is not necessarily the best option. Why? Categorical vs. ordinal variables Cochran-Armitage trend test would be a more efficient way to test this because age is ordinal Anything more complicated than that will require logistic regression (a linear model) E.g. testing whether that an age trend is sufficient to completely model the differences in age 6.8 Contingency table concepts 6.8.1 Association metrics for two binomial proportions There are a few different ways of summarizing categorical differences. Usually described in reference to a treatment/exposure and a disease/outcome. In the example above marijuana use is the “exposure” and LSD use is the “disease”. Risk difference Relative Risk Odds ratio All are parameters are based on the conditional probability of the disease/outcome given the treatment/exposure. For \\(\\mathbb{P}(Y_i = 1 \\mid X_i=0) = \\pi_0\\) and \\(\\mathbb{P}(Y_i = 1 \\mid X_i=1) = \\pi_1\\). \\[ \\begin{align*} RD &amp; = \\pi_1 - \\pi_0\\\\ RR &amp; = \\frac{\\pi_1}{\\pi_0}\\\\ OR &amp; = \\frac{\\pi_1/(1-\\pi_1)}{\\pi_0/(1-\\pi_0)} \\end{align*} \\] What is \\(H_0\\) expressed as each of these parameters? 6.8.2 Confidence intervals for these parameters They are all based on normal approximations. You will derive an estimator and test statistic for the first one. What are intuitive estimators for the other two using the notation below? LSD No LSD MJ \\(n_{11}\\) \\(n_{12}\\) No MJ \\(n_{21}\\) \\(n_{22}\\) \\[ \\begin{align*} \\widehat{RD} &amp; = \\hat\\pi_1 - \\hat\\pi_0 = \\\\ \\widehat{RR} &amp; = \\frac{\\pi_1}{\\pi_0} = \\frac{n_{11}(n_{21}+n_{22})}{(n_{11}+n_{12})n_{21}}\\\\ \\widehat{OR} &amp; = \\frac{n_{11}n_{22}}{n_{12}n_{21}} \\end{align*} \\] Confidence intervals using these estimators \\[ \\begin{align*} \\widehat{RD} \\pm z_{1-\\alpha/2} \\times SE(\\widehat{RD}) \\\\ \\exp\\left\\{ \\log\\widehat{RR}\\pm z_{1-\\alpha/2} \\times SE(\\log\\widehat{RD}) \\right \\} \\\\ \\exp\\left\\{\\log \\widehat{OR} \\pm z_{1-\\alpha/2} \\times SE(\\log\\widehat{OR}) \\right\\} \\end{align*} \\] Where \\[ \\begin{align*} SE(\\widehat{RD}) &amp; = \\sqrt{\\dfrac{n_{11}n_{12}}{(n_{11} + n_{12})^3}+\\dfrac{n_{21}n_{22}}{(n_{21}+n_{22})^3}} \\\\ SE(\\log\\widehat{RD}) &amp;= \\sqrt{\\frac{1}{n_{11}} - \\frac{1}{n_{11}+n_{12}} + \\frac{1}{n_{21}}- \\frac{1}{n_{21}+n_{22}}} \\\\ SE(\\log\\widehat{OR}) &amp; = \\sqrt{\\frac{1}{n_{11}} + \\frac{1}{n_{12}} + \\frac{1}{n_{21}}+\\frac{1}{n_{22}} } \\end{align*} \\] Where \\(SE(\\log\\widehat{RD}) = \\sqrt{\\text{Var}(\\log\\widehat{RD})}\\) The formula for the variance of \\(\\log\\widehat{RD}\\) and \\(\\log\\widehat{OR}\\) is obtained using the Delta method. 6.9 Things not talked about here McNemar’s test – testing correspondence across multiple two-way tables Simpson’s paradox – stratified tables contradict the marginal table Wikipedia. Logistic regression (Can answer all these questions and more in a regression framework) 6.9.1 Other resources Agresti is often used to teach categorical data analysis. "],["nonparametric-tests.html", "7 Nonparametric tests 7.1 Examples of violation of normality assumption 7.2 Two sample 7.3 One sample 7.4 Wilcoxon Rank Sum Test 7.5 Wilcoxon Signed-rank test 7.6 Permutation testing 7.7 There are many other nonparametric tests 7.8 There are more for high-dimensional data", " 7 Nonparametric tests These tests are used when normality is violated They do not make assumptions about the distribution of the data Wilcoxon signed rank test (for paired data) Wilcoxon rank sum test (Also called Mann-Whitney U test) 7.1 Examples of violation of normality assumption 7.2 Two sample Code histinfo = hist(puf$iralcfm, plot = FALSE, probability = TRUE) ## Warning in hist.default(puf$iralcfm, plot = FALSE, probability = TRUE): argument &#39;probability&#39; is not ## made use of Code hist(puf$iralcfm[ puf$mrjmon==&#39;yes&#39;], breaks = histinfo$breaks, main=&quot;Histogram of Alcohol use&quot;, xlab=&quot;Days used past month&quot;, col=rgb(1,0,0,.5), border=NA, probability=TRUE) hist(puf$iralcfm[ puf$mrjmon==&#39;no&#39;], breaks=histinfo$breaks, col=rgb(0,0,1,.5), add=TRUE, border=NA, probability=TRUE ) legend(&#39;topright&#39;, fill=c(rgb(1,0,0,.5), rgb(0,0,1,.5)), legend=c(&#39;Used MJ&#39;, &quot;Didn&#39;t use MJ&quot;), bty=&#39;n&#39;) 7.3 One sample Code diffs = round(puf$iralcfm-puf$ircigfm) hist(diffs, xlab=&#39;alcohol - cigarettes&#39;, main=&#39;Hist of diff&#39;, probability=TRUE, breaks=seq(-30.5, 30.5, length.out=62)) 7.4 Wilcoxon Rank Sum Test Let \\(X_i\\) be 1 if subject \\(i\\) used marijuana in the past month and zero otherwise. \\(Y_i\\) is alcohol use for subject \\(i\\) and assume \\(X_i=0\\) for $i=1, , \\(n_0\\) and \\(X_i=1\\) for \\(i=n_0+1, \\ldots, n\\). This is a two-sample test (similar to the t-test) This method tests the null hypothesis that \\[ \\mathbb{P}(Y_i&gt;Y_j) = \\mathbb{P}(Y_i&lt;Y_j) \\] where \\(Y_i\\) is alcohol use for a randomly selected non-marijuana user and \\(Y_j\\) is alcohol use for a randomly selected marijuana user. Many people often incorrectly say it is a test for the equality of the medians Equation above is called “stochastically greater” Code spuf = puf[sample(nrow(puf), 100),] # full data set test wtestfull = wilcox.test(puf$iralcfm[ puf$mrjmon==&#39;yes&#39;], puf$iralcfm[ puf$mrjmon==&#39;no&#39;]) # subset test wtest = wilcox.test(spuf$iralcfm[ spuf$mrjmon==&#39;yes&#39;], spuf$iralcfm[ spuf$mrjmon==&#39;no&#39;], conf.int = TRUE) wtest ## ## Wilcoxon rank sum test with continuity correction ## ## data: spuf$iralcfm[spuf$mrjmon == &quot;yes&quot;] and spuf$iralcfm[spuf$mrjmon == &quot;no&quot;] ## W = 739, p-value = 0.009905 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## 4.175320e-06 4.000007e+00 ## sample estimates: ## difference in location ## 1.000015 Code wtestfull ## ## Wilcoxon rank sum test with continuity correction ## ## data: puf$iralcfm[puf$mrjmon == &quot;yes&quot;] and puf$iralcfm[puf$mrjmon == &quot;no&quot;] ## W = 226081314, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Code plot(puf$iralcfm[puf$mrjmon==&#39;yes&#39;], rank(puf$iralcfm)[puf$mrjmon==&#39;yes&#39;], xlab=&#39;Days of alcohol use&#39;, ylab=&#39;rank&#39;) Code n1 = sum(spuf$mrjmon==&#39;yes&#39;) n2 = sum(spuf$mrjmon==&#39;no&#39;) wtestStatistic = sum(rank(spuf$iralcfm)[spuf$mrjmon==&#39;yes&#39;]) - n1*(n1+1)/2 mStatistic = n1*n2/2 # Should have a correction for number of ties stdev = sqrt(n1*n2*(n1+n2+1)/12) pnorm(abs((wtestStatistic-mStatistic)/stdev), lower.tail=FALSE) ## [1] 0.01260711 7.5 Wilcoxon Signed-rank test This is a one-sample test (similar to the one-sample/paired t-test) Let’s consider the association between cigarette smoking and alcohol that we looked at before The normality assumption is violated here We also showed that the t-test is robust to this violation (meaning that the type 1 error is pretty close to where it should be) The signed-rank test takes the null hypothesis that the median is equal to zero (or some other chosen value) There are a couple different forms of the test-statistic, Wikipedia gives the formula and the variance. R uses the one that isn’t described on Wikipedia. p-values can be computed for small sample sizes exactly. In large samples, the test statistic is approximately normal with variance \\(N_r(N_r+1)(2N_r +1)/6\\) Code #descr::CrossTable(table(puf$psyanyflag, puf$illflag), chisq = TRUE) diffs = diffs[sample(length(diffs), 100)] wtest = wilcox.test(diffs) ## Warning in wilcox.test.default(diffs): cannot compute exact p-value with ties ## Warning in wilcox.test.default(diffs): cannot compute exact p-value with zeroes Code wtest$statistic ## V ## 701.5 Code sdiffs = sign(diffs[ diffs !=0] ) diffsrank = rank(abs(diffs[ diffs !=0])) nr = length(diffsrank) # test statistic in R statistic= sum(diffsrank[sdiffs&gt;0]) # test statistic that has asymptotic normal distribution Zstatistic = sum(diffsrank*sdiffs)/sqrt(nr*(nr+1)*(2*nr+1)/6) pvalue = 2*pnorm(abs(Zstatistic), lower.tail = FALSE) # wilcox.test result c(wtest$statistic, wtest$p.value) ## V ## 701.5000000 0.3777497 Code # manual result, not exactly the same. May need correction for ties. c(statistic, Zstatistic, pvalue) ## [1] 701.5000000 0.8853092 0.3759899 7.6 Permutation testing Permutation testing can be used to compute “exact” p-values without distributional assumptions. 7.6.1 Permutation testing intuition Consider the two mean example where we are comparing alcohol use between individuals who use marijuana versus those who don’t. Our test statistic is \\[ T = (\\hat\\mu_1 - \\hat\\mu_0)/\\sqrt{\\hat{\\text{Var}}(\\hat\\mu_1 - \\hat\\mu_0)} = T(X, Y) \\] \\(X_i\\) is paired with \\(Y_i\\) for each \\(i\\). If they are independent, the pairing doesn’t matter, so \\(Y_i\\). We can permute the pairing – this combination of \\(X_i\\) and \\(Y_i\\) is equally likely under the null and we could compute a test statistic \\[ T^{p} = T(X^p, Y) \\] where \\(X^p\\) is the permuted marijuana use data. In this case, there are \\({n \\choose n_1}\\) possible pairings. That’s a lot. In practice, because there are so many possible permutations, we just randomly choose a large number of permutations Permutation tests compute a p-value this way for \\(p=1, \\ldots, P\\) \\[ 1/P \\sum_{p=1}^P I\\{ T(X^p, Y) \\ge T\\} \\] The average number of data sets where the test statistics is equal or larger than the observed value. Code permutationTest = function(X, Y, nperm=1000){ Tobs = t.test(Y[X==0], Y[X==1])$statistic # randomly permutes X Tperms = replicate(nperm, {Xperm = sample(X, replace=FALSE); t.test(Y[Xperm==0], Y[Xperm==1])$statistic} ) c(Tobs=Tobs, pvalue=mean(abs(Tperms)&gt;abs(Tobs))) } # In the subset of data permtest = permutationTest(Y=spuf$iralcfm, X = as.numeric(spuf$mrjmon==&#39;yes&#39;)) wtest = wilcox.test(spuf$iralcfm[ spuf$mrjmon==&#39;yes&#39;], spuf$iralcfm[ spuf$mrjmon==&#39;no&#39;], conf.int = TRUE) ttest = t.test(spuf$iralcfm[ spuf$mrjmon==&#39;yes&#39;], spuf$iralcfm[ spuf$mrjmon==&#39;no&#39;]) permtest ## Tobs.t pvalue ## -1.100414 0.338000 Code wtest ## ## Wilcoxon rank sum test with continuity correction ## ## data: spuf$iralcfm[spuf$mrjmon == &quot;yes&quot;] and spuf$iralcfm[spuf$mrjmon == &quot;no&quot;] ## W = 739, p-value = 0.009905 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## 4.175320e-06 4.000007e+00 ## sample estimates: ## difference in location ## 1.000015 Code ttest ## ## Welch Two Sample t-test ## ## data: spuf$iralcfm[spuf$mrjmon == &quot;yes&quot;] and spuf$iralcfm[spuf$mrjmon == &quot;no&quot;] ## t = 1.1004, df = 19.25, p-value = 0.2847 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.243116 4.004479 ## sample estimates: ## mean of x mean of y ## 4.000000 2.619318 Code # In the full sample permtest = permutationTest(Y=puf$iralcfm, X = as.numeric(puf$mrjmon==&#39;yes&#39;)) wtest = wilcox.test(puf$iralcfm[ puf$mrjmon==&#39;yes&#39;], puf$iralcfm[ puf$mrjmon==&#39;no&#39;], conf.int = TRUE) ttest = t.test(puf$iralcfm[ puf$mrjmon==&#39;yes&#39;], puf$iralcfm[ puf$mrjmon==&#39;no&#39;]) permtest ## Tobs.t pvalue ## -37.05836 0.00000 Code wtest ## ## Wilcoxon rank sum test with continuity correction ## ## data: puf$iralcfm[puf$mrjmon == &quot;yes&quot;] and puf$iralcfm[puf$mrjmon == &quot;no&quot;] ## W = 226081314, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## 2.000021 2.000031 ## sample estimates: ## difference in location ## 2.000047 Code ttest ## ## Welch Two Sample t-test ## ## data: puf$iralcfm[puf$mrjmon == &quot;yes&quot;] and puf$iralcfm[puf$mrjmon == &quot;no&quot;] ## t = 37.058, df = 7352.6, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 3.691486 4.103838 ## sample estimates: ## mean of x mean of y ## 6.926761 3.029099 7.7 There are many other nonparametric tests Permutation testing – can be used in a wide array of applications Other tests for comparing distributions Kruskal-Wallis Spearman’s correlation Kolmogorov-Smirnov test for comparing two distributions (and other similar tests; Anderson-Darling, Shapiro-Wilk) 7.8 There are more for high-dimensional data Distance correlation Normalized mutual information "]]
